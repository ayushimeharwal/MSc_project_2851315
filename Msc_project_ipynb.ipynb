{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611c1888",
   "metadata": {},
   "source": [
    "# Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1416d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparsezoo in c:\\users\\ayush\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.24.3)\n",
      "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (6.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (4.65.0)\n",
      "Requirement already satisfied: pydantic~=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (2.8.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (8.0.4)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (5.27.3)\n",
      "Requirement already satisfied: pandas>1.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.5.3)\n",
      "Requirement already satisfied: py-machineid>=0.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (0.6.0)\n",
      "Requirement already satisfied: geocoder>=1.38.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.38.1)\n",
      "Requirement already satisfied: onnxruntime>=1.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.19.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1.2->sparsezoo) (0.4.6)\n",
      "Requirement already satisfied: future in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (0.18.3)\n",
      "Requirement already satisfied: ratelim in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (0.1.6)\n",
      "Requirement already satisfied: six in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnx<1.15.0,>=1.5.0->sparsezoo) (4.7.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (24.3.25)\n",
      "Requirement already satisfied: packaging in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (23.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas>1.3->sparsezoo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas>1.3->sparsezoo) (2022.7)\n",
      "Requirement already satisfied: winregistry in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from py-machineid>=0.3.0->sparsezoo) (1.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic~=2.0->sparsezoo) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic~=2.0->sparsezoo) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (2023.7.22)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.0.0->sparsezoo) (10.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from ratelim->geocoder>=1.38.0->sparsezoo) (5.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.0.0->sparsezoo) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.0.0->sparsezoo) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparsezoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335a2284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepsparse"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [22 lines of output]\n",
      "  Loaded version 1.8.0 from C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-install-jjk1pjky\\deepsparse_a2fd6f60aa0749e1971e4b9cf63c78ba\\src\\deepsparse\\version.py\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-build-env-u__urnc4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 332, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-build-env-u__urnc4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 302, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-build-env-u__urnc4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 503, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-build-env-u__urnc4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 201, in <module>\n",
      "    File \"<string>\", line 162, in _check_supported_system\n",
      "  OSError: Native Windows is currently unsupported for DeepSparse. Please run on a Linux system or within a Linux container on Windows. More info can be found in our docs here: https://docs.neuralmagic.com/deepsparse/source/hardware.html\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached deepsparse-1.8.0.tar.gz (46.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install deepsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e530c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\ayush\\anaconda3\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnx) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnx) (5.27.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnx) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8057baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparsezoo in c:\\users\\ayush\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: onnx in c:\\users\\ayush\\anaconda3\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.24.3)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (6.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (4.65.0)\n",
      "Requirement already satisfied: pydantic~=2.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (2.8.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (8.0.4)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (5.27.3)\n",
      "Requirement already satisfied: pandas>1.3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.5.3)\n",
      "Requirement already satisfied: py-machineid>=0.3.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (0.6.0)\n",
      "Requirement already satisfied: geocoder>=1.38.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.38.1)\n",
      "Requirement already satisfied: onnxruntime>=1.0.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sparsezoo) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnx) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1.2->sparsezoo) (0.4.6)\n",
      "Requirement already satisfied: future in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (0.18.3)\n",
      "Requirement already satisfied: ratelim in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (0.1.6)\n",
      "Requirement already satisfied: six in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from geocoder>=1.38.0->sparsezoo) (1.16.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (24.3.25)\n",
      "Requirement already satisfied: packaging in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (23.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from onnxruntime>=1.0.0->sparsezoo) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas>1.3->sparsezoo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pandas>1.3->sparsezoo) (2022.7)\n",
      "Requirement already satisfied: winregistry in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from py-machineid>=0.3.0->sparsezoo) (1.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic~=2.0->sparsezoo) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from pydantic~=2.0->sparsezoo) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from requests>=2.0.0->sparsezoo) (2023.7.22)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.0.0->sparsezoo) (10.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from ratelim->geocoder>=1.38.0->sparsezoo) (5.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.0.0->sparsezoo) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\ayush\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.0.0->sparsezoo) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparsezoo onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2aef4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037b430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc91da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b160cf63",
   "metadata": {},
   "source": [
    "# Extracting Weight Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd6349d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already downloaded at: C:\\Users\\ayush\\.cache\\sparsezoo\\neuralmagic\\resnet_v1-50-imagenet-pruned95_quantized\\model.onnx\n",
      "Model downloaded at: C:\\Users\\ayush\\.cache\\sparsezoo\\neuralmagic\\resnet_v1-50-imagenet-pruned95_quantized\\model.onnx\n",
      "Layer: classifier.fc.weight\n",
      "Shape: [1000, 2048]\n",
      "Weights: [[-0.07376207  0.         -0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.12108373  0.         -0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.          0.         -0.1097383  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.0622465   0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.04466717 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.11173791  0.          0.05249852 ...  0.          0.\n",
      "   0.        ]]\n",
      "\n",
      "Calculating features for matrix with shape: (1000, 2048)\n",
      "Features for classifier.fc.weight:\n",
      "  density: 0.256699\n",
      "  nnz_min: 102\n",
      "  nnz_max: 426\n",
      "  nnz_avg: 256.699\n",
      "  nnz_sd: 45.01991113940586\n",
      "  bw_min: 1962\n",
      "  bw_max: 2045\n",
      "  bw_avg: 2030.729\n",
      "  bw_sd: 10.750700395788174\n",
      "  scatter_avg: 0.1263876357662273\n",
      "  scatter_sd: 0.02204584034081943\n",
      "  clustering_avg: 0.8753109466765577\n",
      "\n",
      "\n",
      "Layer: classifier.fc.bias\n",
      "Shape: [1000]\n",
      "Weights: [ 7.18252314e-03 -3.35752890e-02 -2.54426375e-02 -5.53644001e-02\n",
      "  2.55135354e-02  9.38738056e-04 -2.39330046e-02  2.32885536e-02\n",
      "  1.90811995e-02 -2.56391261e-02 -3.68980244e-02 -2.95577887e-02\n",
      " -5.23597188e-02 -4.46471609e-02 -1.94348060e-02 -7.67116249e-02\n",
      " -1.62826143e-02 -3.53151597e-02  8.01827945e-03 -5.56148216e-02\n",
      " -7.35835359e-03  2.75577195e-02 -4.50191014e-02  2.31478773e-02\n",
      " -1.02905752e-02 -1.07335905e-02  1.20839570e-02 -1.92321241e-02\n",
      " -1.12573886e-02 -9.69969854e-03 -2.82136071e-02 -5.64677231e-02\n",
      "  2.39614733e-02 -1.68000441e-02 -2.80344021e-02 -2.91973967e-02\n",
      "  1.98813342e-03 -2.99713574e-02  1.26113072e-02  1.50025422e-02\n",
      " -3.05243675e-02  1.44059462e-02  4.45885258e-03 -3.83385345e-02\n",
      " -1.35191705e-03 -2.20567416e-02  5.07019646e-02 -4.59993072e-02\n",
      " -1.98413655e-02 -2.05305200e-02  4.12119692e-03  8.70289747e-03\n",
      "  1.42857172e-02  1.15778521e-02  3.67412493e-02  1.10353362e-02\n",
      "  7.23943636e-02 -3.73550951e-02  1.22396071e-02  8.72210320e-03\n",
      "  1.06228481e-03 -1.00748939e-02 -4.66751158e-02  2.95599960e-02\n",
      "  9.94852465e-03  2.75000203e-02 -6.20447695e-02 -9.05926991e-03\n",
      "  1.90301444e-02 -2.22626626e-02 -4.60606515e-02  6.91799389e-04\n",
      " -5.24906740e-02 -1.32625420e-02 -1.28821023e-02 -6.67677587e-03\n",
      " -9.44978930e-03  2.55744159e-02 -2.05248203e-02  3.00132092e-02\n",
      " -5.39222173e-02 -1.22784441e-02 -2.31894213e-04 -8.62111300e-02\n",
      " -2.68924553e-02 -7.62635097e-03 -4.28134315e-02  1.85105335e-02\n",
      " -2.41977931e-03  1.06674908e-02 -8.64088815e-03 -5.19136600e-02\n",
      "  3.56456265e-03 -2.23296192e-02  5.49065042e-03 -6.60474971e-02\n",
      " -1.61871444e-02 -3.11825983e-02 -4.86312211e-02 -6.12519123e-03\n",
      " -6.24928661e-02 -9.67207626e-02 -2.58080643e-02 -3.65212560e-03\n",
      "  4.00318354e-02 -9.68517642e-03  1.73281226e-02 -4.78103720e-02\n",
      " -3.67595367e-02 -7.11713284e-02 -5.15775867e-02 -1.55462651e-04\n",
      " -2.34559998e-02  7.43837794e-03 -1.21785828e-03 -7.57032260e-02\n",
      " -8.49532336e-02 -4.24969047e-02 -1.58447362e-02  1.35268476e-02\n",
      " -2.32606437e-02 -4.51708958e-02 -2.29440629e-02 -1.46913398e-02\n",
      "  3.04570682e-02 -6.25140294e-02 -6.56374916e-02 -3.90487676e-03\n",
      " -6.96432292e-02  2.13490613e-03 -4.06113900e-02 -3.04008443e-02\n",
      " -2.13773139e-02 -4.36647087e-02 -5.68110356e-03 -9.60441232e-02\n",
      " -4.30465415e-02 -6.58730343e-02 -4.91100363e-03 -7.67589137e-02\n",
      " -5.04581332e-02 -5.32960147e-02 -9.91171896e-02 -5.84154837e-02\n",
      " -4.96176705e-02 -1.18561005e-02 -1.18424594e-02 -4.70281057e-02\n",
      " -4.53852043e-02 -2.49479003e-02  4.14768048e-02  8.40545893e-02\n",
      " -4.34954949e-02  3.09330113e-02 -1.43264281e-03 -2.50886963e-03\n",
      "  1.93428826e-02 -2.26331037e-02 -2.87499987e-02 -3.57963587e-03\n",
      "  1.04560126e-02  4.31700945e-02  9.56360549e-02  7.95878656e-03\n",
      " -3.94814182e-03 -2.34819110e-02 -5.28947078e-02 -3.92696373e-02\n",
      "  5.80184069e-03 -1.75101887e-02  4.62254882e-03  8.82908776e-02\n",
      "  3.62370309e-04  2.13797539e-02  3.42648476e-02 -3.92200239e-02\n",
      "  2.58211396e-03 -1.66405365e-02  8.28758627e-02 -1.12814736e-02\n",
      " -1.88781209e-02 -3.46457376e-03  2.91015431e-02 -8.74293793e-04\n",
      "  3.79122831e-02  2.56398655e-02 -2.69081374e-03  1.14099225e-02\n",
      "  1.08558051e-02  2.02388112e-02 -1.13598248e-02  4.51581329e-02\n",
      "  5.02934754e-02 -2.22554225e-02 -1.54850287e-02  8.21526572e-02\n",
      "  3.25333253e-02  2.77841501e-02 -4.27683517e-02  3.76325548e-02\n",
      " -2.66984049e-02  3.76363359e-02  5.06996587e-02  1.92978494e-02\n",
      "  2.92993262e-02  2.43602917e-02 -4.69399020e-02  6.70401305e-02\n",
      " -4.18688208e-02  4.75240387e-02 -5.11391312e-02  7.15624094e-02\n",
      "  2.87443548e-02 -1.83035880e-02  2.19794037e-03 -4.72385064e-03\n",
      " -2.08121594e-02  4.51373234e-02 -1.35760673e-03  2.34064385e-02\n",
      "  1.38466377e-02 -3.41475978e-02  4.69664745e-02  6.70079738e-02\n",
      "  3.09959315e-02  4.48455736e-02 -4.10200842e-02 -9.33786854e-04\n",
      " -6.26267418e-02  4.17771228e-02  1.27360746e-02 -2.33355649e-02\n",
      "  7.37845674e-02  7.66109326e-04  4.05654535e-02  1.33664580e-03\n",
      "  5.05502075e-02  1.00131258e-02  1.53546892e-02  2.38651019e-02\n",
      "  3.06969844e-02 -5.47394156e-02  7.77995167e-03 -9.16940719e-03\n",
      "  1.89756900e-02  3.04921530e-02  1.12199755e-02  1.35886585e-02\n",
      "  5.02279177e-02 -2.75633093e-02  6.18715351e-03  5.15928343e-02\n",
      "  6.72806241e-03 -5.53373769e-02  3.88861559e-02  5.95839554e-03\n",
      "  2.82084849e-02  3.04579944e-03 -9.05625336e-03 -2.79196189e-03\n",
      "  1.09035540e-02 -3.15305851e-02  5.06598502e-04  3.76044400e-02\n",
      "  2.25221459e-03  3.88893038e-02 -1.64691545e-02  1.20385932e-02\n",
      " -2.91114524e-02 -1.57873407e-02  6.07315823e-02 -1.33506795e-02\n",
      " -1.15350476e-02 -1.44823873e-02 -3.40747163e-02 -5.28748930e-02\n",
      " -1.24264611e-02 -1.82421170e-02 -3.53795849e-02  1.04816502e-03\n",
      " -4.50929217e-02  9.98730659e-02 -2.58825399e-04  2.29471084e-02\n",
      "  7.30250403e-02  2.63193194e-02 -2.46336833e-02 -5.17481901e-02\n",
      " -7.86760747e-02 -2.11611744e-02 -4.66801673e-02 -6.48021325e-02\n",
      " -7.92479329e-03 -4.52685654e-02 -6.37900131e-03  1.81171242e-02\n",
      "  7.75867840e-03 -3.76741514e-02 -3.62528749e-02  5.71768507e-02\n",
      " -4.31748889e-02  2.59982841e-03 -2.35754214e-02 -7.63369491e-03\n",
      " -5.23303961e-03  2.93258391e-02  5.72896451e-02 -2.95589939e-02\n",
      " -2.35522706e-02  1.40334275e-02  5.24822213e-02 -5.27566634e-02\n",
      "  2.49925605e-03  7.80078173e-02  6.54300600e-02  1.47509370e-02\n",
      " -6.44391915e-03 -3.86217535e-02  2.40153950e-02 -1.63859818e-02\n",
      " -2.66221892e-02 -3.52781601e-02 -7.02990666e-02 -1.26462936e-01\n",
      " -5.76088242e-02 -6.03203848e-02 -4.83171269e-02 -3.90032157e-02\n",
      " -5.29044159e-02 -1.99443530e-02 -2.41541490e-02 -3.22387815e-02\n",
      " -1.43556660e-02 -6.51989505e-03 -9.15995392e-04 -3.75830159e-02\n",
      "  4.71829921e-02 -7.45838583e-02 -6.89497450e-03 -1.79417003e-02\n",
      " -3.61990854e-02 -3.99815030e-02 -3.91314626e-02 -2.94071692e-03\n",
      " -5.64100891e-02 -1.71448458e-02  9.62358317e-04 -3.12653519e-02\n",
      "  4.34440374e-02 -5.04198596e-02  7.26737361e-03 -2.63839643e-02\n",
      " -3.99747714e-02 -1.25080459e-02  1.11960410e-03  6.48772158e-03\n",
      "  1.80673972e-02 -5.06256744e-02  6.68015843e-03  4.78780083e-02\n",
      " -9.72009730e-03  3.90928090e-02  1.08393654e-02  2.69072019e-02\n",
      " -2.41655447e-02 -1.90282054e-02 -1.25126513e-02  1.58733297e-02\n",
      " -1.92229114e-02  2.28262749e-02  2.06411108e-02 -2.73236027e-03\n",
      " -3.73267718e-02  1.90801788e-02 -4.28575091e-02 -5.53110726e-02\n",
      " -2.81658061e-02 -1.96119305e-02  1.69495363e-02  4.30671759e-02\n",
      " -5.62820248e-02 -4.12275754e-02  2.68500596e-02 -2.74690823e-03\n",
      " -3.70294154e-02 -1.97445173e-02 -1.34705119e-02 -3.40751559e-02\n",
      " -5.26524596e-02 -2.21111666e-04  1.37637963e-03  3.61619741e-02\n",
      " -4.94093448e-02 -7.72251040e-02 -1.90033335e-02  1.66870072e-03\n",
      " -4.15676348e-02 -1.61344726e-02  4.01354693e-02 -1.03045674e-02\n",
      "  1.25134201e-03  6.67084977e-02 -1.72318369e-02 -2.06429865e-02\n",
      " -7.85827115e-02  2.06377706e-03 -1.96048692e-02 -2.63981465e-02\n",
      " -6.40849695e-02 -1.07236428e-03 -8.83797649e-03 -2.62845624e-02\n",
      "  1.48672266e-02  3.59479412e-02  3.26579884e-02 -2.76954081e-02\n",
      "  4.65284027e-02 -2.21029632e-02  7.46432878e-03 -1.39408084e-02\n",
      "  3.78831215e-02 -2.13591885e-02  5.62322885e-02  5.86267002e-02\n",
      "  6.94981590e-02 -2.38715876e-02 -5.92106730e-02 -1.55608170e-02\n",
      "  5.94555363e-02  1.07580656e-02 -7.23203225e-03  7.30812969e-03\n",
      "  4.50661890e-02  2.41007283e-02 -6.30479492e-03 -1.35143874e-02\n",
      "  1.04360189e-02 -3.01969610e-02  3.84220630e-02  3.25212963e-02\n",
      "  7.22598135e-02  1.96024366e-02  1.14221154e-02 -2.51224488e-02\n",
      "  4.09753434e-03  9.41155478e-02  1.57906709e-03 -1.12730367e-02\n",
      "  5.12705594e-02 -3.46709043e-02  1.06087318e-02 -1.73651297e-02\n",
      "  4.81646135e-03 -2.24487353e-02  3.80009040e-02 -6.81480998e-03\n",
      "  6.04430027e-02  3.92024107e-02 -2.24189945e-02  1.15536554e-02\n",
      "  1.45694222e-02 -5.75081166e-03  3.05278897e-02  3.59810591e-02\n",
      "  8.00202228e-03  4.72815707e-02 -3.76380421e-02  2.42949519e-02\n",
      "  1.20599056e-02  1.42742405e-02  5.00419401e-02 -9.24104080e-03\n",
      "  3.97515483e-03  4.54452373e-02 -4.64813784e-02 -3.10748033e-02\n",
      " -3.52716148e-02  2.03381423e-02 -7.58723868e-03  1.39714675e-02\n",
      "  1.98721439e-02  1.00243418e-03  2.24602013e-03 -4.64732945e-02\n",
      " -1.99527293e-02 -2.82824412e-02  1.25206010e-02  3.59674580e-02\n",
      " -1.23603093e-02  8.74696299e-03 -3.88959795e-02  2.18318589e-02\n",
      " -1.50361294e-02 -6.19697012e-02 -4.22389898e-03  1.81827396e-02\n",
      " -7.76115805e-03 -5.49771416e-04  2.60752073e-04 -1.29214814e-02\n",
      " -5.00403717e-02 -2.16999706e-02  9.42364987e-03  4.75236103e-02\n",
      "  8.96018185e-03  6.21284265e-03  7.48377852e-03 -1.96387637e-02\n",
      "  3.07415556e-02 -3.10038831e-02 -1.62189417e-02 -3.86554957e-03\n",
      " -1.91371460e-02  8.31129029e-03  2.33932119e-02  7.33992904e-02\n",
      " -2.95728743e-02  1.68679319e-02  1.27360737e-02  2.36912686e-02\n",
      " -4.69171554e-02  3.28385048e-02  6.04082383e-02  7.49708265e-02\n",
      " -6.77611679e-02 -2.52223890e-02  4.94622476e-02  4.05777059e-02\n",
      " -1.07373716e-02  4.74860854e-02  4.73299138e-02 -8.95804726e-03\n",
      "  2.87318453e-02 -8.99193063e-03  2.92627197e-02  1.57677438e-02\n",
      " -1.50692919e-02  5.23710065e-03 -1.13173025e-02  4.81495867e-03\n",
      " -6.31845370e-02  5.46683110e-02  4.47489368e-03 -4.76999907e-03\n",
      " -4.61963005e-03 -2.85100285e-02  9.71079431e-03 -6.27861470e-02\n",
      " -3.09952330e-02 -3.50382067e-02 -9.66852810e-03 -1.72530767e-02\n",
      "  4.22357060e-02  8.31449695e-04 -9.75531153e-03 -4.16986784e-03\n",
      " -1.19959526e-02  1.97797809e-02  6.99709579e-02  1.73912924e-02\n",
      " -4.01650369e-02 -1.74527820e-02 -3.34775709e-02  1.35434708e-02\n",
      " -1.61138121e-02 -3.34889479e-02  3.80612798e-02  4.68062907e-02\n",
      "  9.99592710e-04 -8.20438657e-03 -1.80208199e-02 -7.55078811e-03\n",
      "  2.87407986e-03  1.11032994e-02  3.59008415e-03  3.11695244e-02\n",
      " -1.00749256e-02  4.04902697e-02 -2.96245608e-02  4.80153859e-02\n",
      "  9.98696778e-03 -1.26952026e-02  3.21950242e-02  1.87113956e-02\n",
      "  8.32241029e-03  1.82579178e-02 -3.68237272e-02  3.85645665e-02\n",
      "  1.11557217e-02 -7.41084758e-03  3.26175354e-02  2.26446055e-02\n",
      " -2.24832017e-02  4.72698547e-03  1.33777056e-02  3.06831580e-03\n",
      "  7.30284750e-02 -4.02840646e-03 -1.83170289e-02  1.48521727e-02\n",
      "  7.34023675e-02 -5.88973844e-03 -1.13458384e-03 -2.63605639e-03\n",
      "  1.12277623e-02  1.05784936e-02 -4.43756441e-03 -3.70421843e-03\n",
      "  5.55956513e-02  3.07583669e-03  5.19277938e-02 -1.56008536e-02\n",
      " -4.64330465e-02 -2.66356766e-02 -3.12264953e-02 -3.68946232e-02\n",
      "  3.46648344e-03 -1.48153082e-02  3.24022472e-02  4.15379135e-03\n",
      "  8.11842009e-02  2.65256073e-02  7.18272179e-02  4.96286452e-02\n",
      "  5.48841767e-02 -4.04240377e-03  2.79567614e-02  3.42612229e-02\n",
      " -3.94623950e-02  3.52562517e-02 -1.52075570e-03 -3.40998406e-03\n",
      "  3.78481932e-02  5.08220531e-02 -2.57061422e-02 -5.16868532e-02\n",
      "  2.94825598e-03  9.13268235e-03 -1.78790241e-02 -3.34328413e-02\n",
      " -2.59217098e-02 -9.67487320e-03  3.06810662e-02 -5.51861804e-03\n",
      "  3.28109190e-02 -9.48090851e-03  5.79834580e-02 -2.98684146e-02\n",
      " -1.70240309e-02 -1.74296834e-02  1.02215774e-01  1.30645987e-02\n",
      "  1.65932477e-02  1.92038517e-03  7.99818430e-03  3.46367471e-02\n",
      " -1.19268764e-02  3.57079804e-02  8.60924367e-03  1.26649905e-02\n",
      "  4.03739791e-03 -3.43470201e-02 -5.02317119e-03  6.05154503e-03\n",
      "  1.08460952e-02  4.08123992e-02  5.91660989e-03  4.78741862e-02\n",
      " -3.78397666e-02 -2.80672312e-02  7.34836794e-03  5.94040006e-02\n",
      "  3.79171111e-02  2.64575966e-02  8.18701647e-03 -4.21180502e-02\n",
      "  1.41278515e-02  6.92677051e-02  4.74152202e-03  3.85521278e-02\n",
      "  1.73177589e-02  8.65727514e-02  1.26265669e-02  5.87336160e-02\n",
      "  5.17675560e-03 -2.11613141e-02  5.66407703e-02 -3.87915671e-02\n",
      " -2.43166834e-02 -2.40829270e-02 -2.63620485e-02  1.65263796e-03\n",
      "  6.50555342e-02 -4.73239161e-02 -2.39015575e-02  2.77605113e-02\n",
      " -6.94691669e-03  6.81776553e-03 -2.49780100e-02  1.47811333e-02\n",
      "  5.19632101e-02  1.85924489e-02 -7.19528040e-03  5.62330186e-02\n",
      "  5.28199337e-02 -3.72728147e-02 -1.97530426e-02  3.47018195e-03\n",
      "  5.37778996e-03  1.25001343e-02  2.27848589e-02  5.17205968e-02\n",
      " -1.41767543e-02 -6.13405043e-03  7.80964224e-03  1.10788634e-02\n",
      "  4.21589129e-02 -4.63499017e-02  3.61028612e-02  5.14625870e-02\n",
      "  2.92032175e-02  2.30591595e-02  5.65325506e-02 -3.28253605e-03\n",
      " -3.61529738e-02 -1.09613575e-02  1.47675816e-02 -3.08924243e-02\n",
      " -3.76163120e-03 -7.34792091e-03  1.84833119e-03  5.30264452e-02\n",
      "  1.57993101e-02  2.13637650e-02 -2.25506648e-02 -9.00146006e-06\n",
      "  2.29864754e-02  3.82045493e-03  4.07092134e-03  3.41424011e-02\n",
      "  8.84944294e-03 -6.04127683e-02  5.44783426e-03  6.49418635e-03\n",
      "  1.17050260e-02  1.51906470e-02 -5.95428199e-02 -1.10818604e-02\n",
      " -6.27598912e-02  5.85517474e-02 -9.01632104e-03  1.14181759e-02\n",
      "  9.81535576e-03  2.08565919e-03  6.28305972e-02 -2.28785822e-04\n",
      "  1.81676447e-02  1.62581969e-02  2.90769301e-02  3.32247503e-02\n",
      "  1.01278303e-02  3.46255302e-02  8.51717312e-03  1.38916848e-02\n",
      "  4.82633077e-02  1.45857744e-02 -3.85787361e-03  1.61923598e-02\n",
      "  2.10691430e-02  3.53563651e-02 -1.28372638e-02 -2.43942104e-02\n",
      "  5.61800003e-02 -7.32792076e-03  6.98898137e-02 -9.25239455e-03\n",
      "  2.59297565e-02  1.88225266e-02  7.51781370e-03 -1.20307766e-02\n",
      " -1.66276023e-02 -2.44783089e-02  3.98226008e-02 -1.58417914e-02\n",
      "  2.42285361e-03  2.52601001e-02 -9.76832025e-03 -3.54923941e-02\n",
      "  3.64566371e-02 -1.71446428e-02 -4.10583951e-02  5.72980940e-02\n",
      "  2.46458948e-02  9.24526900e-03 -3.92590761e-02 -4.46979441e-02\n",
      "  2.22252104e-02 -3.17246094e-02 -3.51827778e-02  1.00899637e-02\n",
      " -3.78479809e-02  1.51417572e-02 -1.31829791e-02 -6.92027947e-03\n",
      " -1.03293499e-02 -6.75903168e-03  3.01204603e-02  2.33729109e-02\n",
      "  8.03209841e-02  8.55365992e-02 -4.39848714e-02  5.33493720e-02\n",
      " -2.09722016e-02 -1.97011512e-02 -6.77236915e-02  1.41472444e-02\n",
      "  1.90450661e-02 -2.06097197e-02 -2.00109254e-03  1.35544976e-02\n",
      " -4.84633893e-02 -2.01981496e-02  7.61209009e-03  1.24151343e-02\n",
      "  2.12957039e-02  5.62712103e-02 -2.91593652e-02 -2.73171533e-02\n",
      "  8.72116387e-02 -2.93175988e-02  1.37344506e-02  3.02623045e-02\n",
      " -2.99081951e-02 -2.03594361e-02  5.36397435e-02  1.09541323e-02\n",
      "  1.41145401e-02  2.17450317e-02  5.19333743e-02  2.01438963e-02\n",
      "  7.50182793e-02 -8.00788868e-03  1.52769331e-02  3.44349374e-03\n",
      "  3.72605883e-02  3.88972126e-02  1.75631605e-02  2.26492528e-02\n",
      " -1.62068717e-02  3.97527888e-02  6.33424073e-02  2.42178068e-02\n",
      "  1.72313824e-02 -3.30158286e-02 -2.25533079e-02  1.79457793e-03\n",
      " -1.78509206e-02 -5.53703355e-03 -1.89933623e-03  3.99752110e-02\n",
      " -1.65853593e-02  7.21108764e-02 -1.24346120e-02 -9.31166206e-03\n",
      "  7.14718504e-03  9.71256662e-03 -7.65494211e-03 -9.19356197e-02\n",
      "  6.30787089e-02 -2.08592485e-03  8.44645500e-02 -2.50285026e-02\n",
      "  1.99639127e-02 -2.46400107e-02 -7.88571835e-02  2.08795201e-02\n",
      "  6.86209723e-02  4.13607759e-03 -2.35295780e-02  9.61092338e-02\n",
      "  9.62736607e-02  1.92294605e-02  5.88646494e-02  1.53824780e-02\n",
      "  3.26471031e-03  1.67917255e-02 -4.50745374e-02 -6.86977804e-02\n",
      "  9.11436102e-04  3.50236483e-02  2.37922296e-02 -1.84588227e-02\n",
      "  3.57549600e-02 -8.89143161e-03  1.84794273e-02  1.36224013e-02\n",
      "  3.04891057e-02  5.47935218e-02  4.60833013e-02 -2.24283198e-04\n",
      " -4.13055941e-02 -1.52314594e-02  4.67741005e-02  3.02934963e-02\n",
      " -4.44836505e-02 -3.44888642e-02  1.32174082e-02  4.26353440e-02\n",
      "  2.46818573e-03  4.31754254e-02  2.32428182e-02  1.13737453e-02\n",
      " -1.88741870e-02 -6.28587883e-03 -4.62327199e-03 -3.81393805e-02\n",
      " -2.45432667e-02 -3.21821906e-02  7.44311314e-04  1.18805971e-02\n",
      "  9.69686825e-03 -3.18137882e-03 -6.13028035e-02  4.93389787e-03\n",
      " -1.89146958e-02 -3.57759707e-02 -2.90820468e-02 -2.69499775e-02\n",
      " -4.69913287e-03  4.24175747e-02  4.10904177e-02 -1.65852124e-03\n",
      " -9.72106867e-03 -1.38050057e-02  3.58997025e-02 -2.14557480e-02\n",
      "  1.71033721e-02 -1.08194230e-02 -4.15962636e-02 -1.43990088e-02\n",
      " -1.12267546e-02 -3.92261036e-02 -2.98769306e-02 -8.98843911e-03\n",
      "  1.11961563e-03  8.66461173e-03 -1.09318141e-02 -7.57734990e-03\n",
      " -7.65322894e-03  3.26664597e-02  1.83220878e-02 -1.65540446e-03\n",
      " -2.04519872e-02 -5.23281656e-03  2.29477733e-02  4.74451436e-03\n",
      " -1.11407759e-02 -4.44319658e-03  1.63205378e-02 -6.43407255e-02\n",
      "  9.52454191e-03  5.92225008e-02 -3.38344052e-02 -3.10405605e-02\n",
      " -6.21453933e-02  9.12670512e-03  5.82372062e-02  2.45300774e-02\n",
      "  5.98502439e-03  5.72335115e-03 -1.28573738e-02  5.67653999e-02\n",
      "  4.07866947e-02  1.55827403e-02 -3.03320996e-02  7.26073161e-02\n",
      " -1.05377976e-02  3.06470674e-02  2.29384787e-02 -4.85584103e-02\n",
      "  2.48145945e-02 -3.22673796e-03  1.49996914e-02  2.49914918e-02\n",
      "  1.12740118e-02 -2.53327694e-02 -5.31691350e-02 -2.55221389e-02\n",
      " -4.54499125e-02  1.46564015e-03 -2.62080170e-02 -3.44166756e-02\n",
      " -3.46586369e-02 -1.01774342e-01  1.98942982e-02  2.07052822e-03\n",
      "  9.99164674e-03 -4.23510820e-02  2.71106716e-02 -6.61292393e-03]\n",
      "\n",
      "Calculating features for matrix with shape: (1000,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1000,)\n",
      "Skipping layer classifier.fc.bias due to None values in features.\n",
      "\n",
      "Layer: 3472\n",
      "Shape: [1]\n",
      "Weights: [-1]\n",
      "\n",
      "Calculating features for matrix with shape: (1,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1,)\n",
      "Skipping layer 3472 due to None values in features.\n",
      "\n",
      "Layer: 1434\n",
      "Shape: []\n",
      "Weights: 0.01865844801068306\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1434 due to None values in features.\n",
      "\n",
      "Layer: 1435\n",
      "Shape: []\n",
      "Weights: 114\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1435 due to None values in features.\n",
      "\n",
      "Layer: 1437\n",
      "Shape: []\n",
      "Weights: 0.01865844801068306\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1437 due to None values in features.\n",
      "\n",
      "Layer: 1438\n",
      "Shape: []\n",
      "Weights: 114\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1438 due to None values in features.\n",
      "\n",
      "Layer: 1447\n",
      "Shape: []\n",
      "Weights: 0.00567022105678916\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1447 due to None values in features.\n",
      "\n",
      "Layer: 1448\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1448 due to None values in features.\n",
      "\n",
      "Layer: 1460\n",
      "Shape: []\n",
      "Weights: 0.03910059481859207\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1460 due to None values in features.\n",
      "\n",
      "Layer: 1461\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1461 due to None values in features.\n",
      "\n",
      "Layer: 1463\n",
      "Shape: []\n",
      "Weights: 0.03910059481859207\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1463 due to None values in features.\n",
      "\n",
      "Layer: 1464\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1464 due to None values in features.\n",
      "\n",
      "Layer: 1467\n",
      "Shape: []\n",
      "Weights: 0.0361940898001194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1467 due to None values in features.\n",
      "\n",
      "Layer: 1468\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1468 due to None values in features.\n",
      "\n",
      "Layer: 1470\n",
      "Shape: []\n",
      "Weights: 0.0361940898001194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1470 due to None values in features.\n",
      "\n",
      "Layer: 1471\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1471 due to None values in features.\n",
      "\n",
      "Layer: 1480\n",
      "Shape: []\n",
      "Weights: 0.0066473521292209625\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1480 due to None values in features.\n",
      "\n",
      "Layer: 1481\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1481 due to None values in features.\n",
      "\n",
      "Layer: 1499\n",
      "Shape: []\n",
      "Weights: 0.012922951020300388\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1499 due to None values in features.\n",
      "\n",
      "Layer: 1500\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1500 due to None values in features.\n",
      "\n",
      "Layer: 1502\n",
      "Shape: []\n",
      "Weights: 0.012922951020300388\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1502 due to None values in features.\n",
      "\n",
      "Layer: 1503\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1503 due to None values in features.\n",
      "\n",
      "Layer: 1512\n",
      "Shape: []\n",
      "Weights: 0.009442108683288097\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1512 due to None values in features.\n",
      "\n",
      "Layer: 1513\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1513 due to None values in features.\n",
      "\n",
      "Layer: 1531\n",
      "Shape: []\n",
      "Weights: 0.012261359952390194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1531 due to None values in features.\n",
      "\n",
      "Layer: 1532\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1532 due to None values in features.\n",
      "\n",
      "Layer: 1534\n",
      "Shape: []\n",
      "Weights: 0.012261359952390194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1534 due to None values in features.\n",
      "\n",
      "Layer: 1535\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1535 due to None values in features.\n",
      "\n",
      "Layer: 1544\n",
      "Shape: []\n",
      "Weights: 0.02422805316746235\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1544 due to None values in features.\n",
      "\n",
      "Layer: 1545\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1545 due to None values in features.\n",
      "\n",
      "Layer: 1556\n",
      "Shape: []\n",
      "Weights: 0.03030276484787464\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1556 due to None values in features.\n",
      "\n",
      "Layer: 1557\n",
      "Shape: []\n",
      "Weights: 116\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1557 due to None values in features.\n",
      "\n",
      "Layer: 1559\n",
      "Shape: []\n",
      "Weights: 0.03030276484787464\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1559 due to None values in features.\n",
      "\n",
      "Layer: 1560\n",
      "Shape: []\n",
      "Weights: 116\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1560 due to None values in features.\n",
      "\n",
      "Layer: 1565\n",
      "Shape: []\n",
      "Weights: 0.0361940898001194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1565 due to None values in features.\n",
      "\n",
      "Layer: 1566\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1566 due to None values in features.\n",
      "\n",
      "Layer: 1575\n",
      "Shape: []\n",
      "Weights: 0.012222475372254848\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1575 due to None values in features.\n",
      "\n",
      "Layer: 1576\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1576 due to None values in features.\n",
      "\n",
      "Layer: 1587\n",
      "Shape: []\n",
      "Weights: 0.061996739357709885\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1587 due to None values in features.\n",
      "\n",
      "Layer: 1588\n",
      "Shape: []\n",
      "Weights: 167\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1588 due to None values in features.\n",
      "\n",
      "Layer: 1590\n",
      "Shape: []\n",
      "Weights: 0.061996739357709885\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1590 due to None values in features.\n",
      "\n",
      "Layer: 1591\n",
      "Shape: []\n",
      "Weights: 167\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1591 due to None values in features.\n",
      "\n",
      "Layer: 1595\n",
      "Shape: []\n",
      "Weights: 0.01988856866955757\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1595 due to None values in features.\n",
      "\n",
      "Layer: 1596\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1596 due to None values in features.\n",
      "\n",
      "Layer: 1598\n",
      "Shape: []\n",
      "Weights: 0.01988856866955757\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1598 due to None values in features.\n",
      "\n",
      "Layer: 1599\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1599 due to None values in features.\n",
      "\n",
      "Layer: 1608\n",
      "Shape: []\n",
      "Weights: 0.005241308826953173\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1608 due to None values in features.\n",
      "\n",
      "Layer: 1609\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1609 due to None values in features.\n",
      "\n",
      "Layer: 1627\n",
      "Shape: []\n",
      "Weights: 0.012222596444189548\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1627 due to None values in features.\n",
      "\n",
      "Layer: 1628\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1628 due to None values in features.\n",
      "\n",
      "Layer: 1630\n",
      "Shape: []\n",
      "Weights: 0.012222596444189548\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1630 due to None values in features.\n",
      "\n",
      "Layer: 1631\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1631 due to None values in features.\n",
      "\n",
      "Layer: 1640\n",
      "Shape: []\n",
      "Weights: 0.012351949699223042\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1640 due to None values in features.\n",
      "\n",
      "Layer: 1641\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1641 due to None values in features.\n",
      "\n",
      "Layer: 1659\n",
      "Shape: []\n",
      "Weights: 0.01368731539696455\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1659 due to None values in features.\n",
      "\n",
      "Layer: 1660\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1660 due to None values in features.\n",
      "\n",
      "Layer: 1662\n",
      "Shape: []\n",
      "Weights: 0.01368731539696455\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1662 due to None values in features.\n",
      "\n",
      "Layer: 1663\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1663 due to None values in features.\n",
      "\n",
      "Layer: 1672\n",
      "Shape: []\n",
      "Weights: 0.014747146517038345\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1672 due to None values in features.\n",
      "\n",
      "Layer: 1673\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1673 due to None values in features.\n",
      "\n",
      "Layer: 1684\n",
      "Shape: []\n",
      "Weights: 0.0312546081840992\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1684 due to None values in features.\n",
      "\n",
      "Layer: 1685\n",
      "Shape: []\n",
      "Weights: 122\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1685 due to None values in features.\n",
      "\n",
      "Layer: 1687\n",
      "Shape: []\n",
      "Weights: 0.0312546081840992\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1687 due to None values in features.\n",
      "\n",
      "Layer: 1688\n",
      "Shape: []\n",
      "Weights: 122\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1688 due to None values in features.\n",
      "\n",
      "Layer: 1692\n",
      "Shape: []\n",
      "Weights: 0.0202481672167778\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1692 due to None values in features.\n",
      "\n",
      "Layer: 1693\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1693 due to None values in features.\n",
      "\n",
      "Layer: 1695\n",
      "Shape: []\n",
      "Weights: 0.0202481672167778\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1695 due to None values in features.\n",
      "\n",
      "Layer: 1696\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1696 due to None values in features.\n",
      "\n",
      "Layer: 1705\n",
      "Shape: []\n",
      "Weights: 0.0036072395741939545\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1705 due to None values in features.\n",
      "\n",
      "Layer: 1706\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1706 due to None values in features.\n",
      "\n",
      "Layer: 1724\n",
      "Shape: []\n",
      "Weights: 0.010899873450398445\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1724 due to None values in features.\n",
      "\n",
      "Layer: 1725\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1725 due to None values in features.\n",
      "\n",
      "Layer: 1727\n",
      "Shape: []\n",
      "Weights: 0.010899873450398445\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1727 due to None values in features.\n",
      "\n",
      "Layer: 1728\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1728 due to None values in features.\n",
      "\n",
      "Layer: 1737\n",
      "Shape: []\n",
      "Weights: 0.004451517481356859\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1737 due to None values in features.\n",
      "\n",
      "Layer: 1738\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1738 due to None values in features.\n",
      "\n",
      "Layer: 1756\n",
      "Shape: []\n",
      "Weights: 0.01488779578357935\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1756 due to None values in features.\n",
      "\n",
      "Layer: 1757\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1757 due to None values in features.\n",
      "\n",
      "Layer: 1759\n",
      "Shape: []\n",
      "Weights: 0.01488779578357935\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1759 due to None values in features.\n",
      "\n",
      "Layer: 1760\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1760 due to None values in features.\n",
      "\n",
      "Layer: 1769\n",
      "Shape: []\n",
      "Weights: 0.013305150903761387\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1769 due to None values in features.\n",
      "\n",
      "Layer: 1770\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1770 due to None values in features.\n",
      "\n",
      "Layer: 1781\n",
      "Shape: []\n",
      "Weights: 0.03478843346238136\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1781 due to None values in features.\n",
      "\n",
      "Layer: 1782\n",
      "Shape: []\n",
      "Weights: 118\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1782 due to None values in features.\n",
      "\n",
      "Layer: 1784\n",
      "Shape: []\n",
      "Weights: 0.03478843346238136\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1784 due to None values in features.\n",
      "\n",
      "Layer: 1785\n",
      "Shape: []\n",
      "Weights: 118\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1785 due to None values in features.\n",
      "\n",
      "Layer: 1789\n",
      "Shape: []\n",
      "Weights: 0.020523421466350555\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1789 due to None values in features.\n",
      "\n",
      "Layer: 1790\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1790 due to None values in features.\n",
      "\n",
      "Layer: 1792\n",
      "Shape: []\n",
      "Weights: 0.020523421466350555\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1792 due to None values in features.\n",
      "\n",
      "Layer: 1793\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1793 due to None values in features.\n",
      "\n",
      "Layer: 1802\n",
      "Shape: []\n",
      "Weights: 0.005150899291038513\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1802 due to None values in features.\n",
      "\n",
      "Layer: 1803\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1803 due to None values in features.\n",
      "\n",
      "Layer: 1821\n",
      "Shape: []\n",
      "Weights: 0.014863738790154457\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1821 due to None values in features.\n",
      "\n",
      "Layer: 1822\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1822 due to None values in features.\n",
      "\n",
      "Layer: 1824\n",
      "Shape: []\n",
      "Weights: 0.014863738790154457\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1824 due to None values in features.\n",
      "\n",
      "Layer: 1825\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1825 due to None values in features.\n",
      "\n",
      "Layer: 1834\n",
      "Shape: []\n",
      "Weights: 0.0040792301297187805\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1834 due to None values in features.\n",
      "\n",
      "Layer: 1835\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1835 due to None values in features.\n",
      "\n",
      "Layer: 1853\n",
      "Shape: []\n",
      "Weights: 0.015159571543335915\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1853 due to None values in features.\n",
      "\n",
      "Layer: 1854\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1854 due to None values in features.\n",
      "\n",
      "Layer: 1856\n",
      "Shape: []\n",
      "Weights: 0.015159571543335915\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1856 due to None values in features.\n",
      "\n",
      "Layer: 1857\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1857 due to None values in features.\n",
      "\n",
      "Layer: 1866\n",
      "Shape: []\n",
      "Weights: 0.010431467555463314\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1866 due to None values in features.\n",
      "\n",
      "Layer: 1867\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1867 due to None values in features.\n",
      "\n",
      "Layer: 1878\n",
      "Shape: []\n",
      "Weights: 0.040702689439058304\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1878 due to None values in features.\n",
      "\n",
      "Layer: 1879\n",
      "Shape: []\n",
      "Weights: 119\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1879 due to None values in features.\n",
      "\n",
      "Layer: 1881\n",
      "Shape: []\n",
      "Weights: 0.040702689439058304\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1881 due to None values in features.\n",
      "\n",
      "Layer: 1882\n",
      "Shape: []\n",
      "Weights: 119\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1882 due to None values in features.\n",
      "\n",
      "Layer: 1887\n",
      "Shape: []\n",
      "Weights: 0.020523421466350555\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1887 due to None values in features.\n",
      "\n",
      "Layer: 1888\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1888 due to None values in features.\n",
      "\n",
      "Layer: 1897\n",
      "Shape: []\n",
      "Weights: 0.008742017671465874\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1897 due to None values in features.\n",
      "\n",
      "Layer: 1898\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1898 due to None values in features.\n",
      "\n",
      "Layer: 1909\n",
      "Shape: []\n",
      "Weights: 0.03200716897845268\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1909 due to None values in features.\n",
      "\n",
      "Layer: 1910\n",
      "Shape: []\n",
      "Weights: 134\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1910 due to None values in features.\n",
      "\n",
      "Layer: 1912\n",
      "Shape: []\n",
      "Weights: 0.03200716897845268\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1912 due to None values in features.\n",
      "\n",
      "Layer: 1913\n",
      "Shape: []\n",
      "Weights: 134\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1913 due to None values in features.\n",
      "\n",
      "Layer: 1917\n",
      "Shape: []\n",
      "Weights: 0.020077086985111237\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1917 due to None values in features.\n",
      "\n",
      "Layer: 1918\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1918 due to None values in features.\n",
      "\n",
      "Layer: 1920\n",
      "Shape: []\n",
      "Weights: 0.020077086985111237\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1920 due to None values in features.\n",
      "\n",
      "Layer: 1921\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1921 due to None values in features.\n",
      "\n",
      "Layer: 1930\n",
      "Shape: []\n",
      "Weights: 0.003907517530024052\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1930 due to None values in features.\n",
      "\n",
      "Layer: 1931\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1931 due to None values in features.\n",
      "\n",
      "Layer: 1949\n",
      "Shape: []\n",
      "Weights: 0.012288946658372879\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1949 due to None values in features.\n",
      "\n",
      "Layer: 1950\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1950 due to None values in features.\n",
      "\n",
      "Layer: 1952\n",
      "Shape: []\n",
      "Weights: 0.012288946658372879\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1952 due to None values in features.\n",
      "\n",
      "Layer: 1953\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1953 due to None values in features.\n",
      "\n",
      "Layer: 1962\n",
      "Shape: []\n",
      "Weights: 0.006447591353207827\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1962 due to None values in features.\n",
      "\n",
      "Layer: 1963\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1963 due to None values in features.\n",
      "\n",
      "Layer: 1981\n",
      "Shape: []\n",
      "Weights: 0.010088304989039898\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1981 due to None values in features.\n",
      "\n",
      "Layer: 1982\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1982 due to None values in features.\n",
      "\n",
      "Layer: 1984\n",
      "Shape: []\n",
      "Weights: 0.010088304989039898\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1984 due to None values in features.\n",
      "\n",
      "Layer: 1985\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1985 due to None values in features.\n",
      "\n",
      "Layer: 1994\n",
      "Shape: []\n",
      "Weights: 0.013118315488100052\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1994 due to None values in features.\n",
      "\n",
      "Layer: 1995\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1995 due to None values in features.\n",
      "\n",
      "Layer: 2006\n",
      "Shape: []\n",
      "Weights: 0.03194914758205414\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2006 due to None values in features.\n",
      "\n",
      "Layer: 2007\n",
      "Shape: []\n",
      "Weights: 137\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2007 due to None values in features.\n",
      "\n",
      "Layer: 2009\n",
      "Shape: []\n",
      "Weights: 0.03194914758205414\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2009 due to None values in features.\n",
      "\n",
      "Layer: 2010\n",
      "Shape: []\n",
      "Weights: 137\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2010 due to None values in features.\n",
      "\n",
      "Layer: 2014\n",
      "Shape: []\n",
      "Weights: 0.020067740231752396\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2014 due to None values in features.\n",
      "\n",
      "Layer: 2015\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2015 due to None values in features.\n",
      "\n",
      "Layer: 2017\n",
      "Shape: []\n",
      "Weights: 0.020067740231752396\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2017 due to None values in features.\n",
      "\n",
      "Layer: 2018\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2018 due to None values in features.\n",
      "\n",
      "Layer: 2027\n",
      "Shape: []\n",
      "Weights: 0.004059488885104656\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2027 due to None values in features.\n",
      "\n",
      "Layer: 2028\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2028 due to None values in features.\n",
      "\n",
      "Layer: 2046\n",
      "Shape: []\n",
      "Weights: 0.010174835100769997\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2046 due to None values in features.\n",
      "\n",
      "Layer: 2047\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2047 due to None values in features.\n",
      "\n",
      "Layer: 2049\n",
      "Shape: []\n",
      "Weights: 0.010174835100769997\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2049 due to None values in features.\n",
      "\n",
      "Layer: 2050\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2050 due to None values in features.\n",
      "\n",
      "Layer: 2059\n",
      "Shape: []\n",
      "Weights: 0.004587771836668253\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2059 due to None values in features.\n",
      "\n",
      "Layer: 2060\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2060 due to None values in features.\n",
      "\n",
      "Layer: 2078\n",
      "Shape: []\n",
      "Weights: 0.009026981890201569\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2078 due to None values in features.\n",
      "\n",
      "Layer: 2079\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2079 due to None values in features.\n",
      "\n",
      "Layer: 2081\n",
      "Shape: []\n",
      "Weights: 0.009026981890201569\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2081 due to None values in features.\n",
      "\n",
      "Layer: 2082\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2082 due to None values in features.\n",
      "\n",
      "Layer: 2091\n",
      "Shape: []\n",
      "Weights: 0.016838977113366127\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2091 due to None values in features.\n",
      "\n",
      "Layer: 2092\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2092 due to None values in features.\n",
      "\n",
      "Layer: 2103\n",
      "Shape: []\n",
      "Weights: 0.02368021011352539\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2103 due to None values in features.\n",
      "\n",
      "Layer: 2104\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2104 due to None values in features.\n",
      "\n",
      "Layer: 2106\n",
      "Shape: []\n",
      "Weights: 0.02368021011352539\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2106 due to None values in features.\n",
      "\n",
      "Layer: 2107\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2107 due to None values in features.\n",
      "\n",
      "Layer: 2111\n",
      "Shape: []\n",
      "Weights: 0.020254865288734436\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2111 due to None values in features.\n",
      "\n",
      "Layer: 2112\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2112 due to None values in features.\n",
      "\n",
      "Layer: 2114\n",
      "Shape: []\n",
      "Weights: 0.020254865288734436\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2114 due to None values in features.\n",
      "\n",
      "Layer: 2115\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2115 due to None values in features.\n",
      "\n",
      "Layer: 2124\n",
      "Shape: []\n",
      "Weights: 0.004223905503749847\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2124 due to None values in features.\n",
      "\n",
      "Layer: 2125\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2125 due to None values in features.\n",
      "\n",
      "Layer: 2143\n",
      "Shape: []\n",
      "Weights: 0.013323213905096054\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2143 due to None values in features.\n",
      "\n",
      "Layer: 2144\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2144 due to None values in features.\n",
      "\n",
      "Layer: 2146\n",
      "Shape: []\n",
      "Weights: 0.013323213905096054\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2146 due to None values in features.\n",
      "\n",
      "Layer: 2147\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2147 due to None values in features.\n",
      "\n",
      "Layer: 2156\n",
      "Shape: []\n",
      "Weights: 0.0067950086668133736\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2156 due to None values in features.\n",
      "\n",
      "Layer: 2157\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2157 due to None values in features.\n",
      "\n",
      "Layer: 2175\n",
      "Shape: []\n",
      "Weights: 0.015611949376761913\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2175 due to None values in features.\n",
      "\n",
      "Layer: 2176\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2176 due to None values in features.\n",
      "\n",
      "Layer: 2178\n",
      "Shape: []\n",
      "Weights: 0.015611949376761913\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2178 due to None values in features.\n",
      "\n",
      "Layer: 2179\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2179 due to None values in features.\n",
      "\n",
      "Layer: 2188\n",
      "Shape: []\n",
      "Weights: 0.012558857910335064\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2188 due to None values in features.\n",
      "\n",
      "Layer: 2189\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2189 due to None values in features.\n",
      "\n",
      "Layer: 2200\n",
      "Shape: []\n",
      "Weights: 0.03191070258617401\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2200 due to None values in features.\n",
      "\n",
      "Layer: 2201\n",
      "Shape: []\n",
      "Weights: 127\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2201 due to None values in features.\n",
      "\n",
      "Layer: 2203\n",
      "Shape: []\n",
      "Weights: 0.03191070258617401\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2203 due to None values in features.\n",
      "\n",
      "Layer: 2204\n",
      "Shape: []\n",
      "Weights: 127\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2204 due to None values in features.\n",
      "\n",
      "Layer: 2208\n",
      "Shape: []\n",
      "Weights: 0.02121044509112835\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2208 due to None values in features.\n",
      "\n",
      "Layer: 2209\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2209 due to None values in features.\n",
      "\n",
      "Layer: 2211\n",
      "Shape: []\n",
      "Weights: 0.02121044509112835\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2211 due to None values in features.\n",
      "\n",
      "Layer: 2212\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2212 due to None values in features.\n",
      "\n",
      "Layer: 2221\n",
      "Shape: []\n",
      "Weights: 0.004706465173512697\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2221 due to None values in features.\n",
      "\n",
      "Layer: 2222\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2222 due to None values in features.\n",
      "\n",
      "Layer: 2240\n",
      "Shape: []\n",
      "Weights: 0.01830819435417652\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2240 due to None values in features.\n",
      "\n",
      "Layer: 2241\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2241 due to None values in features.\n",
      "\n",
      "Layer: 2243\n",
      "Shape: []\n",
      "Weights: 0.01830819435417652\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2243 due to None values in features.\n",
      "\n",
      "Layer: 2244\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2244 due to None values in features.\n",
      "\n",
      "Layer: 2253\n",
      "Shape: []\n",
      "Weights: 0.005518306512385607\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2253 due to None values in features.\n",
      "\n",
      "Layer: 2254\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2254 due to None values in features.\n",
      "\n",
      "Layer: 2272\n",
      "Shape: []\n",
      "Weights: 0.01563587784767151\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2272 due to None values in features.\n",
      "\n",
      "Layer: 2273\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2273 due to None values in features.\n",
      "\n",
      "Layer: 2275\n",
      "Shape: []\n",
      "Weights: 0.01563587784767151\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2275 due to None values in features.\n",
      "\n",
      "Layer: 2276\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2276 due to None values in features.\n",
      "\n",
      "Layer: 2285\n",
      "Shape: []\n",
      "Weights: 0.009911837987601757\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2285 due to None values in features.\n",
      "\n",
      "Layer: 2286\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2286 due to None values in features.\n",
      "\n",
      "Layer: 2297\n",
      "Shape: []\n",
      "Weights: 0.03300054371356964\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2297 due to None values in features.\n",
      "\n",
      "Layer: 2298\n",
      "Shape: []\n",
      "Weights: 110\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2298 due to None values in features.\n",
      "\n",
      "Layer: 2300\n",
      "Shape: []\n",
      "Weights: 0.03300054371356964\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2300 due to None values in features.\n",
      "\n",
      "Layer: 2301\n",
      "Shape: []\n",
      "Weights: 110\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2301 due to None values in features.\n",
      "\n",
      "Layer: 2306\n",
      "Shape: []\n",
      "Weights: 0.02121044509112835\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2306 due to None values in features.\n",
      "\n",
      "Layer: 2307\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2307 due to None values in features.\n",
      "\n",
      "Layer: 2316\n",
      "Shape: []\n",
      "Weights: 0.006101401522755623\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2316 due to None values in features.\n",
      "\n",
      "Layer: 2317\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2317 due to None values in features.\n",
      "\n",
      "Layer: 2328\n",
      "Shape: []\n",
      "Weights: 0.020790493115782738\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2328 due to None values in features.\n",
      "\n",
      "Layer: 2329\n",
      "Shape: []\n",
      "Weights: 130\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2329 due to None values in features.\n",
      "\n",
      "Layer: 2331\n",
      "Shape: []\n",
      "Weights: 0.020790493115782738\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2331 due to None values in features.\n",
      "\n",
      "Layer: 2332\n",
      "Shape: []\n",
      "Weights: 130\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2332 due to None values in features.\n",
      "\n",
      "Layer: 2336\n",
      "Shape: []\n",
      "Weights: 0.018750697374343872\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2336 due to None values in features.\n",
      "\n",
      "Layer: 2337\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2337 due to None values in features.\n",
      "\n",
      "Layer: 2339\n",
      "Shape: []\n",
      "Weights: 0.018750697374343872\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2339 due to None values in features.\n",
      "\n",
      "Layer: 2340\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2340 due to None values in features.\n",
      "\n",
      "Layer: 2349\n",
      "Shape: []\n",
      "Weights: 0.004609429743140936\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2349 due to None values in features.\n",
      "\n",
      "Layer: 2350\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2350 due to None values in features.\n",
      "\n",
      "Layer: 2368\n",
      "Shape: []\n",
      "Weights: 0.011240735650062561\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2368 due to None values in features.\n",
      "\n",
      "Layer: 2369\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2369 due to None values in features.\n",
      "\n",
      "Layer: 2371\n",
      "Shape: []\n",
      "Weights: 0.011240735650062561\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2371 due to None values in features.\n",
      "\n",
      "Layer: 2372\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2372 due to None values in features.\n",
      "\n",
      "Layer: 2381\n",
      "Shape: []\n",
      "Weights: 0.0056183780543506145\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2381 due to None values in features.\n",
      "\n",
      "Layer: 2382\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2382 due to None values in features.\n",
      "\n",
      "Layer: 2400\n",
      "Shape: []\n",
      "Weights: 0.00906610768288374\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2400 due to None values in features.\n",
      "\n",
      "Layer: 2401\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2401 due to None values in features.\n",
      "\n",
      "Layer: 2403\n",
      "Shape: []\n",
      "Weights: 0.00906610768288374\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2403 due to None values in features.\n",
      "\n",
      "Layer: 2404\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2404 due to None values in features.\n",
      "\n",
      "Layer: 2413\n",
      "Shape: []\n",
      "Weights: 0.012480415403842926\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2413 due to None values in features.\n",
      "\n",
      "Layer: 2414\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2414 due to None values in features.\n",
      "\n",
      "Layer: 2425\n",
      "Shape: []\n",
      "Weights: 0.02161179855465889\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2425 due to None values in features.\n",
      "\n",
      "Layer: 2426\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2426 due to None values in features.\n",
      "\n",
      "Layer: 2428\n",
      "Shape: []\n",
      "Weights: 0.02161179855465889\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2428 due to None values in features.\n",
      "\n",
      "Layer: 2429\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2429 due to None values in features.\n",
      "\n",
      "Layer: 2433\n",
      "Shape: []\n",
      "Weights: 0.01850701868534088\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2433 due to None values in features.\n",
      "\n",
      "Layer: 2434\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2434 due to None values in features.\n",
      "\n",
      "Layer: 2436\n",
      "Shape: []\n",
      "Weights: 0.01850701868534088\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2436 due to None values in features.\n",
      "\n",
      "Layer: 2437\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2437 due to None values in features.\n",
      "\n",
      "Layer: 2446\n",
      "Shape: []\n",
      "Weights: 0.005575810093432665\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2446 due to None values in features.\n",
      "\n",
      "Layer: 2447\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2447 due to None values in features.\n",
      "\n",
      "Layer: 2465\n",
      "Shape: []\n",
      "Weights: 0.012343227863311768\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2465 due to None values in features.\n",
      "\n",
      "Layer: 2466\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2466 due to None values in features.\n",
      "\n",
      "Layer: 2468\n",
      "Shape: []\n",
      "Weights: 0.012343227863311768\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2468 due to None values in features.\n",
      "\n",
      "Layer: 2469\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2469 due to None values in features.\n",
      "\n",
      "Layer: 2478\n",
      "Shape: []\n",
      "Weights: 0.005385005846619606\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2478 due to None values in features.\n",
      "\n",
      "Layer: 2479\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2479 due to None values in features.\n",
      "\n",
      "Layer: 2497\n",
      "Shape: []\n",
      "Weights: 0.009310737252235413\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2497 due to None values in features.\n",
      "\n",
      "Layer: 2498\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2498 due to None values in features.\n",
      "\n",
      "Layer: 2500\n",
      "Shape: []\n",
      "Weights: 0.009310737252235413\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2500 due to None values in features.\n",
      "\n",
      "Layer: 2501\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2501 due to None values in features.\n",
      "\n",
      "Layer: 2510\n",
      "Shape: []\n",
      "Weights: 0.014936915598809719\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2510 due to None values in features.\n",
      "\n",
      "Layer: 2511\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2511 due to None values in features.\n",
      "\n",
      "Layer: 2522\n",
      "Shape: []\n",
      "Weights: 0.020829617977142334\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2522 due to None values in features.\n",
      "\n",
      "Layer: 2523\n",
      "Shape: []\n",
      "Weights: 122\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2523 due to None values in features.\n",
      "\n",
      "Layer: 2525\n",
      "Shape: []\n",
      "Weights: 0.020829617977142334\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2525 due to None values in features.\n",
      "\n",
      "Layer: 2526\n",
      "Shape: []\n",
      "Weights: 122\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2526 due to None values in features.\n",
      "\n",
      "Layer: 2530\n",
      "Shape: []\n",
      "Weights: 0.021444648504257202\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2530 due to None values in features.\n",
      "\n",
      "Layer: 2531\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2531 due to None values in features.\n",
      "\n",
      "Layer: 2533\n",
      "Shape: []\n",
      "Weights: 0.021444648504257202\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2533 due to None values in features.\n",
      "\n",
      "Layer: 2534\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2534 due to None values in features.\n",
      "\n",
      "Layer: 2543\n",
      "Shape: []\n",
      "Weights: 0.004710350651293993\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2543 due to None values in features.\n",
      "\n",
      "Layer: 2544\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2544 due to None values in features.\n",
      "\n",
      "Layer: 2562\n",
      "Shape: []\n",
      "Weights: 0.012271774932742119\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2562 due to None values in features.\n",
      "\n",
      "Layer: 2563\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2563 due to None values in features.\n",
      "\n",
      "Layer: 2565\n",
      "Shape: []\n",
      "Weights: 0.012271774932742119\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2565 due to None values in features.\n",
      "\n",
      "Layer: 2566\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2566 due to None values in features.\n",
      "\n",
      "Layer: 2575\n",
      "Shape: []\n",
      "Weights: 0.005423147231340408\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2575 due to None values in features.\n",
      "\n",
      "Layer: 2576\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2576 due to None values in features.\n",
      "\n",
      "Layer: 2594\n",
      "Shape: []\n",
      "Weights: 0.011694968678057194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2594 due to None values in features.\n",
      "\n",
      "Layer: 2595\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2595 due to None values in features.\n",
      "\n",
      "Layer: 2597\n",
      "Shape: []\n",
      "Weights: 0.011694968678057194\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2597 due to None values in features.\n",
      "\n",
      "Layer: 2598\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2598 due to None values in features.\n",
      "\n",
      "Layer: 2607\n",
      "Shape: []\n",
      "Weights: 0.012898032553493977\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2607 due to None values in features.\n",
      "\n",
      "Layer: 2608\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2608 due to None values in features.\n",
      "\n",
      "Layer: 2619\n",
      "Shape: []\n",
      "Weights: 0.02359146997332573\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2619 due to None values in features.\n",
      "\n",
      "Layer: 2620\n",
      "Shape: []\n",
      "Weights: 118\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2620 due to None values in features.\n",
      "\n",
      "Layer: 2622\n",
      "Shape: []\n",
      "Weights: 0.02359146997332573\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2622 due to None values in features.\n",
      "\n",
      "Layer: 2623\n",
      "Shape: []\n",
      "Weights: 118\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2623 due to None values in features.\n",
      "\n",
      "Layer: 2627\n",
      "Shape: []\n",
      "Weights: 0.027397124096751213\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2627 due to None values in features.\n",
      "\n",
      "Layer: 2628\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2628 due to None values in features.\n",
      "\n",
      "Layer: 2630\n",
      "Shape: []\n",
      "Weights: 0.027397124096751213\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2630 due to None values in features.\n",
      "\n",
      "Layer: 2631\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2631 due to None values in features.\n",
      "\n",
      "Layer: 2640\n",
      "Shape: []\n",
      "Weights: 0.004805619362741709\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2640 due to None values in features.\n",
      "\n",
      "Layer: 2641\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2641 due to None values in features.\n",
      "\n",
      "Layer: 2659\n",
      "Shape: []\n",
      "Weights: 0.012544154189527035\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2659 due to None values in features.\n",
      "\n",
      "Layer: 2660\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2660 due to None values in features.\n",
      "\n",
      "Layer: 2662\n",
      "Shape: []\n",
      "Weights: 0.012544154189527035\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2662 due to None values in features.\n",
      "\n",
      "Layer: 2663\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2663 due to None values in features.\n",
      "\n",
      "Layer: 2672\n",
      "Shape: []\n",
      "Weights: 0.006875053513795137\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2672 due to None values in features.\n",
      "\n",
      "Layer: 2673\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2673 due to None values in features.\n",
      "\n",
      "Layer: 2691\n",
      "Shape: []\n",
      "Weights: 0.0121503546833992\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2691 due to None values in features.\n",
      "\n",
      "Layer: 2692\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2692 due to None values in features.\n",
      "\n",
      "Layer: 2694\n",
      "Shape: []\n",
      "Weights: 0.0121503546833992\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2694 due to None values in features.\n",
      "\n",
      "Layer: 2695\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2695 due to None values in features.\n",
      "\n",
      "Layer: 2704\n",
      "Shape: []\n",
      "Weights: 0.014904658310115337\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2704 due to None values in features.\n",
      "\n",
      "Layer: 2705\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2705 due to None values in features.\n",
      "\n",
      "Layer: 2716\n",
      "Shape: []\n",
      "Weights: 0.03194286674261093\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2716 due to None values in features.\n",
      "\n",
      "Layer: 2717\n",
      "Shape: []\n",
      "Weights: 98\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2717 due to None values in features.\n",
      "\n",
      "Layer: 2719\n",
      "Shape: []\n",
      "Weights: 0.03194286674261093\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2719 due to None values in features.\n",
      "\n",
      "Layer: 2720\n",
      "Shape: []\n",
      "Weights: 98\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2720 due to None values in features.\n",
      "\n",
      "Layer: 2724\n",
      "Shape: []\n",
      "Weights: 0.026211606338620186\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2724 due to None values in features.\n",
      "\n",
      "Layer: 2725\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2725 due to None values in features.\n",
      "\n",
      "Layer: 2727\n",
      "Shape: []\n",
      "Weights: 0.026211606338620186\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2727 due to None values in features.\n",
      "\n",
      "Layer: 2728\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2728 due to None values in features.\n",
      "\n",
      "Layer: 2737\n",
      "Shape: []\n",
      "Weights: 0.004537357483059168\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2737 due to None values in features.\n",
      "\n",
      "Layer: 2738\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2738 due to None values in features.\n",
      "\n",
      "Layer: 2756\n",
      "Shape: []\n",
      "Weights: 0.016443835571408272\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2756 due to None values in features.\n",
      "\n",
      "Layer: 2757\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2757 due to None values in features.\n",
      "\n",
      "Layer: 2759\n",
      "Shape: []\n",
      "Weights: 0.016443835571408272\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2759 due to None values in features.\n",
      "\n",
      "Layer: 2760\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2760 due to None values in features.\n",
      "\n",
      "Layer: 2769\n",
      "Shape: []\n",
      "Weights: 0.007936165668070316\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2769 due to None values in features.\n",
      "\n",
      "Layer: 2770\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2770 due to None values in features.\n",
      "\n",
      "Layer: 2788\n",
      "Shape: []\n",
      "Weights: 0.031183231621980667\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2788 due to None values in features.\n",
      "\n",
      "Layer: 2789\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2789 due to None values in features.\n",
      "\n",
      "Layer: 2791\n",
      "Shape: []\n",
      "Weights: 0.031183231621980667\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2791 due to None values in features.\n",
      "\n",
      "Layer: 2792\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2792 due to None values in features.\n",
      "\n",
      "Layer: 2801\n",
      "Shape: []\n",
      "Weights: 0.012595717795193195\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2801 due to None values in features.\n",
      "\n",
      "Layer: 2802\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2802 due to None values in features.\n",
      "\n",
      "Layer: 2813\n",
      "Shape: []\n",
      "Weights: 0.03574642166495323\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2813 due to None values in features.\n",
      "\n",
      "Layer: 2814\n",
      "Shape: []\n",
      "Weights: 149\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2814 due to None values in features.\n",
      "\n",
      "Layer: 2816\n",
      "Shape: []\n",
      "Weights: 0.03574642166495323\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2816 due to None values in features.\n",
      "\n",
      "Layer: 2817\n",
      "Shape: []\n",
      "Weights: 149\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2817 due to None values in features.\n",
      "\n",
      "Layer: 2821\n",
      "Shape: []\n",
      "Weights: 0.020318450406193733\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2821 due to None values in features.\n",
      "\n",
      "Layer: 2822\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2822 due to None values in features.\n",
      "\n",
      "Layer: 2824\n",
      "Shape: []\n",
      "Weights: 0.020318450406193733\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2824 due to None values in features.\n",
      "\n",
      "Layer: 2825\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2825 due to None values in features.\n",
      "\n",
      "Layer: 2834\n",
      "Shape: []\n",
      "Weights: 0.0042139324359595776\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2834 due to None values in features.\n",
      "\n",
      "Layer: 2835\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2835 due to None values in features.\n",
      "\n",
      "Layer: 2853\n",
      "Shape: []\n",
      "Weights: 0.009938192553818226\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2853 due to None values in features.\n",
      "\n",
      "Layer: 2854\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2854 due to None values in features.\n",
      "\n",
      "Layer: 2856\n",
      "Shape: []\n",
      "Weights: 0.009938192553818226\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2856 due to None values in features.\n",
      "\n",
      "Layer: 2857\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2857 due to None values in features.\n",
      "\n",
      "Layer: 2866\n",
      "Shape: []\n",
      "Weights: 0.020041121169924736\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2866 due to None values in features.\n",
      "\n",
      "Layer: 2867\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2867 due to None values in features.\n",
      "\n",
      "Layer: 2885\n",
      "Shape: []\n",
      "Weights: 0.024274015799164772\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2885 due to None values in features.\n",
      "\n",
      "Layer: 2886\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2886 due to None values in features.\n",
      "\n",
      "Layer: 2888\n",
      "Shape: []\n",
      "Weights: 0.024274015799164772\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2888 due to None values in features.\n",
      "\n",
      "Layer: 2889\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2889 due to None values in features.\n",
      "\n",
      "Layer: 2898\n",
      "Shape: []\n",
      "Weights: 0.052959803491830826\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2898 due to None values in features.\n",
      "\n",
      "Layer: 2899\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2899 due to None values in features.\n",
      "\n",
      "Layer: 2910\n",
      "Shape: []\n",
      "Weights: 0.16136522591114044\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2910 due to None values in features.\n",
      "\n",
      "Layer: 2911\n",
      "Shape: []\n",
      "Weights: 66\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2911 due to None values in features.\n",
      "\n",
      "Layer: 2913\n",
      "Shape: []\n",
      "Weights: 0.16136522591114044\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2913 due to None values in features.\n",
      "\n",
      "Layer: 2914\n",
      "Shape: []\n",
      "Weights: 66\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2914 due to None values in features.\n",
      "\n",
      "Layer: 2919\n",
      "Shape: []\n",
      "Weights: 0.020318450406193733\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2919 due to None values in features.\n",
      "\n",
      "Layer: 2920\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2920 due to None values in features.\n",
      "\n",
      "Layer: 2929\n",
      "Shape: []\n",
      "Weights: 0.07489582151174545\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2929 due to None values in features.\n",
      "\n",
      "Layer: 2930\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2930 due to None values in features.\n",
      "\n",
      "Layer: 2941\n",
      "Shape: []\n",
      "Weights: 0.16670407354831696\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2941 due to None values in features.\n",
      "\n",
      "Layer: 2942\n",
      "Shape: []\n",
      "Weights: 50\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2942 due to None values in features.\n",
      "\n",
      "Layer: 2944\n",
      "Shape: []\n",
      "Weights: 0.16670407354831696\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2944 due to None values in features.\n",
      "\n",
      "Layer: 2945\n",
      "Shape: []\n",
      "Weights: 50\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2945 due to None values in features.\n",
      "\n",
      "Layer: 2949\n",
      "Shape: []\n",
      "Weights: 0.16626794636249542\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2949 due to None values in features.\n",
      "\n",
      "Layer: 2950\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2950 due to None values in features.\n",
      "\n",
      "Layer: 2952\n",
      "Shape: []\n",
      "Weights: 0.16626794636249542\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2952 due to None values in features.\n",
      "\n",
      "Layer: 2953\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2953 due to None values in features.\n",
      "\n",
      "Layer: 2962\n",
      "Shape: []\n",
      "Weights: 0.0020797147881239653\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2962 due to None values in features.\n",
      "\n",
      "Layer: 2963\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2963 due to None values in features.\n",
      "\n",
      "Layer: 2981\n",
      "Shape: []\n",
      "Weights: 0.014613630250096321\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2981 due to None values in features.\n",
      "\n",
      "Layer: 2982\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2982 due to None values in features.\n",
      "\n",
      "Layer: 2984\n",
      "Shape: []\n",
      "Weights: 0.014613630250096321\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2984 due to None values in features.\n",
      "\n",
      "Layer: 2985\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2985 due to None values in features.\n",
      "\n",
      "Layer: 2994\n",
      "Shape: []\n",
      "Weights: 0.008441464975476265\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2994 due to None values in features.\n",
      "\n",
      "Layer: 2995\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2995 due to None values in features.\n",
      "\n",
      "Layer: 3013\n",
      "Shape: []\n",
      "Weights: 0.009625321254134178\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3013 due to None values in features.\n",
      "\n",
      "Layer: 3014\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3014 due to None values in features.\n",
      "\n",
      "Layer: 3016\n",
      "Shape: []\n",
      "Weights: 0.009625321254134178\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3016 due to None values in features.\n",
      "\n",
      "Layer: 3017\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3017 due to None values in features.\n",
      "\n",
      "Layer: 3026\n",
      "Shape: []\n",
      "Weights: 0.09111443907022476\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3026 due to None values in features.\n",
      "\n",
      "Layer: 3027\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3027 due to None values in features.\n",
      "\n",
      "Layer: 3038\n",
      "Shape: []\n",
      "Weights: 0.1017606258392334\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3038 due to None values in features.\n",
      "\n",
      "Layer: 3039\n",
      "Shape: []\n",
      "Weights: 83\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3039 due to None values in features.\n",
      "\n",
      "Layer: 3041\n",
      "Shape: []\n",
      "Weights: 0.1017606258392334\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3041 due to None values in features.\n",
      "\n",
      "Layer: 3042\n",
      "Shape: []\n",
      "Weights: 83\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3042 due to None values in features.\n",
      "\n",
      "Layer: 3046\n",
      "Shape: []\n",
      "Weights: 0.16612936556339264\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3046 due to None values in features.\n",
      "\n",
      "Layer: 3047\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3047 due to None values in features.\n",
      "\n",
      "Layer: 3049\n",
      "Shape: []\n",
      "Weights: 0.16612936556339264\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3049 due to None values in features.\n",
      "\n",
      "Layer: 3050\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3050 due to None values in features.\n",
      "\n",
      "Layer: 3059\n",
      "Shape: []\n",
      "Weights: 0.0018061957089230418\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3059 due to None values in features.\n",
      "\n",
      "Layer: 3060\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3060 due to None values in features.\n",
      "\n",
      "Layer: 3078\n",
      "Shape: []\n",
      "Weights: 0.03416704759001732\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3078 due to None values in features.\n",
      "\n",
      "Layer: 3079\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3079 due to None values in features.\n",
      "\n",
      "Layer: 3081\n",
      "Shape: []\n",
      "Weights: 0.03416704759001732\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3081 due to None values in features.\n",
      "\n",
      "Layer: 3082\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3082 due to None values in features.\n",
      "\n",
      "Layer: 3091\n",
      "Shape: []\n",
      "Weights: 0.009397318586707115\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3091 due to None values in features.\n",
      "\n",
      "Layer: 3092\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3092 due to None values in features.\n",
      "\n",
      "Layer: 3110\n",
      "Shape: []\n",
      "Weights: 0.011096132919192314\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3110 due to None values in features.\n",
      "\n",
      "Layer: 3111\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3111 due to None values in features.\n",
      "\n",
      "Layer: 3113\n",
      "Shape: []\n",
      "Weights: 0.011096132919192314\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3113 due to None values in features.\n",
      "\n",
      "Layer: 3114\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3114 due to None values in features.\n",
      "\n",
      "Layer: 3123\n",
      "Shape: []\n",
      "Weights: 0.16579605638980865\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3123 due to None values in features.\n",
      "\n",
      "Layer: 3124\n",
      "Shape: []\n",
      "Weights: 128\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3124 due to None values in features.\n",
      "\n",
      "Layer: 3135\n",
      "Shape: []\n",
      "Weights: 0.21070025861263275\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3135 due to None values in features.\n",
      "\n",
      "Layer: 3136\n",
      "Shape: []\n",
      "Weights: 72\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3136 due to None values in features.\n",
      "\n",
      "Layer: 3138\n",
      "Shape: []\n",
      "Weights: 0.21070025861263275\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3138 due to None values in features.\n",
      "\n",
      "Layer: 3139\n",
      "Shape: []\n",
      "Weights: 72\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3139 due to None values in features.\n",
      "\n",
      "Layer: 3145\n",
      "Shape: []\n",
      "Weights: 0\n",
      "\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3145 due to None values in features.\n",
      "\n",
      "Layer: Conv_13.weight_quantized\n",
      "Shape: [64, 3, 7, 7]\n",
      "Weights: [[[[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 132 131 128]\n",
      "   [132 135 138 ... 139 134 128]\n",
      "   ...\n",
      "   [126 118 113 ... 116 124 128]\n",
      "   [128 128 133 ... 138 136 135]\n",
      "   [128 131 132 ... 131 130 129]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 129]\n",
      "   [128 128 132 ... 137 134 132]\n",
      "   [134 138 144 ... 142 132 124]\n",
      "   ...\n",
      "   [120 112 102 ... 109 122 128]\n",
      "   [128 128 132 ... 145 142 139]\n",
      "   [128 133 137 ... 136 133 130]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   [129 132 133 ... 136 132 128]\n",
      "   ...\n",
      "   [125 123 118 ... 123 128 128]\n",
      "   [128 128 133 ... 136 133 132]\n",
      "   [130 128 128 ... 128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128 ... 128 128 127]\n",
      "   [128 128 128 ... 128 134 128]\n",
      "   [128 128 125 ... 128 135 128]\n",
      "   ...\n",
      "   [128 130 124 ... 124 128 131]\n",
      "   [128 133 128 ... 124 128 131]\n",
      "   [128 133 133 ... 124 126 128]]\n",
      "\n",
      "  [[128 128 128 ... 134 133 123]\n",
      "   [126 128 125 ... 136 140 131]\n",
      "   [128 123 120 ... 131 144 141]\n",
      "   ...\n",
      "   [130 131 119 ... 113 129 139]\n",
      "   [135 139 128 ... 114 124 135]\n",
      "   [128 138 138 ... 118 121 130]]\n",
      "\n",
      "  [[128 128 128 ... 132 130 122]\n",
      "   [127 128 126 ... 133 136 129]\n",
      "   [128 128 121 ... 130 138 136]\n",
      "   ...\n",
      "   [129 131 123 ... 118 128 135]\n",
      "   [132 136 128 ... 119 125 133]\n",
      "   [128 136 136 ... 121 124 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128 ... 128 128 123]\n",
      "   [128 128 125 ... 137 133 130]\n",
      "   [128 125 117 ... 128 135 134]\n",
      "   ...\n",
      "   [128 136 140 ... 128 121 124]\n",
      "   [127 128 128 ... 137 132 128]\n",
      "   [128 127 125 ... 128 128 128]]\n",
      "\n",
      "  [[122 128 128 ... 131 128 128]\n",
      "   [128 122 123 ... 143 141 137]\n",
      "   [128 123 109 ... 120 137 141]\n",
      "   ...\n",
      "   [135 142 151 ... 128 112 117]\n",
      "   [122 128 137 ... 145 132 125]\n",
      "   [126 122 123 ... 134 134 128]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 124 128 ... 137 133 131]\n",
      "   [128 125 117 ... 126 133 135]\n",
      "   ...\n",
      "   [133 134 139 ... 128 119 122]\n",
      "   [128 128 132 ... 139 128 125]\n",
      "   [123 125 125 ... 128 134 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[131 128 130 ... 128 128 128]\n",
      "   [128 128 128 ... 125 126 128]\n",
      "   [129 128 128 ... 124 124 125]\n",
      "   ...\n",
      "   [129 126 124 ... 118 119 121]\n",
      "   [128 125 124 ... 119 122 122]\n",
      "   [128 128 126 ... 122 125 125]]\n",
      "\n",
      "  [[125 128 126 ... 128 128 129]\n",
      "   [126 128 128 ... 132 132 128]\n",
      "   [127 128 129 ... 134 135 135]\n",
      "   ...\n",
      "   [128 131 134 ... 142 140 140]\n",
      "   [128 132 134 ... 140 138 137]\n",
      "   [128 128 134 ... 139 137 136]]\n",
      "\n",
      "  [[129 128 128 ... 128 128 128]\n",
      "   [130 128 128 ... 126 126 128]\n",
      "   [128 128 127 ... 126 125 123]\n",
      "   ...\n",
      "   [128 127 126 ... 124 124 124]\n",
      "   [128 126 125 ... 124 123 124]\n",
      "   [128 128 124 ... 122 122 123]]]\n",
      "\n",
      "\n",
      " [[[125 139 114 ... 138 127 124]\n",
      "   [142  97 154 ...  80 142 131]\n",
      "   [118 150 128 ... 213 110 121]\n",
      "   ...\n",
      "   [128 106 190 ...  73 222  82]\n",
      "   [128 128 128 ... 214  57 155]\n",
      "   [128 128 120 ...  99 143 125]]\n",
      "\n",
      "  [[119 141 111 ... 130 128 128]\n",
      "   [131 106 158 ...  86 146 128]\n",
      "   [119 156 128 ... 228 104 123]\n",
      "   ...\n",
      "   [143  95 191 ...  64 239  86]\n",
      "   [128 128 128 ... 230  55 138]\n",
      "   [128 128 128 ...  91 146 132]]\n",
      "\n",
      "  [[128 139 113 ... 147 113 128]\n",
      "   [143  97 156 ...  94 151 128]\n",
      "   [113 140 152 ... 197 105 123]\n",
      "   ...\n",
      "   [128 101 171 ...  99 209  80]\n",
      "   [134 128 128 ... 201  42 165]\n",
      "   [124 136 120 ...  86 165 116]]]\n",
      "\n",
      "\n",
      " [[[129 128 129 ... 128 128 130]\n",
      "   [128 128 128 ... 128 128 129]\n",
      "   [128 128 128 ... 124 128 128]\n",
      "   ...\n",
      "   [128 128 125 ... 121 123 126]\n",
      "   [129 128 128 ... 122 125 128]\n",
      "   [131 130 128 ... 126 128 130]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   ...\n",
      "   [128 126 126 ... 128 126 127]\n",
      "   [128 127 127 ... 126 126 128]\n",
      "   [128 128 128 ... 126 127 128]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 130 128 128]\n",
      "   [128 128 128 ... 131 127 128]\n",
      "   ...\n",
      "   [128 129 131 ... 137 133 131]\n",
      "   [128 128 129 ... 133 131 129]\n",
      "   [125 128 128 ... 131 129 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 3, 7, 7)\n",
      "Features for Conv_13.weight_quantized:\n",
      "  density: 0.9998937074829932\n",
      "  nnz_min: 146\n",
      "  nnz_max: 147\n",
      "  nnz_avg: 146.984375\n",
      "  nnz_sd: 0.12401959270615269\n",
      "  bw_min: 147\n",
      "  bw_max: 147\n",
      "  bw_avg: 147.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9998937074761913\n",
      "  scatter_sd: 0.00084367069867557\n",
      "  clustering_avg: 0.006910469667271964\n",
      "\n",
      "\n",
      "Layer: Conv_13.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [  502  2449  2908  2217  1431  2526  1388     0  2405  2476  3263  1480\n",
      "  2118  2578     0     0  2670  1402  5580  2602  1817  2642 -4031  2445\n",
      "  2303  2604     0  2560   600  1854 -5320  2840  5602 15369  6077   971\n",
      " -3694 -4502  3352  1044  3122  1395  2059  2031  3353  3302  1830 11378\n",
      "  1167 -3398  3675  2520     0  1894 -2073  3931    58  1634  1968  2318\n",
      " 17784  9238  3085  5617]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_13.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_37.weight_quantized\n",
      "Shape: [64, 64, 1, 1]\n",
      "Weights: [[[[145]]\n",
      "\n",
      "  [[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 77]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[103]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[137]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[152]]\n",
      "\n",
      "  [[125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[131]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  [[135]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 64, 1, 1)\n",
      "Features for Conv_37.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_37.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [-1477   615  3969  3359  1582  1853   837  3852  1069   586  1100  1991\n",
      "  2132  1282 -1438  2941  6170 -6713  2784  1209  1807  1920     0 -2709\n",
      "   438  1532  2773  1182 -2083  2103  -207  1097  1129  -125  2675  2473\n",
      "  1586  1725  1425  1287  5002 -6307  1451  1004  1720  3521  1469 -1860\n",
      "  5783  1990  2608  3726  4646  1957  1301  2174  -655   349  4417 -1877\n",
      "  5343  1460  1994  -922]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_37.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_60.weight_quantized\n",
      "Shape: [64, 64, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[133 133 134]\n",
      "   [133 128 134]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [133 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[135 128 135]\n",
      "   [132 128 139]\n",
      "   [137 135 137]]]\n",
      "\n",
      "\n",
      " [[[122 124 121]\n",
      "   [125 113 121]\n",
      "   [128 123 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 142 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 133]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 143 130]\n",
      "   [128 122 128]\n",
      "   [128 114 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [136 136 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 150 136]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 124 128]\n",
      "   [128 116 117]\n",
      "   [142 152 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 133]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 136 114]\n",
      "   [128 133 128]]\n",
      "\n",
      "  [[128 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 135 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 115]\n",
      "   [128 150 128]\n",
      "   [120 128 113]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [113 111 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 110 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[133 142 141]\n",
      "   [128 133 138]\n",
      "   [128 137 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [118 128 128]]\n",
      "\n",
      "  [[128 134 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 117 128]\n",
      "   [128 120 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_60.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_60.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [  5019  -1430   2212   3038   1883  -3903  -1109    413   4875    157\n",
      "   4532   4178   1868   3423   1020   3999  -5731   1257   -812  -1769\n",
      "  -1622  -3293  -5529     81  -4092   5583   3345  -7069    417  -2522\n",
      "  -2443      0  -3616   1634   3873    328   4257  -9223   5522  -5813\n",
      "  -1333  -6256  -3196  -4988 -15301  -1049   2541   5118   5370   2457\n",
      "   5403  -8471    133   -191    209  -7706  -5731   -847  -4800    272\n",
      "   4445  -1001  17561  -3091]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_60.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_83.weight_quantized\n",
      "Shape: [256, 64, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[143]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[130]]]\n",
      "\n",
      "\n",
      " [[[139]]\n",
      "\n",
      "  [[129]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_83.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_83.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [   38   418  -570  3750   163  1410  -995  -421  -548 -1505   213     0\n",
      "  1334   628    66  1112   896     0  -744     0     0 -1184   737  -140\n",
      "   275   462  -146  2398     0  2349   991     0  1652  2571 -2698  -216\n",
      "    55  -563  -582  -201   372     0     0   177     0   506  1429     0\n",
      "  -831   133   557   247  1928     0 -1474    37   606  -597     0     0\n",
      "  -242  -531  1415     0  -725  -173  -278  -313     0    23    -6     0\n",
      "   457 -1471 -1733  1360     0  -142  -177     0  1880  -897  2210  1004\n",
      "  -176 -2300     0     0     0  2002   715  -369  -648  -632  2311   179\n",
      "   346  1025  -326   305     0  -386     0     0  1560   -59  1810  -670\n",
      "  -425   547   689     0     0     0     0     0     0   -20 -3329  2913\n",
      " -1455     0  1160  -741  1192   -70  1504  -536     0   665     0  2198\n",
      "  -754   485     0     0     0   159     0     0  1619  -715   281     0\n",
      "  1218 -2891     0   259     0  -810     0     0  1482     0  -873  2141\n",
      "   544  -434  3383     0  -259  -408   478   532   596  -780  1120  -168\n",
      "     0   -36     0 -2977     0   265   450  1826     0   101  1804   204\n",
      "  -573  2263 -1080 -1051  -686     0     0   815   491   303     0   211\n",
      "   699   266  1043  -111   800   585   750  1757     0  -654  1289     0\n",
      "  -684   152     0     0 -1017  1294  -183     0   244     0     0  -163\n",
      "   996     0   905     0  -486     0     9   563     0  1842     0     0\n",
      "   485   808   186  -328  -446     0     0     0 -1699  -329  -696  -436\n",
      "   414     0  1151  -567  1537   699   608 -1564   411   741  -202     0\n",
      "  -203   184  -671   985]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_83.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_105.weight_quantized\n",
      "Shape: [256, 64, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[134]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[102]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[118]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[104]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_105.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_105.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [  488   137   642  -713   546  -576   484  1279   214  1265  -150     0\n",
      "  1199   101   600   158 -2215     0  -962     0     0 -1321  -528  1180\n",
      "  1958  -556    79 -1375     0 -1039  8862     0   939   312  -800   548\n",
      "   300  1399   384   478  2315     0     0   -69     0  1489  -794     0\n",
      "  -225  5654   345  1436   723     0  -523  1307   777   -51     0     0\n",
      "  2136   -51   997     0  1721   -26 -1215   197     0   201    41     0\n",
      "  1713 -1314 -1363  -136     0   514   527     0  -859  -527  -687  3123\n",
      "  -329    67     0     0     0   163 -1633  1497   959  1377  1128   731\n",
      " -1813  -118   226   -54     0  1067     0     0   289  1536  1332   532\n",
      "  1604   115  1046     0     0     0     0     0     0  1212  1235   451\n",
      "  -515     0  -309   268  1624  -229   293  4062     0   948     0 -1793\n",
      "   917  1788     0     0     0  -192     0     0   649  2951  3538     0\n",
      "   285   339     0  1220     0   345     0     0   279     0   924 -1326\n",
      "  -346  -302  1623     0   605 -2036  -311   107 -1090  5197   720   -44\n",
      "     0  1900     0   706     0     4  -376  -280     0  1575  -304  -269\n",
      "  2124  3160  -111  2812  -340     0     0  1172   -66   284     0  2140\n",
      "   390   335   419   740   565   694   201   410     0  1147   934     0\n",
      "  1117   273     0     0  1018   596   660     0  1649     0     0  1696\n",
      "  3769     0    87     0   341     0   886  -361     0   106     0     0\n",
      "  1359   386   632   -80   192     0     0     0   945   614  1474   831\n",
      "  -357     0   155  -415 -1087    78   393  -790     6   -74   709     0\n",
      "  -683   -86   864  -232]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_105.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_129.weight_quantized\n",
      "Shape: [64, 256, 1, 1]\n",
      "Weights: [[[[115]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[108]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[136]]\n",
      "\n",
      "  [[147]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[107]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[117]]\n",
      "\n",
      "  [[151]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 256, 1, 1)\n",
      "Features for Conv_129.weight_quantized:\n",
      "  density: 0.99993896484375\n",
      "  nnz_min: 255\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 255.984375\n",
      "  nnz_sd: 0.12401959270615269\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999938964839844\n",
      "  scatter_sd: 0.0004844515340065226\n",
      "  clustering_avg: 0.003967763863342343\n",
      "\n",
      "\n",
      "Layer: Conv_129.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [12834  1934 -1646  1064 -4286  3437  5578  6415  3257   786   740  2128\n",
      "   757 -4956 -3501 -1838  -237  1729  1376   934   588 -2336 -1293 -3506\n",
      "  1743  4447  1038  3369   727  3284 -3312 -2814  1440   941 -1955  1694\n",
      "  1187  2205  6455 -1966  3733 -4143  2825 -3446  1693 -1219 -1683 -3463\n",
      "  -372  -118 -2123  -690 -5525  5902  6304    -8 -3010 -3209  3514  2639\n",
      "  3443   553   193  4577]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_129.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_152.weight_quantized\n",
      "Shape: [64, 64, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 125 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 123]\n",
      "   [128 128 128]\n",
      "   [128 128 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 130 128]\n",
      "   [128 128 124]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 129 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [127 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [123 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 131 128]]\n",
      "\n",
      "  [[119 128 122]\n",
      "   [128 123 128]\n",
      "   [128 124 136]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 134]\n",
      "   [128 123 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 132 128]\n",
      "   [128 128 128]\n",
      "   [128 126 128]]\n",
      "\n",
      "  [[128 131 128]\n",
      "   [133 128 125]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 119]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 126 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 127]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 122 128]\n",
      "   [128 128 128]\n",
      "   [132 135 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[136 134 128]\n",
      "   [128 128 128]\n",
      "   [128 133 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_152.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_152.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [ 1020  1794  2396  2621  2188  1816  2157     0  1683   175  3477 -2470\n",
      "   886 -3116  6011   786     0  1056  1274  2328     1    68  1123 -1637\n",
      "   452  1282  5163   808  1451  1236 -2359   453  2488  1082  1708  3070\n",
      "  1775   116  1450  2515  2069   932   454  -665  2445  -916  1410   867\n",
      "  -677  3520   745     0   767  2545  1226   351     0 -1644  1582  2508\n",
      "  2263 -2077   504  1001]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_152.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_175.weight_quantized\n",
      "Shape: [256, 64, 1, 1]\n",
      "Weights: [[[[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[123]]\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[151]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[133]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[107]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[113]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_175.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_175.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [ -626  -953     8  3692  1363 -1419    63  -516    29    93   906  2466\n",
      "   600  -254    18  -143     6     0  -121   626     0    18 -2521    83\n",
      "    18    51  1097   282    55  1175    35   200    37   -23    14    12\n",
      "  1215    17    17   784 -1841  -314  -629 -1396  2069    32    47  -248\n",
      "   -62    28    43    26    38  -244    -6   137   570    13   166  1194\n",
      "  -862  -248   233 -2201   760  -654    29 -2109   448    27    37  1830\n",
      "    25    10    52 -1190     0    13 -1951   -66  -483  -922  -527    23\n",
      "  1851    31   747   702     0    37  -860  -186  3424   641     9 -2051\n",
      "  -181   608   -20    72     0  -132  1208  -629  -275   560  2635   416\n",
      "    26   896   221  1309   150   977   498  -155     0 -1393    26    35\n",
      " -1221  -384   942    19  -623   -59  -457    28  -925    20  3296  -780\n",
      "  -575    14  1177 -1161     0   244  -684    91   425 -1946    17 -1733\n",
      " -1256     3  -747    18   608  1368     0  1302   116  -275     2    64\n",
      "  2090  2596    32   378 -1088    13    74 -1597   146    23  1011  -974\n",
      "   741 -2077   940    31 -1228 -2309    21    99 -1740    22  1963  -834\n",
      "   683     0   117    10    89     0   780 -1341    27  -460 -1272 -2069\n",
      "  2957   279   455 -1256   784   -30    52  -793   247  2130  -286   723\n",
      "    45    -7  1735 -1392    60   493  -389 -1383   371  1219 -3172   115\n",
      "    36 -2517 -1055   821 -1455  1014 -1123   619     0    24     0   252\n",
      "    15    53    38   312    11     0     0 -2222   362  2182   -99   820\n",
      "  1112  2131   440  -398  1456 -4102    16    31  -154  -996  2963 -2132\n",
      "    49  -337  1681   669]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_175.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_199.weight_quantized\n",
      "Shape: [64, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[153]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[103]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[138]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[152]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 256, 1, 1)\n",
      "Features for Conv_199.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_199.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [ 3865   831 -1323   658  5495  1233  3945  5014 -1803  1338  -752  1721\n",
      "  1376 -3033  3615  1752  6130 -5932   920  4475   438   323  2751 -1928\n",
      "   913   451  2191  -670  1358 -2980  -545  -526   775   626 -3472   592\n",
      "   126  2540     0  -964  3307  5149  -562  1426  3421  3624  -702 -2313\n",
      "   901  2015  2004  3039  1710  2921  6563  4936  -272 -2662  -207   652\n",
      " -3206  3920 -3335  4682]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_199.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_222.weight_quantized\n",
      "Shape: [64, 64, 3, 3]\n",
      "Weights: [[[[128 115 128]\n",
      "   [128 141 128]\n",
      "   [119 128 128]]\n",
      "\n",
      "  [[128 128 112]\n",
      "   [128 133 128]\n",
      "   [128 132 128]]\n",
      "\n",
      "  [[128 119 147]\n",
      "   [128 117 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [120 128 128]]\n",
      "\n",
      "  [[133 117 128]\n",
      "   [128 128 116]\n",
      "   [128 120 155]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [108 135 105]\n",
      "   [128 153 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 145]\n",
      "   [128 106 103]\n",
      "   [128 128 151]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[117 128 128]\n",
      "   [128 106 112]\n",
      "   [128 160 154]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128  98 110]\n",
      "   [128 128 152]]\n",
      "\n",
      "  [[139 147 128]\n",
      "   [128 105 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 130 136]\n",
      "   [116 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 140]\n",
      "   [142 104 128]\n",
      "   [128 135 128]]\n",
      "\n",
      "  [[128 114 128]\n",
      "   [144  89 168]\n",
      "   [128 114 142]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 139]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128  99]\n",
      "   [128 149 114]]\n",
      "\n",
      "  [[128 128 134]\n",
      "   [144 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 108]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 132]\n",
      "   [112 161 109]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [100 139 137]\n",
      "   [128 150 128]]\n",
      "\n",
      "  [[128 128 122]\n",
      "   [128 112 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [104 157 104]\n",
      "   [128 144 116]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 138 128]\n",
      "   [124 128 128]\n",
      "   [140 117 128]]\n",
      "\n",
      "  [[128 128 122]\n",
      "   [128 128 121]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[114 128 128]\n",
      "   [128 155 128]\n",
      "   [117 128 135]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [142 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [143 128 113]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 113 128]\n",
      "   [128 135 129]]\n",
      "\n",
      "  [[128 117 140]\n",
      "   [128 128 122]\n",
      "   [128 140 117]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126 138 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[137 144 128]\n",
      "   [128 105 108]\n",
      "   [128 128 149]]\n",
      "\n",
      "  [[128 128 152]\n",
      "   [128  89 128]\n",
      "   [128 138 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_222.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_222.bias_quantized\n",
      "Shape: [64]\n",
      "Weights: [ 10372   5483   6402  -1918   1561   2258  -5370   2314  -5619   1486\n",
      "   1261 -15081   6986   3368  -2966   4236  -4541   2354   9803   6244\n",
      "  -5982   5642   -846   2192  -3317   7094  -9560   -569  -4704   3552\n",
      "   3644   -144  10376   4057   8797   2958   8283   7064   -443   -728\n",
      "    241   6765  -5985 -12638  -3037   2969  11904  -2646   6707  -3374\n",
      "   -616   8272  -2507   1211  -6315  -4734  -5204  11451  -1708  -2823\n",
      "   5440  -1860   4505  10173]\n",
      "\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_222.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_245.weight_quantized\n",
      "Shape: [256, 64, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[133]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[140]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[111]]\n",
      "\n",
      "  [[ 80]]\n",
      "\n",
      "  [[164]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_245.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_245.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [   41  -149     7   -12  -304  -622    -2    18     7     9 -2582  -922\n",
      " -1057 -2547    16  1039    -3    81   -79   902 -4585     6 -1826     6\n",
      "     3    12   -21  -383 -1028    25    13  -124    29     3  -126    13\n",
      "    13    -7     8   260 -1645     8    41  -360 -1564    18    -8 -1913\n",
      "   930     2    19    26   212 -1102    14  1625  -312     5 -1617  -925\n",
      "   -65 -1345   792   187 -1263    44    22 12883 -1237    30  -233   874\n",
      "     5     6  1840  1248  -963     7  -126  -421    19  -389 -2108    19\n",
      "  -662    14  1694   756  1577     8     2    38  1241    42     6  1489\n",
      " -2463 -2295   614    18  1342  -400 -2060    22 -3219  1440    21  -540\n",
      "    20 -1517   111 -2585   835 -2315  -229   227  4539    51     8     1\n",
      "   191  1590    15    25  -376   106    -7     6 -1019   -10    30 -3932\n",
      " -1005    20  -872   516  4338   287  6621  -332   913  -591     2  1431\n",
      " -1151    17   621     8 -4922 -1806  1672 -1948  -154  -769    -6   833\n",
      "     3     7     8    23     6     7    19  1628    23    16  3376  -348\n",
      " -2008    37  -170     5  2004 -4578    -2     8 -1977    15  -788    55\n",
      "   705     4   -73    12    10   282  1134  -159    49  -192  -802 -1386\n",
      " -2826  1319 -1291   124   307   -13    17   413 -2634   818  -387 -1831\n",
      "   -17     8  -337  1729   -18 -1930 -1235 -1808    65 -2264 -2926    -2\n",
      "     4 -4997    12  -836   -92  -788  -289  -580  1147    34  -747  3645\n",
      "     2 -2046    26 -1419     0   384 -6792    31  -592 -1983 -1540  -606\n",
      " -1243   941 -3019  -194  -763 -8520     5  2275   556  1399  -298    22\n",
      "    20    48  -984 -1249]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_245.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_269.weight_quantized\n",
      "Shape: [128, 256, 1, 1]\n",
      "Weights: [[[[ 87]]\n",
      "\n",
      "  [[ 73]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[148]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[158]]\n",
      "\n",
      "  [[108]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[142]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 256, 1, 1)\n",
      "Features for Conv_269.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_269.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [ -214  -532 -1818 -1817   809 -9544  -662    16 -2590   294   377   -92\n",
      "  2388  1121  2067 -4185   707 -6425   661   942  1812 -2121   542 -3626\n",
      "   403     0  1175 -1606  2498 -1695   971 -1211  -534   703   722 -1465\n",
      "  1522  -282  3835  -654  1171   480 -1449   964   880  -370 -1245   240\n",
      "  -241  1213  1718  1669  2784   589  -860 -2653   376 -4514   -91  4579\n",
      "  1411  -131  -350  -595  1186  -350   498     0   815  4578   665 -1345\n",
      "  2011 -2989 -1660  1066  -632   -17 -1149  2147  -919  1691 -1745   618\n",
      "  2741   504   478  3045  3441 -1954   362  -219 -2094  1925  2136  -939\n",
      "   579   285   731  -911 -1930  1558   607 -1577  2435  1290   843   238\n",
      "   346   422  -656  -770    95  -872  1625  1846  3672 -3737  8074 -3172\n",
      " -1904 -1001  1450   160  2087 -2380   252   214]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_269.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_292.weight_quantized\n",
      "Shape: [128, 128, 3, 3]\n",
      "Weights: [[[[128 128 119]\n",
      "   [128 120 121]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[124 128 128]\n",
      "   [117 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 133]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[124 128 128]\n",
      "   [128 128 118]\n",
      "   [128 115 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 124]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 123 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 135 128]\n",
      "   [128 139 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 114]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143 156 144]\n",
      "   [147 158 155]\n",
      "   [128 141 147]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[109 102 103]\n",
      "   [128 113 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 140]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[116 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[134 128 128]\n",
      "   [145 128 128]\n",
      "   [128 137 132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_292.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_292.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [   388    -45   3853   -375   1022   -670   -470   8750    342   7863\n",
      "  -3941   7329  -1398   3269   -588   4839     30   6677   6319   1088\n",
      "   5431   2879   2406   6281   2331   2479   4726   -528  -1367   3880\n",
      "    -55   1128   4536   3093 -11005  -2594   8401   3865    251   6113\n",
      "   3934   1529  -2423  -3032    277   7824   8621   1034   4506   -918\n",
      "  -1706    662    809  -1065   -674     13  -3521   -409   -496  -1537\n",
      "  -3909   2355  -1009   3243   -194   6816  -1467    376     53   4461\n",
      "  12178    620  -1534    432   3660   -899   1890  -2274   1291   -850\n",
      "   2520   4616  -1144   3533  -2773   4713   4574  -1028   9735  -1464\n",
      "  -1806   2971   3465  -3312   4405   7463   1719    438   9228   -774\n",
      "   3595  -1393   -209   2404    439    894   3512   -760  -2317   1169\n",
      "   8542   -199   2988  -3323   7122   -741   7369   1672   -697   4841\n",
      "   2984   7805   3225   2093   2747   4374  -3095   2939]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_292.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_315.weight_quantized\n",
      "Shape: [512, 128, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[138]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[108]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[147]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[168]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_315.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_315.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [    0  1145   107  4142   556  -685  3516     0  2113  1576   316  1007\n",
      "    87  1562   849  1408   584 -2991  5610   337   387   890     0  -480\n",
      "     0  -171   710   589     0     0     0    83  1646     0     0   304\n",
      "    32     0   987  1087   -10     0  1093     0   677  -755     0     0\n",
      " -2163     0     0   354   861 -3511   367  -504     5  -290  2831  1604\n",
      "   150     0   524   159  -749 -1299  2007  2839   895     0  -438     0\n",
      " -4035  -290   240  -814 -1171   362   328  2565     0     0   375     0\n",
      "     0  -421   657 -5102     0   694   847     0     0   615  1320     0\n",
      "  2303   426   808     0  3375  1154  1818  -572     0   735     0   176\n",
      " -2509   514  -230 -5523 -1874  1108   219 -1458 -1987     0  -197   694\n",
      "   715  -132   230  2170   307     0  4916     0  1392  1930     0     0\n",
      "   618     0  -727     0  1884  3157   306   275   305 -1818  -363   927\n",
      "   642  -558  -397 -1540     0     0   613   564   579 -4195   428   525\n",
      "     0  -276     0   683 -1363   244  3177 -1673     0     0   768   781\n",
      "   286   428   397  -304   851  3678  -888     0  1192  2833     0     0\n",
      "     0   245  1961     0  3463   405     0 -2071    33   198  -237   760\n",
      "  -316   406  1165  1391  2356  1189  -379  2954  1182  1573   609  1549\n",
      "   737 -3503  -230  4613    93   873   318  -719     0  -986     0     0\n",
      "     0   339   603   503   924     0  3680    99  -479   676  2338  2801\n",
      "     0   696  3313     0   259 -1294 -1883  3985   506  1193  1150  3238\n",
      "   436  -354   392   404  -856     0     0  1910     0   737   444 -1548\n",
      "     0   805     0    93   652     0  -495     0 -3559  -705    29    -1\n",
      "  2814     0   -48  1234     0   359  1431     0   542 -1950     0   264\n",
      "   524 -2016  2801   266 -2022   252 -1945   860     0  1795     0   715\n",
      "  1506  -662 -1398  1504   440   813   -56   157  4279  1098     0  -249\n",
      "     0   -56     0     0     0 -2325  1029  -626   802     0     0     0\n",
      "   325     0     0 -3150     0     0  -725  6270   -11     0     0     0\n",
      "     0   625     0 -1183 -5357  -171  1119  1188   200     0  -298     0\n",
      "  -377   164  2398   243   539  1296  3672  -863 -2844  -148  1168     0\n",
      "  -158     0   156  9629   942  -701     0  1972 -3011   477     0  1596\n",
      "     0     0     0  -185  1450 -3212 -1748   353   302  -710   315   647\n",
      " -1248  -966    67  1529  -247   -35  3380     0 -2086  -527 -1677   -10\n",
      "     0  5832     0     0  -155  -416  4414  2801     0     0     0   962\n",
      "   128   428     0 -2149  1197  1454 -8382     0    16   505 -1095  -676\n",
      "   858   835   769   367   760   582 -2320     0   185     0     0     0\n",
      "    15  6537     0  1765  -834  1027  -595  2581   272  2489  1762   224\n",
      "  2144 -1106     0   437  1268 -2299   -85   -43     0  -741 -1611     0\n",
      "  -667   674   805     0  1355  2657  -241     0   990     0     0  -304\n",
      "  2611   913 -3516     0  1879 -1799  1969   884     0  2068   710  3176\n",
      "   799 -1851     0  1240     0 -1190  -311  4023  1557  1216  2998     0\n",
      " -6277   -21   785   895  2453   878   708   315   135   496   394  1243\n",
      "     0     0     0  -140    16  1881    23 -1707 -1101     0     0     0\n",
      "   991   757  -360   675 -1180   183   -16   649]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_315.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_337.weight_quantized\n",
      "Shape: [512, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 256, 1, 1)\n",
      "Features for Conv_337.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_337.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [    0  -114   -87  -658    94   -83  -205     0  -154  -168  -420   722\n",
      "   274  1546  3235   484  1211  1789   694  1386  9615   -89     0   307\n",
      "     0  -501 -3580   595     0     0     0  -957  1930     0     0  1116\n",
      "   348     0  1148  1852   711     0   175     0  3343  4262     0     0\n",
      "    58     0     0  -366  3021   353   -50  -395   -72    61  -140    59\n",
      "  2700     0  -771  4871  -105  2233 -1333   739  4378     0   633     0\n",
      "  1486   528  1815 -1292  -300  2125   247  1466     0     0  -502     0\n",
      "     0   264  2355  1567     0   -89  -912     0     0 -1636  1449     0\n",
      "  1688  1270   -65     0   687   330   -79 -4843     0  1085     0  1067\n",
      "  1293  1057   303    87   439   467  1879  -209  -514     0   204  1685\n",
      " -3363   913   783    23   183     0   606     0  1264  6309     0     0\n",
      " -2421     0   182     0   -19  -159  1552  1054  1316   289   554   255\n",
      "   -76  1193   -73  -128     0     0 -3714   -78 -1759   111   499  -384\n",
      "     0  1666     0   -50 -1899  1446   920    55     0     0    63   110\n",
      "  -111   790  3819  -145   952  1667  -210     0 -1664   234     0     0\n",
      "     0   797  3149     0  -197   821     0  -543   234  -537   716   709\n",
      "   -26  1825  3403   350  2496   199   319  -381    -9  1576  1950  -229\n",
      "  -140  -239   165   -79  -472 -1041   -93  1613     0   326     0     0\n",
      "     0  1170   938  2960  2544     0   232 -2769 -1075    67   897  -151\n",
      "     0  1565   906     0   409 -1195    70  1629  1403   -70   373  1047\n",
      "    44   545  -651    66    89     0     0   243     0  1730   140  1298\n",
      "     0  -297     0 -1797  1751     0    74     0   381   107  1160    -1\n",
      "  -776     0   266  2425     0  -156    53     0  -494  -307     0  -443\n",
      "  1304 -2026  1140  1385   334   192  -474  2414     0  -269     0  -179\n",
      "   581  -458   533  3232  -342   -19  -218  -326    73  5146     0   898\n",
      "     0   856     0     0     0 -2012  -345  -339  -754     0     0     0\n",
      "   784     0     0  -394     0     0   100   -57   616     0     0     0\n",
      "     0   582     0 -2784  -329    16  -217   673   439     0   217     0\n",
      "  -525   311 -2371  1299  1310  -387   -12  -481   875   539  -210     0\n",
      "   938     0  -611 -2812  3226   -23     0 -1862   537    96     0  -896\n",
      "     0     0     0   182  -330    41   143  -476    63  -393  1917  3686\n",
      "  -461   426  -470   -41   882  1223    41     0  -111  -362  -832    -9\n",
      "     0   493     0     0   126  -410   794   812     0     0     0    49\n",
      "   869   824     0  1805  1508  2483   899     0  1620  1583  1775 -4104\n",
      "  4311    31   296  -391  -135   638  -705     0  -231     0     0     0\n",
      "   344   499     0   231  -351  -360  -318  4059   601   612   407  1043\n",
      "   599   430     0  -338  -250  1994   326 -3828     0  -183   962     0\n",
      "   414   125  -150     0  -532  2300  1958     0   150     0     0    57\n",
      "   598   966  -349     0  -188  -192   598  1691     0  -813 -4377   385\n",
      "  2149  -459     0  1746     0   361   815   537  1506  -758  1638     0\n",
      "  2194   543  1389  -689  2165  -385   950  1274   200 -1186 -1154  -173\n",
      "     0     0     0   593   601    43  -112    11 -1420     0     0     0\n",
      "   711   547   893 -3107   214   103  -536  -676]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_337.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_361.weight_quantized\n",
      "Shape: [128, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_361.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_361.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [ 5460  2934  1963 -1810  5163 -3674     0   354     0 -1167     0  3609\n",
      "  1437 -1121 -1292     0  1958 -1812 -1027  1364     0 -1709     0     0\n",
      " -1422  1752 -4025 -2316   567  5443  1684  -521  -994  8382 -2755  9407\n",
      "   362  4683     0 -1930  1710 -4231     0   512  5067  2489 -1873  1723\n",
      "  4343 -2364     0 -1206 -1058 -1708  3174   613 -3346  5162  1405  7593\n",
      "  4279 -9115  1108  1645  3216  3363  -925 -1783  3258  1002  2104    74\n",
      "     0   137     0  5802  2134  7249   726  2614 -1369     0  3035     0\n",
      "  1634  5174  1789     0  -835  -339  2862  3519     0 -3291  -322 -1972\n",
      "  1865  2263  2273  1807  3222  7934 -3862     0 -4183  1351   294   303\n",
      "   865  7331  -480  4331  2556 -2210     0   983 -4499 -2063  1560  -417\n",
      "  1009   856 -1512  1351  1604     0     3   274]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_361.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_384.weight_quantized\n",
      "Shape: [128, 128, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[144 163 148]\n",
      "   [128 128 128]\n",
      "   [118 102 114]]\n",
      "\n",
      "  [[130 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 120 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[135 141 136]\n",
      "   [128 128 128]\n",
      "   [120 109 115]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 137 137]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[122 128 128]\n",
      "   [106 128 128]\n",
      "   [116 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 120]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [139 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 137]\n",
      "   [128 128 128]\n",
      "   [111 107 116]]\n",
      "\n",
      "  [[128 142 136]\n",
      "   [128 128 128]\n",
      "   [128 117 122]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 116 128]\n",
      "   [128 128 128]\n",
      "   [128 141 144]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 150 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_384.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_384.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [    0 -5445 -4043     0     0  5187     0 11779 -2794 -6981     0 -4991\n",
      "  5369     0 -3907  -307 -6248     0     0 -3408 -2881 -4728 24408  -883\n",
      "     0 -5140 -3353 13797     0 -1814 -5999 -4752     0   626 -1328  1139\n",
      "     0 -4650  1405     0 -6486  2119 -1412     0 -2863 -9754     0  7913\n",
      "   -65  -338 -7341  4662 -3354   718 -4970  -309     0  1009 -4681 15364\n",
      "  9358     0 -1648     0   160  -375 -3564 -3859  -481 -5940 -2295 -3895\n",
      " -2042   773  3187     0 -3982 -4874     0 -1693 -5681 -7225 -6751 -5412\n",
      " -1950 -3325 -3169 -2922 -4286 -5799 -7192     0 -5282 -1832   569     0\n",
      " -4593 -7942 -7275     0   -82     0 -2579 -6534     0     0 -6214 -4798\n",
      "     0     0  -522 -2656 -4823     0  4755  1990 -5076     0  5996  -905\n",
      " -3322 -3489 -7270 -4437     0 -4954 -2634 -3100]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_384.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_407.weight_quantized\n",
      "Shape: [512, 128, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n",
      "Features for Conv_407.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_407.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [     0    -74   -653    -68     26   -125  -1949   2673     22    -82\n",
      " -10493  -2873     14   1692   -641   -256     20   -240    516  -1258\n",
      "   -866   1258   1456   -163      0   3084  -3722     31      0      0\n",
      "      0  -1488   -890      0      0     14   -907    372    -75   1203\n",
      "     -6    729     16   1884  -2267    -91   1427   1332   1034      0\n",
      "    437     63  -2188    -14   1055    110     18  -2567    112   1295\n",
      "    708    996   -160  -2370   -115    101   -293    155  -1179    103\n",
      "   -417   1557    123   -446     40  -3341    -86   -405    604  -1658\n",
      "    613      0      0      0   1921    -70   -564   -322  -1331      3\n",
      "   1214      0   -763    944  -4120   1512  -2028    175     60      0\n",
      "   -432     62     65  -2079      0     34    549    -46    537   -687\n",
      "    -44   5303   -673    119     49   -161      0    417   -118  -1664\n",
      "  -1331     43    173  -2421   1750    628     39   -813    624  -1250\n",
      "      0      0    923   2573    791      0   1526    236  -2457    173\n",
      "     59  -1330    -15    -14    -49    452     -9   -104    499  -1794\n",
      "    286    -60  -1882     39    933    -12   6682    643   5051     -7\n",
      "   -758   -718    106   -191   1785    583    571     99    -68    -67\n",
      "  -6071   -118  -1154   -391    -29   1298    439   -394      0   -448\n",
      "   1962     32  -3261  -2260   -582    -21   1737   1214     63   4681\n",
      "   -710   1428    -44  -1951  -1473    167    -80  -1285   -205    -85\n",
      "    -27    337    242    -99   1094     -2    286     52   -902   3606\n",
      "      9    -72   1125    -27      0      0   1620    524    -52    -15\n",
      "  -2944   2169    425   1147    -31   -288     53    -16      0  -1556\n",
      "     -9      0   -374    -21     22      5    210     46     36   -205\n",
      "   -171   1517  -2225    135     -7    957   1200   -546    236      3\n",
      "    -34     24      0  -1587   1041  -1565  -3517      0     14  -8534\n",
      "    194    120    121     -1    482   1596    -36   -418   1733    499\n",
      "    -23   3236     10     42    314  -3006    121  -1953    -12  -1141\n",
      "    693    893   -497   1745    -17     15      0     26   -224     56\n",
      "   -410  -2335   -110    -85   -116    -78  -4693  -2438   1098   1920\n",
      "      0    317   1758      0   1393     95    -11    -53   2261   -295\n",
      "      0  -2100    -81   1381      0   -128   3944   1459    -19    113\n",
      "   1425    521   2535     89      0     17      0   -489    -15   -123\n",
      "      8  -3083  -2116      0   1765   -975      7    948   -821   -943\n",
      "   -482    -85    -50   -305     13     26     52      0  -1658   1936\n",
      "   -663  -6651   -227   -177    739  -1248     59   -395      0  -1577\n",
      "      0   2347      0   -887  -1966      3     62    127   -553   -307\n",
      "   -661   1359    556  -1002   -163     74      1   -519    104   3997\n",
      "    -26   -166    865   1309   2042    123    605      0     17    -75\n",
      "     24    -57      0   1652    899    -43     73  -2916      0  -1086\n",
      "    132  -1932   -668    453  -1882    594     25  -3413  -2525   -695\n",
      "  -1394   -265    -83  -1693   -314      0    212   -549      0      0\n",
      "   1923     21      0    -52   -206    878    -59   -366   1120     16\n",
      "  -1806    -68     29     -7      0    -23   -117  -1803   1139    806\n",
      "    188     60   -767    796   -153    203   -415      0   -185      6\n",
      "    -12   1434     -6    994    956    -98   -491    137     75   -440\n",
      "    -99    -20    125    435      0   -199  -2542     51    451   -236\n",
      "   2535   -365      0   1230     44    157   1524  -1114      7      0\n",
      "   -447   2507   -136  -2169  -1116    -42  -2634   1470    -37    688\n",
      "   -118  -2000      0      0   2806  -2111   1596     18  -1481   2261\n",
      "   3040   1807      0   2489  -1909     11    -59    115   -942   -899\n",
      "   1215   -178]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_407.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_431.weight_quantized\n",
      "Shape: [128, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[169]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[139]]\n",
      "\n",
      "  [[105]]\n",
      "\n",
      "  [[108]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_431.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_431.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [-2170  2705  -417  -199   194  -749  1429  2414  3490  3284  -727 -3695\n",
      "   926  2411  4061  2005 -1750  3015  2800 -1480  4207  4690  3927  5384\n",
      "  2020  8753  -856 -1463  3632 -2594  6187  1721 -2298 -1094  3731  1196\n",
      "  2803  4812 -4619   195    21  2420 -2867  3414 -1516 -1523  7010 -2805\n",
      "  3114  2447 -2517  -950  1516  2916  3840   470 -3486  3803   201  1409\n",
      " -3714 -3759  -406 -4413  -340  1894  3043  4707 -1037 -1155   557  3191\n",
      "   796  -271  7376  3028  4083  3200   595  2254  -989 -5839  -911  1252\n",
      " -3670 -8439  -947  2283  3862 -9533  3477 -2487  1152   440   247  1414\n",
      " -2352  -977  1279  2182 -4206  5925  2523   547  -625  1511  -286  1554\n",
      "  2883  2327  1867  1280   505   342 -2771  2014  1397   425 -2804  4785\n",
      "  3853  2634   -33   476 -3655 -2888  -284 -4823]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_431.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_454.weight_quantized\n",
      "Shape: [128, 128, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 117 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 100 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [147 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 150 128]\n",
      "   [113 156 128]\n",
      "   [128 153 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 134]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 148]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 113 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 109]\n",
      "   [128 128 106]\n",
      "   [128 128 117]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 105  84]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [110 128 128]\n",
      "   [128 141 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_454.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_454.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [  4329    240     40  -1067   7522   4806   2126  11119   1103  -5146\n",
      "   2364   7606  -2269 -10326  11227    795      0  10608  -5158   -464\n",
      "   2992   6623   6374    386  -8555   5345  -3145   2717  -1988   1203\n",
      "  -2411      1  13540    174  -4640   -386  -4076   9148  -3940   5539\n",
      "  -3127   1008    247   1872  -5772   4074   2774    265     63  15920\n",
      "  -2438 -11887  -3734  -6886   1226  -4164   2941   9156   9512   1832\n",
      "   5622  -2764  -3919   4658  15357   2913   4140   -834   1207   3027\n",
      "  -2358  -5092   2292   4785 -13144     18   2053  -2336   2199   7003\n",
      "  -4353   4140   1044  -2603   5401  -2578   2477  10833   3768   8696\n",
      "   7727   3627   6335   -748   1625  -4398  -3199  -4088   2811      0\n",
      "  -4515    391   2597   5384  -1246  -3784   -150   -816   3407  -1148\n",
      "  -3678      0  -3028   5821  -1979   4414   5398    572  -3344   5673\n",
      "  -3228  -9060  -4037   5999    685   -389  10105  -2575]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_454.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_477.weight_quantized\n",
      "Shape: [512, 128, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[135]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n",
      "Features for Conv_477.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_477.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [    0  -653  -222   653  -905    21  1831  -390  -468 -1313  -520 -1018\n",
      "  -718 -1995 -1822 -3023 -2743 -1277  1736  -442 -2290 -1635  -962   -50\n",
      "  1071  -649   102    67     5     0 -1119  1313 -2161  1528     0 -1307\n",
      "  -165 -2262  -212   162  -665 -1306 -2170 -1454   151   465  -348  -471\n",
      "  1957     0  -932    20 -3053 -3331   142  -429 -3818 -2277  -385   -61\n",
      "   -65 -1459    44 -1626   302 -1535 -2854 -1343  -882  -936 -1557  -136\n",
      " -2013   259 -1844  -166 -1528  -353  -773 -1902  1868 -1065  -482     0\n",
      "  -709 -1202  -871   -44  -837  -287 -1854  -953  -133  -461   356 -1580\n",
      "   130 -1151  -722  2720 -3193  -341 -1949  -735  1231   -62 -1683  -105\n",
      "  -261  2568 -1428  3810 -2938  1055  -512  -445    53  -202 -1303     1\n",
      "  1535  -437 -1808  -794  -986  -902  2375 -1408  -280 -1608   854  -250\n",
      " -2679  -878 -2177   393 -1538   185  -816 -1706  -749  -265 -1857 -2099\n",
      "  -179 -1709 -1560   -65  -454  -643 -2027  -242 -1118 -1590 -1233  -483\n",
      " -1219 -1837 -1201 -2160   363  -462 -1195   681 -1619  -319   557 -3922\n",
      "  -761  -325   682 -1256   -20    51 -4823 -2522    65   157     0  -940\n",
      " -1240  -472  -186 -1418 -2261  -118  -672 -2312  -867   141  -701  -588\n",
      "   159 -2551    25  -687 -2630 -1921   785  -738 -2434 -2323   963 -1090\n",
      "  -592 -1533   354  -668 -3503 -6210 -2157 -2684  -451 -1917   982 -1147\n",
      "  -698   194 -1562 -1854   365  -369  -246 -1939  2465    19   700   806\n",
      "     0   226   -12  2402 -1685     7  -411 -1236 -1420  -154 -2029   -35\n",
      "  -537 -1610 -1438  1097  -140 -1620 -2102 -1406  -443  -801   338  -887\n",
      "   290  -390    56 -3154 -3359     0   287 -1058  -162    13   170  -295\n",
      " -5641  -436 -1375  -178   574   999 -1259  -628   -67 -2523  -477  1649\n",
      " -1918   -53  1109  -581 -3027  -856 -1961   140 -1218    38 -1813    31\n",
      " -1708  -210 -2697 -2257   670   132   131  -678 -1072 -1421  -862 -2480\n",
      "  1297 -1975  -431   -79 -1157  1760  1197   -17 -1711   -98  1415  -185\n",
      " -1803 -1367 -2497  -141  1338  -207 -2090 -2228   804 -1090 -1966  -328\n",
      "   948  -612  1101  -173 -3826  -412  -363   807  -542     0 -2973    59\n",
      "  -315    41 -1547 -3675  -756 -1694  -140   -42  -143  1346    31   885\n",
      " -2546  -172 -3129   -71 -1388  1511   -58 -2564  -483 -4509  -760 -4152\n",
      "     0 -1020     0 -2551    36   148 -1704   102 -1283 -3438   263 -2788\n",
      " -2593   381   721  -131  -380 -1917   426  -304    54   194  -996 -2528\n",
      "  -721 -4599   -40  3551  1284 -2124  -247   323  -168  -544 -1581   441\n",
      "   -80  -885     0   251  -537 -1198   -25  -401  -637 -1059   -38  -500\n",
      " -2741   144 -1055  -453  -316  -879 -4248     0    62  -139  -364     0\n",
      " -2526     5 -1968  -293  -660  -925   284  -279 -2177    49 -2738 -2153\n",
      " -2164 -1728  2151    34  -780   392   667 -2371  -542   250 -1854 -1489\n",
      "   305 -1642   376     0  -617  -751 -1245  -925 -1487 -2055  -653   212\n",
      "    23   -78 -1682    95 -1219    -4  -671 -2848     0 -3263 -1229  -997\n",
      "   105  -119  -925 -1167  1987 -1415 -1090  -924 -2669  -365 -2553     0\n",
      "    12   524 -1846   319    85 -1902 -1071 -2544    94 -4277 -5023 -3510\n",
      "  3460   912   314  -480  -509  -898   527 -1575 -5141 -2074   682  -532\n",
      " -1757  -311 -1090   -70   -56 -1115  -182 -1735]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_477.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_501.weight_quantized\n",
      "Shape: [128, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 82]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[103]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_501.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_501.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [ -3286  -2689   -572      0  -2390   3591  -6860  -4988   1805   2247\n",
      "      0   3137   -660  -3695  -1881   1256  -1108  -1344    250  -2925\n",
      "  -1791   2597    580  -2420  -1534   1360    745   -567    789  -3713\n",
      "   3697   -906   -853   2148   1303   2361      8   -713  -3087  -1509\n",
      "    839   3675   2078   3537      0  -1506   1510    892  -2658      0\n",
      "   1431    610      0  -1981   5298   -289    133   3164      0   5041\n",
      "   3595      0   4828   3597  -4210  -2623  -2956   3849  -7893   1229\n",
      "  -4819    325   1024      0   4814   4280  -4510  -3689  -4180  -2673\n",
      "  -3808   -659  -4890      0  -3647  -4390   2506   3515  -1400 -12978\n",
      "   2215   2119  -2452   3404    295   4274     25      0  -1878      0\n",
      "  -2862  -2858  -4152   1018   2039  -1736   3484   2554  -3120  -2325\n",
      "  -1084  -1800  -3571   1271  -1564   -186   2681   -460    456   3477\n",
      "  -3685   1305   4508   -628   2207  -2616  -2302   2356]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_501.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_524.weight_quantized\n",
      "Shape: [128, 128, 3, 3]\n",
      "Weights: [[[[122 128 132]\n",
      "   [128 128 128]\n",
      "   [141 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [120 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 116]\n",
      "   [128 134 128]\n",
      "   [115 128 139]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [121 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [137 128 128]\n",
      "   [128 146 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 118]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 107 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [135 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 118]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [143 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 150]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[132 136 128]\n",
      "   [133 137 128]\n",
      "   [134 134 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_524.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_524.bias_quantized\n",
      "Shape: [128]\n",
      "Weights: [ 3276 -6772 -2305   829   750  3144 -1635 -1288 -5470    42   176     2\n",
      "  1433  4767   358 -1297  5042  1475  -678   807 -2258  3771  2320  -585\n",
      "   702  -189 -3505   454  4482  -319 -1285  1398 -6578  3064 -2683   679\n",
      "  1512  -592  1667 -1049 -5156  -982  2889 -9459  2817  1171 -1328 -2862\n",
      " -3197  -256  1052  1884  -202  -247  -297   619  -250 -1504 -1061  -150\n",
      "  2916  -560  1719  1243   135  -347  2832   523   655 -1807  -541  -824\n",
      "    69  1434   647  4316   -50  -983  1291  3601  2034 -1652   647   766\n",
      "  -426  -790  4168   851   292    79 -2057  3569  1188 -2668 -1558  -871\n",
      "   587 -1043   907 -1200  1419 -2237   535  6551  -353  6655   545  -190\n",
      "  3053  -794 -5554  1193   196     0  3914 -2111  4400   750  3335  -927\n",
      "  -118 -2932  -477   781   925  1254 -1501 -6713]\n",
      "\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_524.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_547.weight_quantized\n",
      "Shape: [512, 128, 1, 1]\n",
      "Weights: [[[[170]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n",
      "Features for Conv_547.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_547.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [ -160  -156   531 -2727 -1106  -451    32     4  -310   423   -20   584\n",
      "  -468 -2707  -329  -416  -504  -980  -562    -3   344   -56   -90   681\n",
      "  2113  -614   -25   -37   -60 -1180   -95    76  -244  -130  -393  1152\n",
      "  -894     5    -2    -8  -340     2  1345   -68  -300   534     2    24\n",
      "   761   542  -133   394 -1298 -3697  -103 -1322   -71  -751    85 -4285\n",
      "  -485     3   571  -232  -592   -31    70   183    81  -676    14     0\n",
      "  -151   -41   -37  -136  1152   -79   -80    29  1191 -1511  -492   969\n",
      "    77  -579    73    29  -144  -906  -240  2562     3  -251    -3  -368\n",
      "    50   -22  -921 -1167  -907    28   507  -263    46    25    18  -153\n",
      "    60   317  -125  -972  -810   551  -663  -324  -444     6  1099  -106\n",
      "    29  -261    40    26  -730   -48  -649 -1285 -1605    72   297 -2539\n",
      " -2731  -117 -1058   -81  -713  1627  -301    -2   -31  -145  -971   231\n",
      "   -45  -106   763   -23  -394  -145  -312   212     6    -6   904  -538\n",
      "  -947  -468    17  -989    25     1    -7   -61     0   626     1   -65\n",
      "     2   277 -1471   292   207   -39 -2175     3    96  -402  3123    34\n",
      "    11  -236    -6     4   119   165     1 -3369    -1    10   -79  -935\n",
      "   -15    39    36  -462  -178  -418  -437  -489  -507    -1  1044  2264\n",
      " -1530    24  1393   145  -164 -1152 -1118    81    28  2075  1788 -1758\n",
      "  -119  -916   140    -4    53     3  -500  -637  -370  -614  -228 -1176\n",
      "  2360    26    -6  -764  -305  -489  -578   525    -3  -534  -681    86\n",
      " -1859  -366  -353  2260  -635   -70     4     0  -550 -1102 -1462  -106\n",
      " -3825   -13     1 -2229 -1798  2601    10 -1311   138   469   245 -2630\n",
      "  -720  -228    14  -733 -1025     0   402     0  -636  -246   -77 -2101\n",
      "    -1   132  -466   140 -1531 -1106   635    29     3  -343   686    82\n",
      "   -54  -256  -155    -2   230   208  -768  -330  -518  -114     6   -44\n",
      "  -499  -514    -1 -1342   -31  -110  -575   260   188     2 -1201     2\n",
      "  -197   -28    74  2083 -1027 -1846    49   214  -336   -14     1     3\n",
      "  1475   171   928   -48 -2358   584 -1663   477    -3   518 -1145   -44\n",
      "    -1    23  -271  -380     1  -635   681 -1367    29 -1863   589  1452\n",
      "  -635  -139  -357   900  -396    87  -339 -1044  -230  1725  3928 -1666\n",
      "  2268   286 -3092  -162  -144   471  -367 -1626  -778  -390    99  -620\n",
      "  -118  -995 -4559   -63   -72  -823 -1061    -5    37  -971   -69   -89\n",
      "     3  -655  -584    68   122 -1154  -209   176   401  -179   -54  -374\n",
      "   -29  -585   240   -13 -1208    12  -810    28  -376     4    90  -266\n",
      "  -401  -193  -520   -46   729  -672   -39  1589  -566   -18   825   515\n",
      "   -53    -4 -2465   474  1437  -847  -511   105  -131    30  -158  -311\n",
      "   -25 -1836  -265 -1164   303     1  -375  -101     2   304   -80  -634\n",
      "   336    77   175   828   530    16    -2    36  -116  -300     1   970\n",
      "  -132   682  -840 -1418  -640 -1066  -543   -46   375  -393    25   -89\n",
      "  -423  -224     7    18  -570   -95  -145  -927  -237  -154   -19 -2713\n",
      "  -107     0  -196    -6   339  -618    -4     3  2398  -921  -384  -675\n",
      "  2861  -787 -1921  -563  -980  -302   394  1123   -70     4  -386     3\n",
      "  -380   269 -2203     1   -38   -78  -151   275]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_547.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_571.weight_quantized\n",
      "Shape: [256, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[108]]\n",
      "\n",
      "  [[112]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[138]]\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[143]]]\n",
      "\n",
      "\n",
      " [[[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[165]]\n",
      "\n",
      "  [[150]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[133]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[156]]\n",
      "\n",
      "  [[106]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 96]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 512, 1, 1)\n",
      "Features for Conv_571.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_571.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [ -724  4196   315  2021   951  -492  1420 -1857 -1434   451  -122 -1894\n",
      "   -23  1825 -2865  -953 -2893 -1357  1271 -2008  2678  -539 -2817  1085\n",
      "  -221  3003   -41  2973  3500  2602  -370  -587   932 -2312  1208 -1632\n",
      " -1682 -4339 -2337   574  -844  2721  1588 -2042   -91  1141 -2373 -2136\n",
      " -5245  -699  1269  -291  -338  3500   -41 -4755   -21 -1478 -2899 -4276\n",
      "   652  3979   620  2197  1492  -211  -228  -481  -286  3544   393   391\n",
      "  1431   272 -3652   445 -2422  1008  -368  1417 -1846   291 -2168 -1325\n",
      "  1286  -282 -3866  -937 -1198 -7934 -3275 -1318  1051 -1721  -782   375\n",
      "   306 -2369 -4135 -2170 -2310 -3499 -3431  -968 -2623 -1336  -280    70\n",
      " -1973  1940 -3707  1960  -238  -943  -442  2744 -2009 -1026  3368  -552\n",
      "  -260  1977 -2347 -5084  2300  2071  -875  1182 -2255  3944   230  3072\n",
      " -3367 -2420 -2303   -98  2026  3384  -462 -2738  1451 -1747  1992   642\n",
      "   727   218  2559   930   679  -864 -4445  -331  5864   554   543 -2949\n",
      "  5526  1208 -4242 -1302   148 -5773  2484   663  2850 -1160  2401 -3044\n",
      " -1994 -3929 -2984 -1881 -2169  -392  2201  -151  1214 -2079  1507  -536\n",
      " -5434 -2792  4578   863  1706  -487 -1383 -3086  -106  -375 -1527 -1433\n",
      " -1296  -293  3919 -4630  1723   130  -175   278  2160 -1737  3318   287\n",
      " -3476   804  -145  2122 -4205 -2473  -367  3258 -4607    29  1477  -621\n",
      " -4258   221 -3142   108 -3717   740   149   495  2705  1842   343 -2570\n",
      "  1984  1995  3688  -976  2074  -367 -2192 -2377 -5764  2136 -3164    93\n",
      "  -268 -1185  1717 -1388 -1264 -2685  -782  -863  1684   564 -4229  4004\n",
      " -2643  3277  3804  -326]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_571.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_594.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[145 151 144]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 137 143]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [175 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 116 122]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 142]\n",
      "   [128 128 138]\n",
      "   [128 133 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [124 121 122]\n",
      "   [117 111 112]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 132]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 136]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 113 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 133 132]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_594.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_594.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [-2008  -970  3422   231  2858 -1612  3452  2784  -825  1680  -669  3679\n",
      "  2359   474  1274 -1810  2731  3964  1502  2671  3207 -1177  3297  3228\n",
      " -1697  3580   697   572  2767  1333  3249  3888  1753    13  -258   726\n",
      " -2671  2014   422  1360 -3292  -223 -1073 -1144 -1663   197    75  3175\n",
      "  -228  -100 -3674  2804  2792  1731 -1057 -2386  -368  2801  1383  -506\n",
      "  -713  2884  2118  2783   624  3136  -147  2692   958  1074 -1509  2279\n",
      " -1545  2762  1436   474   673   568   204   520  -153    75   308  1158\n",
      "  3491  3449 -3362 -1436 -3259    28   262   258  2262 -1019  1337  2794\n",
      "  1149   682  1115  5733  3891   409  1226 -1546  -151  2046 -1529  3355\n",
      "  -656 -3102  4113  3117  3409  4005  1553  -877  1849  -599   869  2733\n",
      " -1967  -444  1173   249  4690  1360  1963  2775   -43   434  -609  2356\n",
      " -1032  1264  2317  1050  1033  2782  -429   761 -2472  3239   342  3986\n",
      "  -259  -382 -2051  3805  1862   211  2134  2569  2871  -588 -3042   537\n",
      "  2570 -2399  -338  -364 -1369  2467   387  2349  1716  1771 -1409 -2321\n",
      "   948  -903 -1796  1977  1570   574  4852  2920   789  1551 -1399  4213\n",
      "  -465   936  1385  -281   352   -60   894   343  2877   -30  2867  4430\n",
      " -1161  4341 -1032 -1792   691 -1129  -997    -5  5731   595  4777  4327\n",
      "  3083 -1176 -3193  2963  5248 -1768  1357 -1822  1847  1706   352 -1726\n",
      "  -374   959  -823  1880 -2467  1573   443  3386  -795  2017  -542  -756\n",
      "  -338  3978  1824  1843  -464   482 -1460   300  -285  -478  -636  1149\n",
      "  2288  4235 -2945  3846   -40  2132  4528  -826  3672   359  1861   -84\n",
      "  1504  5591 -2322   396]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_594.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_617.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[138]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[144]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_617.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_617.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [ -619 -1549   266 ...  -600     0 -1085]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_617.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_639.weight_quantized\n",
      "Shape: [1024, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 512, 1, 1)\n",
      "Features for Conv_639.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_639.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [-2093  -438  1142 ... -1333     0   604]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_639.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_663.weight_quantized\n",
      "Shape: [256, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 84]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_663.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_663.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [    0  2267     0     0     0     0  -773     0 -5066   328     0     0\n",
      "   897     0     0 -2584  -223  2972     0  2393     0     0     0     0\n",
      "     0 -1360     0 -1501     0  2749  3675     0     0 -2671     0  -285\n",
      "     0  2914     0  1125     0  3454     0 -3751 -2327     0  3648  2620\n",
      "  1671  1942     0 -2860     0 -2011 -4977 -1944 -1681     0 -4293 -3263\n",
      "     0   786     0  2950     0 -4058   769     0     0     0 -4458     0\n",
      "     0 -2071  4643     0  4699 -3796     0   517 -1502  4483 -1751     0\n",
      " -3437     0     0     0  1529  3345     0     0     0     0     0  4067\n",
      "  1032     0  2851     0     0     0  1485  1112 -2850 -3720  1965 -1600\n",
      "     0  3696 -1223 -1607     0     0 -2078     0   380     0   971     0\n",
      "     0     0 -2587  -441  2581     0     0     0     0     0   480    71\n",
      "     0  -399     0     0 -6071 -3361     0   779     0 -1401     0 -3472\n",
      "  2229  2139     0     0     0     0 -5577     0  1357     0 -5403    62\n",
      "   779     0  1097  2899     0     0     0     0     0 -3314 -3834     0\n",
      "     0     0     0     0  -656   887     0 -1614  -721  2584     0     0\n",
      "  -817     0  2776     0   -95     0     0     0     0     0 -3383  2714\n",
      "     0 -1181     0     0  3071 -2697     0   821     0     0 -1524     0\n",
      "     0     0     0  1565     0     0 10154  2228  3161  1715     0 -3146\n",
      " -3479  2515     0 -3077  -829 -8000 -2848     0  2738     0     0 -3007\n",
      "  -144 -3626  1784     0     0 -3320     0     0 -4433 -1067 -2200 -3272\n",
      " -3856 17335     0     0 -3688  3106 -3019 -2803 -1783     0     0     0\n",
      " -3632     0 -3125     0]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_663.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_686.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_686.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_686.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [  -312      0  -1641   1840  -1080  -2160  -1151   -855  -3442   -257\n",
      "      0   5130  -1911   -664   1054   4368  -3003   2561    -25  -3931\n",
      "    632   -312  -3642  -6078   1149   -163      0  -1471  -3486    -59\n",
      "   -922      0      0  -3361      0   3131    487      0  -1341  -2006\n",
      "    705   -245  -3528  -2134   -540  -1107  -1809  -7127      0  -6552\n",
      "  -1511  -1146      0      0  -4429   2837  -1579      0   1702  -4743\n",
      "  -3194   4390  -2617      0   8221    822  -3525  -3273      0  -4404\n",
      "  -2445  -2777   3600  -1674    282      0      0  -2159    -28      0\n",
      "      0     42  -1752  -5911   -650    109   -989  -1268 -10549      0\n",
      "      0  -1130      0   -278      0  -3418      0  -1173  -2251  -1155\n",
      "  -1404    231  -1176  -4451   -264      0  -1007      0      0  -3408\n",
      "   1656  -3388  -4066   4529   1041   1496   2950  -2995   3575   2330\n",
      "      0  -3396   -348   -129   -920      0    745  -2148      0  -3717\n",
      "    722   -736      0  -2610  -1674     33  -1961      0    943   9489\n",
      "  -3088 -10410  -7615   -187   -331  12360  15830      0      0      0\n",
      "  -5103  -3321   2514     -2  -3270  -1237   2747      0   -415      0\n",
      "      0      0  -1468  -3033   5417  -2236  -1698  -1241   1109      0\n",
      "  -1701  -3811  -4611  -1302  -2011    905    -81      0   -836      0\n",
      "  -1266  -1374      0  -5459  -1814   3805  -2201  -1970   6088  26231\n",
      "  -7949  10600  -1644  -1717    -29      0  -1578   -957   1074  -3269\n",
      "  -4077      0  -1720      0  -1229      0   -288   6158      0   1692\n",
      "      0  -7761   -453  -3223      0  -1930  -9016  -2909   7287   1129\n",
      "  -2074  -3097  -1263  -2260    509   -894  -4610 -10766      0   -208\n",
      " -10362     49  -1520   -849  -3553      0      0     85   2789   -506\n",
      "      0  -2903  -3393  -2883  -3261    730   3707      0  -4902    219\n",
      "  -7998  -3459   -414      0   -225   8786]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_686.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_709.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[106]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[141]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[135]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_709.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_709.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [-1241  -608   701 ...   433  2335  -627]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_709.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_733.weight_quantized\n",
      "Shape: [256, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[139]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_733.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_733.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [-1977   402   434     0     0 -4102   -22     0     0     0 -2807     0\n",
      "     0     0 -4326     0   523     0     0  -562     0 -1279  -342 -1660\n",
      " -2286 -1302  6147 -2344     0  3618  1973  1688  1241  1563     0  1149\n",
      "     0   -39   575 -1647 -1662  -354 -2372 -2322     0 -1360 -1831     0\n",
      "     0 -2519   250 -4349     0 -2209 -1430 -1076   607 -1636 -1268  1729\n",
      "     0  -664     0     0     0  2943     0   721 -3088     0     0 -1750\n",
      "     0   488 -2860  -588   763  1068  2811  -647     0   355  2359 -1513\n",
      "     0  2283     0     0 -4152    34 -4983     0     0   179 -1223   582\n",
      "  2250  2745   577  -850 -3356     0     0 -1558 -1017 -3180  -704 -4861\n",
      "     0     0   902     0 -3717     0  1681 -5298 -3899 -1898 -1603 -1990\n",
      "   576     0     0 -1892  3379 -5832 -3592   145     0 -3837  -855 -1147\n",
      "     0  -671   887  -100  -119     0 -1801 -3257 -1937     0 -1427 -2434\n",
      "     0  1501  -693 -4524   -17 -2692 -3890     0 -1518     0  2131     0\n",
      "  1592   249   334    -1 -1006  -131 -2215   331 -3078   516  6282     0\n",
      "   296  2443 -3256 -1713     0     0 -1466 -1059 -1927 -2918  1173     0\n",
      "     0 -3049   986     0     0 -1065   457     0  -596  1621 -2492 -2570\n",
      "     0     0  1663     0 -1326 -1093 -3010 -1690     0   873  1684     0\n",
      "     0 -1804     0   292  -589 -1576     0  2641 -2221 -3197     0   218\n",
      "     0  -789  -570  1416 -2854 -2138 -2026     0 -1489   106     0 -1645\n",
      "  1069 -2513   -16  1341  -252 -2719 -4929     0 -1376    38     0     0\n",
      " -1391 -1050  1389  1303   303     0 -1410 -1133  1438 -3227 -1476  1858\n",
      "  4147  -446 -1351 -3606]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_733.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_756.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 148]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 126]\n",
      "   [128 132 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [134 128 135]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_756.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_756.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [ -3275      0   -169     52   -617 -10049   -908    170  -3730      0\n",
      "  -3806   2510   -180   2157      0  -6625  -2257  -1866    -63   5865\n",
      "  -1331      0    595   -966      0      0  -1912  -2138  -8078  -2139\n",
      "  -2382  -4832   -153      0    457  -3461      0   -116   1782      0\n",
      "  -2551      0   2119      0  -4918   2031  -2618   -737      0    695\n",
      "  -2541    193  -3071  -2972  -4573  -3950  -1850   -404  -4417   -668\n",
      "   -233  -2727  -3830   -280    328   3254      0   -188  -3311      0\n",
      "      0    513      0   3956   -920  -2747   -873    595   -460  -1079\n",
      "   -790  -2939   2781   2454   2080  -3056    157   -467   7361  -3219\n",
      "  -5941    153  -1809   -646  -3162  -3848  -2943  -3617  -1414  -2232\n",
      "  -6498    466   5321     11   4033      0    201      0   6085  -6817\n",
      "  -2438      0  -5906   -957   -588  -1550    758      0   -220  -2062\n",
      "  -3210   2595   7736  -3232   7325  -4083  -2205  -2407  -6771   -590\n",
      "  -4615   3884 -11936   2277  -5712   1655      0      0   3978      0\n",
      "  -5618  -3082      0  -1241  -1022  -1539  -3491    145    322   4385\n",
      "  -2519      0      0  15369  -1855  -3335  -2472      0  -1560    928\n",
      "   -265      0  -5474    800   5667   7252    457      0      0  -2886\n",
      "   -105  -2941   -249   -733  -2208  -2312  -1838      0      0   -734\n",
      "      0    365  -2981  -1944      0   -825  -1868   3314  -4093    122\n",
      "      0  -1231      0   1376      0   -509  -4473  -3815   3339  -1293\n",
      "   -243      0  -1723   1445   1204    632      0  -2917   -942   -285\n",
      "     53  -1382   -544   -508   1336   -401  -5303   -364   6225  -3448\n",
      "    635   -423  -1927    153  -2547      4      0   4818  -2525   1373\n",
      "   7250   4510    469      0      0  -2511   -832  -1107   4229    902\n",
      "   3574  -6062      0   2690      0   6184  -5824  -1844      0  -1834\n",
      "  -2225  -4583   -704      0   8517      0]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_756.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_779.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[140]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[117]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_779.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_779.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [ -727  -467 -1159 ...  -837  -559  -177]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_779.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_803.weight_quantized\n",
      "Shape: [256, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[110]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[125]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_803.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_803.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [ 1623  -583  2936     0  1718 -6357  -738     0     0 -2604 -2208  -466\n",
      "  -411     0     0 -3047 -1434     0     0 -3008 -1104     0     0 -3650\n",
      " -1280     0 -2164  -538     0  -992  -616   481     0 -1666  -981  3591\n",
      "     0 -2025 -2107 -1868     0     0 -2784     0     0     0     0 -2083\n",
      "     0     0     0     0  -469     0     0     0 -1050 -1518 -4174  -846\n",
      "  -378 -1220 -1004     0   520    -2 -2278 -1312  1376  1190  1345     0\n",
      "   857     0 -3957     0     0  1778     0 -1641   774     0     0     0\n",
      "   867     0     0 -3481     0   420     0     0  -391 -6206     0   329\n",
      "   954 -3983     0   583  -865 -1247     0 -3952     0     0 -1521    73\n",
      "     0     0   -16     0     0 -3751 -2232     0  2894   112 -3664 -2386\n",
      " -2169 -1356 -1240   733  -540 -3161     0 -2377 -1080  -295  1689 -4333\n",
      "   901  -115     0  1145   884     0 -1370   175  -754 -1828 -2310     0\n",
      "     0   769     0   390     0     0 -1295  2068     0 -5824     0 -3492\n",
      " -2346 -3780     0 -2438 -1653     0     0  2786     0   442 -3562  2900\n",
      " -1811  -211 -4588     0  -979  1388   455  2136     0  -441     0 -1198\n",
      "     0   557     0  2183     0  1597  1026     0 -6455   640  3975  1490\n",
      " -4937     0  1191     0    18  3156  -686 -6871     0  -231     0  1117\n",
      " -4545     0  1687     0     0  -926     0     0  1664 -1345 -1118     0\n",
      " -3075  2126     0 -1977 -1264  1343     0     0  -265  2559  2588 -1165\n",
      "  1500 -1686 -1480     0     0   567     0  2596 -3883   200  -904 -2745\n",
      "     0   333   585     0 -3043     0 -2604  2487   751 -2634 -1215  -245\n",
      " -1153   939  1470     0]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_803.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_826.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[104 128 173]\n",
      "   [104 128 146]\n",
      "   [ 88  86 128]]\n",
      "\n",
      "  [[128 128 151]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 110 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 120]\n",
      "   [128 128 128]\n",
      "   [128  97 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [141 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[107 128 111]\n",
      "   [128 128 128]\n",
      "   [128 150 164]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 106 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_826.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_826.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [ -3907  -3824   -973   2236   -204      0   4791  -8509  -6147      0\n",
      "      0      0   2084  -8670   -454   3618  -1171      0      0      0\n",
      "  -2290      0    459  -2495      0      0    413   1327    668    959\n",
      "  -5270   2234  -2366      0  -3043  -2413    303  -1424  -3295   3290\n",
      "  -1118      0   4390      0  -1568  -8348    841      0   2045      0\n",
      "  -4745  -5384   -994   2193      0   6864   4976  -2649   2661  -2865\n",
      "   1620   7244      0   -567  -2783  -8214   -110  -4483      0      0\n",
      "   2210      0  -1822      0  -3001    270   1627      0  -5752  -2630\n",
      "  -5216  -4764  -1999      0  -2340  -5122    158  -1356      0  -2003\n",
      "      0 -10600  -2665   1012   3671      0   1059     67  -3929   2689\n",
      "      0   3339      0   2696    148    -47      0      0   4236      0\n",
      "  -9159      0  -3674  -2475      0      0    161  -1613  -1052     33\n",
      "  -1034   -288      0   -148   3375  -1490  -3818  -2805   1246  -6610\n",
      "     39  -3094  -2048  -1667      0   1329     12      0   2184   -746\n",
      "  -2057   3740      0  -2740   -215      0      0   -116   4309    771\n",
      "      0      0  -3507  -1957   7220      0  -6196   -869   -177   1412\n",
      "    672  -4480      0    246      0   4552  -1395   -447      0   1487\n",
      "   3129   2323   -486      0  -2316   2600  -3726  -2434  -3544  -1135\n",
      "   -878      0    932   5525  -6054      0  -1428   -415      0  -7605\n",
      "   -180    863  -5716      0    825  -1641      0   -231    -94   1423\n",
      "  -1748    956  -2155   -406   4547  -2514   -859   1132  -3194   2500\n",
      "   -478     84  -2267   4484      0   2041  -2558    312   6876  -1372\n",
      "      0      0  -7021      0    502  -4804   2525   2125  -1020      0\n",
      "   -942   2703    237   2152   -766   3829      0    695  -2564      0\n",
      "   -262    265      0  -8112    204   -346  -1428   4572      0      0\n",
      "      0   -129      0    246  -2784  -1453]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_826.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_849.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[111]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[112]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_849.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_849.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [-1124 -1032   -14 ... -1939   424    58]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_849.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_873.weight_quantized\n",
      "Shape: [256, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[151]]\n",
      "\n",
      "  [[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[140]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_873.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_873.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [    0 -2699 -1020     0     0  1080 -3317     0 -1886     0 -3968  -947\n",
      "     0 -1558     0     0     0   -90  1893 -1314     0 -1286 -3360     0\n",
      "     0     0 -1944  -546  1864  1417  -917 -3085     0  -804     0  -260\n",
      " -1959  -828 -1093   -70     0 -1135  -447     0 -3684 -1810 -1110 -1645\n",
      "     0     0     0     0     0  1747     0     0  -882     0 -1577  -250\n",
      "  1430     0 -1243     0 -1115     0 -2024  -645  -175     0 -1179   -35\n",
      "     0     0 -1150  -710     0     0  -252    40   479     0 -1485     0\n",
      "     0     0     0 -2493     0  2662     0 -1924     0    63     0     0\n",
      " -1475     0     0     0     0     0 -3457     0  -273 -4573     0     0\n",
      "   864  -938     0  2109  2291  -540 -1703    -8  -807  -589     0     0\n",
      "   118   833  1072  -706  -600 -4169 -1957  -766     0 -1417   643     0\n",
      "  -291 -2524 -1646  2025  1120     0   137     0     0     0  -365     0\n",
      "  -140  1873 -1938   -27     0     0     0     0 -2516 -1061     0     0\n",
      "  1916  1027 -2540 -1701 -2995 -2382  -716 -1926     0 -4661  -769 -2460\n",
      "     0 -1281     0 -1069  -794 -1607     0  -498     0  -891 -1695 -3073\n",
      "     0  -678     0  1925     0     0   375  -501  -591  -368  -235 -4047\n",
      "  -226 -3147  -306  -817  -821    41   651  -295     0  -156 -1937     0\n",
      " -1424     0  -944   682  1033 -3554  -977     0 -1370     0 -2343     0\n",
      "    99 -1863  -219  1478     0     0  -577     0   -44  -979  -407     0\n",
      " -1844     0   154  -643     0     0  -151     0    52   916     0     0\n",
      "     0 -1225     0     0     0   341 -3307     0     0     0   274  -395\n",
      "  -321     0     0     0]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_873.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_896.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 142 145]\n",
      "   [128 128 128]\n",
      "   [128 128 112]]\n",
      "\n",
      "  [[128 128 116]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 162 148]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128  94]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[117 128 128]\n",
      "   [128 128 113]\n",
      "   [128 128 112]]\n",
      "\n",
      "  [[113 128 128]\n",
      "   [128 128 137]\n",
      "   [117 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_896.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_896.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [  -78   184   814     0 -6360   996     0     0     0     0     0     0\n",
      "   530     0     0   469  -356 -1273     0  -840     0     0  -997 -1103\n",
      "   709     0     0 -1347 -1501  2702     0  -132  -811 -4289     0 -1634\n",
      "  1299  -781 -3255     0  2663   853 -3153  -141 -1338  1245  -285     0\n",
      "     0 -7787 -2073     0  2488 -3076   -48   627  -491 -3181     0 -1385\n",
      " -1009 -5773     0   103     0 -5758     0  2236  2710     0 -1785     0\n",
      "   596 -1859  4358 -1064  3659   666 -1249     0   184  -338     0  -422\n",
      "     0 -2243   -95  2090 -2096  2531     0   369  1151 -2237  1498   375\n",
      "   328 -2156  1483     0     0   998 -2054     0     0 -1755     0  -735\n",
      "  4447    12     0 -2657  -371     0  4651     0  -423  -330  3569     0\n",
      " -2829  -366 -2896     0  1674     0  1803 -2419  2230     0 -2837 -6761\n",
      "     0   -95 -2115  1264  -224     0 -3364     0  -135     0   866     0\n",
      "   170 -1049 -1891  1005     0 -1602    40     0 -1050 -1304  1784 -2130\n",
      " -2718  1787     0   228  -194  1003  -628  1276 -1396  -318 -3501   -16\n",
      "  3028  3535   436   371     0  -875  1398 -1426   418     0 -1461 -4761\n",
      " -1217 -2288   -47     0  3424  -811 -1388   838     0     0     0     0\n",
      "     0     0  3196   547     0     0 -3063  -271  3516     0  -379     0\n",
      "  1068     0 -1040 -1203  3355 -2258  4685 -2658     0  3146     0     0\n",
      "  -231  1936   -65     0 -1557 -2153  2944 -1123     0  -992  -276     0\n",
      "  5925  -979     0     0     0  -572     0 -1730     0     0 -1078 -4169\n",
      "  1082     0 -1568     0   132     0  3868 -2811     0   194  -502 -2042\n",
      "  1368   885  2100  5422]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_896.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_919.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[118]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_919.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_919.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [-1736   -90  -522 ...  -274  -788   -12]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_919.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_943.weight_quantized\n",
      "Shape: [256, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_943.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_943.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [-2821 -1184     0 -1112 -1215 -1287   272     0  1230  1875 -1535  -857\n",
      "   208     0  1126   726  -469  1513 -1714     0     0 -1768 -2223 -2188\n",
      "    24 -2169     0 -1920  1203     0     0     0  -577     0     0 -5262\n",
      "     0     0     0  -147 -2097     0 -1865  -330 -1570     0 -1992  3000\n",
      "     0 -2560 -2430     0     0     0 -1724 -1726     0   714     0  -248\n",
      "  -880  -952     0 -2401  2781     0 -3527  1556     0 -1152     0 -2350\n",
      "  1541 -1227 -1863  -885     0  -933     0  -922 -2875  -720     0  -104\n",
      "   673 -1839   239 -1321  -974     0   291 -1900     0     0     0     0\n",
      " -2310  3762     0  -672 -4890     0     0   437 -2072 -1546     0   236\n",
      "  -613 -1111     0     0 -2701 -2946 -1517     0     0  -608     0  -847\n",
      "     0     0  -645     0  -296     0     0 -1490 -1644   196     0   386\n",
      "     0  -733 -2661  1208 -1183     0   450 -2307 -2018     0     0 -1198\n",
      "  -635  -389  -271   629     0     0     0     0  -338     0     0 -4012\n",
      " -2032  -535 -1514     0  -161     0  1867  1214     0  -482     0     0\n",
      "     0   179     0     0  -819     0     0 -1556 -3185   180  1129     0\n",
      "  1874     0     0     0  -236 -1549 -2173 -1628     0     0     0     0\n",
      "  -802 -2671 -2238     0   651  -476 -1488     0     0  -254 -2396 -1006\n",
      " -1246 -1601  -233  1250 -1386     0     0  -289  -931     0 -1457 -1377\n",
      "     0     0  1929 -2037  -719 -2877   445   213     0   576   844  -353\n",
      "   535     0     0   285  -387   718 -1659    76     0   238     0     0\n",
      "     0 -1232  -403   272 -1179  -526 -5243 -1456  1269     0     0     0\n",
      "   210     0 -1889 -3983]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_943.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_966.weight_quantized\n",
      "Shape: [256, 256, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 128]\n",
      "   [118 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 148 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [144 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n",
      "Features for Conv_966.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_966.bias_quantized\n",
      "Shape: [256]\n",
      "Weights: [    0     0 -3619     0 -1040     0     0 -2499  -184     0  -901   574\n",
      " -1883     0   230     0     0 -3108     0 -1208  1179  2443  2426     0\n",
      "  2470 -1246  -533 -1113     0     0 -2847     0 -1318 -2203   598     0\n",
      "  -616 -1631   -20     0     0  -771     0     0   787     0 -1827     0\n",
      "   330     0     0     0 -6523 -1331 -1001 -5680     0     0     0   541\n",
      "     0     0  -955 -1302 -1241     0     0   582   -27  1629 -2442 -1010\n",
      "     0     0     0  3651  1076   864  -532     0     0   678   456 -1889\n",
      "     0     0  4537     0 -5900  3240  1260 -2282     0     0     0   355\n",
      " -1278   -97  1668  -676     0 -1074 -1288 -1079     0  -585     0  -144\n",
      "     0     0     0     0  -930     0     0  1774  -319     0     0     0\n",
      "  -219     0  2315     0  -421     0   274     0     0 -3421     0  1701\n",
      " -2919     0 -1064     0  -916  -880 -5429   342   191     0  -942 -1501\n",
      "  -580 -1148     0     0     0  -556     0     0     0  2059  2093   259\n",
      "     0 -4406  2225     0   -74 -1480     0 -1146     0  1083     0     0\n",
      "     0  -493  -129   562  3209  1037  4491 -1723     0   332  -794     0\n",
      " -1053 -4047     0     0  1147 -1318  -870  2683  2848     0  -634  2003\n",
      "  -398  -689  1493  -804   960  -788 -1634 -1242     0 -1029     0     0\n",
      " -1269     0 -1982  1784  2624   111  2404 -1251  1067  -258 -1327     0\n",
      "     0 -1064     0     0  -226  3188     0  -928     0 -2981 -2501  1386\n",
      " -3101 -1917  -923   976     0  1863     0   548     0  2904     0 -2730\n",
      "     0 -1342     0  -901   425  2133   562     0     0   199   852   817\n",
      " -1367  -903     0     0]\n",
      "\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_966.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_989.weight_quantized\n",
      "Shape: [1024, 256, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_989.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_989.bias_quantized\n",
      "Shape: [1024]\n",
      "Weights: [-148 -582 -349 ...   42  244  131]\n",
      "\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_989.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1013.weight_quantized\n",
      "Shape: [512, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[145]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 1024, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1013.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_1013.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [  876 -1204   788 -4608  -438   208  -430  1448 -3987 -1064 -1946     0\n",
      "     0 -1555   508   122   -79   547 -1191 -1824   360  -738  1157  -350\n",
      " -2957  -673  -315 -1861 -1074  -769     0   -60  -195 -1872  -508 -1321\n",
      " -1868  -899  -385 -2042 -2275   706  -195   134     0  -577 -1439   601\n",
      " -5189  -434 -1193 -1991  -494 -2779 -1773   375 -2548    10  -584  -901\n",
      "   137 -2997  -785  -699   711  -708 -1501  1250   816 -1203     0   481\n",
      "   503  -469 -1709 -2496   867 -1565 -2951 -1940 -1086  -115  -343 -1522\n",
      "  -951  -562   620  -312 -1717 -1275 -1688   301 -1960  -420   194   -38\n",
      " -1291  1132 -2778   739 -1473   680  1512  -614 -1410  -308   616   686\n",
      "    94  -153 -1346  -722  -325  -137  1558   275    21   512     0 -1136\n",
      "     0   -86 -3897  -422   967 -3049   734 -1031 -1519  -105 -1427   -28\n",
      " -1753   357 -1861  -477   328 -1182 -1118   -95 -2460  -859   446   406\n",
      " -1136 -1696  -866  -332 -1320 -3529   744 -1483  -226   985     0   101\n",
      " -2174  -384   992 -1396  -833 -1123 -3767 -3529  -454  -539     0 -1443\n",
      "     0 -1326 -1469 -1581   593  -895 -1818 -1421 -2312 -1786   300   629\n",
      "   -97   161  -558  -656  -783 -1991  -341 -1047 -1941   562 -1693 -1573\n",
      "  -377  -545     0  -229  -702    40 -1212     0     0  -319   185   322\n",
      "  -948 -1731 -1209  -411  -201 -1228  -519   932   583 -1153 -1041   -26\n",
      "  -126 -3102  -917  -526   509   487  1111  -361  -972  -878  -728   480\n",
      " -1165   237  -252  -480  -467 -1073 -1108   966   317     0  -303  1327\n",
      "   -77 -1990 -1024 -2151  -200  -638 -2296     0   232  -508  -726  -613\n",
      "  -670 -1193  -933   701   -51  -690     0  -259 -1709  1540  2252  -281\n",
      "  1726   102  -750 -3432  -356  -229 -1756 -1094   807  -967  -857     0\n",
      " -1386  -925 -1098   440     0  -896  -450 -2629   122 -1758  -416  -963\n",
      "  -597  -971 -2183  -467   524   611     0 -1177    60 -1181   783   184\n",
      "   407  -945   703  -311    62   165   872   785  -419 -1436 -2269 -1381\n",
      "    87     0 -1460   822  -836   138  -329 -1623 -1034  -859   415  1170\n",
      "  -755 -1021     0  -475 -1340   546   460  -984   903     0   364  -698\n",
      " -1564 -2834  -564 -2432  -296   922 -2244   385  -428    76 -2776  -727\n",
      "  1261  -523  -324  -601  -557  -220  -161  -284  1875  -700 -1968  -297\n",
      " -2218 -1202  -387  -426   140   131     0 -1869 -1325  -911  -662 -2717\n",
      "   207 -1446 -2738  -781  -130 -1120  1591   847  1191  -207  1668  -854\n",
      "  -551  1914 -2020   819 -1270  -872  -590     0  -488     0  -367 -1358\n",
      "  -780 -2960     0  1177 -2314 -3817   620  -168  -965 -1559  -829 -2900\n",
      "  -236 -1043 -3187     0 -1726   467 -1703   522   322     0  -756  -124\n",
      "   142  -860 -2716 -1445 -2138   919 -1031 -4187 -2152 -1311 -1332     0\n",
      "     0 -1685   262  -533   626  -629  -731   361   682 -1861 -1434 -2353\n",
      "  -247   626  -417 -2733 -2181  -498   928   367 -1155  -510   -74  -364\n",
      "     0  -949 -1787 -1354   321     0   204 -1378  -515 -1235  -390   922\n",
      " -1301   172  -901   986    18 -1199 -3861 -1580  2272  -864 -1058 -1617\n",
      "  -905    32   433 -2807 -1259   277   701  -116  1291  -412  -573 -1382\n",
      "  -724 -1443  -815 -1937   311  1174 -1161 -1629    59   153 -1315 -2201\n",
      " -2285    97  -542  -980 -1379  -673     0   405]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1013.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1036.weight_quantized\n",
      "Shape: [512, 512, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 112 114]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1036.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 4608\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4608.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999997832\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.00021701388888884174\n",
      "\n",
      "\n",
      "Layer: Conv_1036.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [ -605  -654  -242  -328 -1208  -363  -558  1257  -109  -341 -1306  -446\n",
      "  -283  -991  -462   -38  -243  -487  -193  -383  -237  1810  -715  -543\n",
      "  -311  -433  -355  -357  -311 -1502  -498  -488 -1244   -90   575  -185\n",
      "  -209  -310  -293  -979  -696  -918  -528  -752  -723  -559  -380  -192\n",
      "  -486  -482 -1075  -530  -114  -688   -32  -174  -599 -1170   231  -500\n",
      " -1380   -98  -688   -85  -159  -829  -747 -1349  -462 -1515  -330  -448\n",
      "  -437   -49  -509 -1092  -303    64 -1510 -2737   -48  -367   -96  -295\n",
      "     7  -756  -798   -46  -608  1246     0  -279  -416  -523  -510   147\n",
      "   148  -320  -203  -395   765  -221  -120  -230  -689  -543    24  -424\n",
      " -1823  -414  -541  -887  -175   676  -343   -64   -72  -738 -1064     0\n",
      "  -216  -361  -207  -613  -107 -1007  1210  -276  -774   -39  -356  -397\n",
      "  -725  -263  -601  -278  -694  -514   130  -337  -389  -533  -202  -180\n",
      "  -136  -645  -834  -450  -679  -653  -333   369    33  -159 -1428  -102\n",
      "  -324  -713  -562    32  -428  -279   -91 -1258  -433     0  -514  -559\n",
      " -1068  -556  -355  -347 -1963  -438   -99  -537  -567  -462  -398  -215\n",
      " -1706  1110  -666  -202  -174  -587  -136  -217  -122  -168  -733  -644\n",
      "   574  -327  -666   -97  -358 -1059  -236  -684  -191 -2034  -730    74\n",
      "   -33  -386 -1846  -256  -702  -792  -283  -436  -287    -9 -1056   251\n",
      "    15   -44  -865  -672  -704  -414  -529  -595 -1693  -177  -374   -72\n",
      "  -351  1679  -379 -1131  -329  -163  -293  -167  -208  -685  -318  -153\n",
      "  -945  -260  1664  -418  -641  -155  -534  -714  -333  -631  -284  -378\n",
      "  -453  -315  -501  -404  -416  -512  -583  -390  -461  1975   341   279\n",
      "  -122  -284  -882  -232  -260    36  -149   317    74  -199  -413  -151\n",
      "  -524  1453  -221  -353  -337     0  2219  -807  -371  -645   241  -321\n",
      "  -213  -623  -440  -337   -84  -916  -597   437  -277  -286  -139  -870\n",
      " -1274   -78  -442  -219  -418  -511  -239  -810  1693  -758  -114    36\n",
      "  -620   -87  -174  -101     0  -708   -93  -271  -379  -241  -404 -1360\n",
      "  -329  -170    37   121   -83  -545  -288     0  -233  -236 -1365  -367\n",
      "  -219  -239  -224  -441  -675  -144  -844  -691 -1088  -355  -312  -212\n",
      "  -126 -1236  -603   715  -549  -664  -104  -234     0 -2267  -466   149\n",
      "  -770  -505   120   -50  -373   -97  -660  -850  -916  -295     4 -1509\n",
      "  -245 -1523  -823  -408 -1585     0 -1305  -167  -363  -195  -598 -1258\n",
      " -1008 -2303  -478  -726  -562   -70  -275  -642  -188  -443    53   -14\n",
      " -1504  -891   -55  -368 -1214  -416  -185  -490  -161  -394   -82   -34\n",
      "  -265  -315  -577   -13  -350 -1363  -195  -181  -189  -137  -245  -109\n",
      "  -490  -379  -367  -608 -1038  -603  -220 -1115  -211     1  -481  -295\n",
      "  -507  -766  -528  -158 -1265  -402  -405  -428  -611  -100 -1238  -622\n",
      "  -547  -290  -179  -510  -226  -845  -482  -193  -432  -798  -266  -489\n",
      "  -463     0  -159  -209  -722  -375  -233  -869 -1871  2644  -255  -181\n",
      "   569  -779   205  -281 -1024  -226  -856  -191  -225  -371  -156  -143\n",
      "  -583 -2240  -253    19  1846  -409  -394  -748  -401 -1192  -319  -129\n",
      "  -991  -290  -519  -420 -3274  -459  -391  -550     0  -414  2959  -450\n",
      "  -457  -400  -311  -222   -11  -521  -477  -235]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1036.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1059.weight_quantized\n",
      "Shape: [2048, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1059.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1059.bias_quantized\n",
      "Shape: [2048]\n",
      "Weights: [ 581    0 -672 ...    0    0    0]\n",
      "\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1059.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1081.weight_quantized\n",
      "Shape: [2048, 1024, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (2048, 1024, 1, 1)\n",
      "Features for Conv_1081.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_1081.bias_quantized\n",
      "Shape: [2048]\n",
      "Weights: [-297    0 -140 ...    0    0    0]\n",
      "\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1081.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1105.weight_quantized\n",
      "Shape: [512, 2048, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 2048, 1, 1)\n",
      "Features for Conv_1105.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2048\n",
      "  nnz_max: 2048\n",
      "  nnz_avg: 2048.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2048\n",
      "  bw_max: 2048\n",
      "  bw_avg: 2048.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995116\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.00048828124999976153\n",
      "\n",
      "\n",
      "Layer: Conv_1105.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [    0  -700     0     0     0  -140   187     0     0   512     0   373\n",
      "     0   938     0   202   467     0     0     0   267   407     0     0\n",
      "     0   317     0  -203     0     0     0  -346     0     0  -133     0\n",
      "   -45   268     0     0     0    21    76  -276   234    72     0     0\n",
      "   132     0     0     0     0     0     0   289  -177     0     0     0\n",
      "     0  -259     0   140     0   425     0   741     0  1032   490     0\n",
      "     0  -353     0     0     0     0   295   582     0  -259     0     0\n",
      "     0   365     0  -170     0   -85     0     0    30   455   459   -18\n",
      "     0     0     0   -75   556     0  -921   -96   511   -67  -758     0\n",
      "   297     0     0     0     0     0   804     0     0   -87     0     0\n",
      "     0   344     0  -123  -261     0     0     0  1159   611     0     0\n",
      "   206     0   321     0   206     0  1709     0   227     0     0     0\n",
      "  -860     0     0     0     0     0     0     0   318     0     0     0\n",
      "   -56     0   743    41   500     0     0     0     0     0     0     0\n",
      "     0     0   487     0     0     0     0     0     0   913     0  -127\n",
      "     0     0     0     0     0     0  -261     0   272  -446     0     0\n",
      "   -49     0     0     0     0     0     0     0     0     0   -40     0\n",
      "     0     0     0     0     0     0     0     0     0     0   -61   177\n",
      "     0     0   503     0   556  -865     0   681     0     0  -356   970\n",
      "     0     0   122     0     0   106     0     0     0     0     0     0\n",
      "     0     0    81     0   534     0   673     0     0     0     0     0\n",
      "   394     0  -308     0   250    60     0    54   606     0     0   215\n",
      "     0     0     0  -224  1030     0   136     0  -716     0 -1146     0\n",
      "   105     0   214     0   474     0     0    34    13  2428     0     0\n",
      "     0     0  -340     0     0     0     0   737     0    26     0     0\n",
      "  -145     0     0   113     0     0  -139     0     0     0     0  -347\n",
      "    90     0     0     0     0     0     0  -118     0     0  -341   246\n",
      "     0   747     0     0   851   -92     0  -657     0  -355     0     0\n",
      "     0     0 -1243     0     0     0     0     0     0     0   -24   533\n",
      "     0     0   257  -199   902     0     0  -196     0     0     0     0\n",
      "   672     0     0     0     0   635     0   385     0     0     0  -114\n",
      "     0     0     0   606   209     0     0     0     0     0   182     0\n",
      "   200     0    92   408   464     0     0     0     0  -584  -173     0\n",
      "   186     0   164     0   153     0     0     0     0 -1031  -528     0\n",
      "  -966     0   504    60     0   373     0     0     0   324   407     0\n",
      "   -28  -692   304     0     0     0   307     0     0     0    48   548\n",
      "     0  -371   549     0     0   294     0    53     0   -10     0     0\n",
      "   473   585  -506     0     0     0   448     0     0  -606     0  -506\n",
      "     0   401     0  -708     0   -58     0     0   452  -694     0     0\n",
      "     0     0   653     0     0     0     0   -17     0     0     0   863\n",
      "     0     0     0   673   400  -324     0     0     0     0     0     0\n",
      "     0  -778   392     0     0     0     0   541     0     0  -185    33\n",
      "   460     0     0     0   466  -500     0     0]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1105.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1128.weight_quantized\n",
      "Shape: [512, 512, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 138 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1128.weight_quantized:\n",
      "  density: 0.9999995761447482\n",
      "  nnz_min: 4607\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4607.998046875\n",
      "  nnz_sd: 0.044150994357255134\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999995761445315\n",
      "  scatter_sd: 9.581378983777146e-06\n",
      "  clustering_avg: 0.0002174379281454624\n",
      "\n",
      "\n",
      "Layer: Conv_1128.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [  113  -611  -630   -38   842     0     0 -1419     0  -966     0 -2003\n",
      "     0   662   661 -1526     0    12  -787  -476     0 -2105     0     0\n",
      "     0     0  -339 -2518 -2716     0   783     0     0  2674     0 -1217\n",
      " -1657 -2598 -2423 -1025   577 -1654 -2470 -1548     0 -7072  -193 -1439\n",
      "     0     0 -1927     0 -3192 -1752 -2626     0     0 -2543 -1963 -1568\n",
      " -1097 -5826     0  -880  2706     0  -875 -3858 -1126  2319     0     0\n",
      "    -9 -5719 -1105     0  -823 -2110 -1445   254 -1352  -116     0  -540\n",
      "     0     0  1959  -868 -3885 -1827 -2245  -823  -772     0     0 -1085\n",
      " -2116     0     0  1707     0  2111 -7258     0   633 -2605 -2790     0\n",
      "     0     0     0   940     0 -2253 -3871 -2129     0  -433     0   198\n",
      " -2134  -778  6408   290 -1513  -627  -512  -529     0  1077  -772   -50\n",
      "     0 -1728 -1966  -444     0  -222 -1224  1055     0 -2983     0     0\n",
      "     0     0  -847 -1915  2668  -312 -1582     0  -382     0 -1815 -1539\n",
      "  1355 -3532 -1994 -3784 -2035 -3350     0 -2197     0     0     0     0\n",
      "  -938    12     0 -1773 -1609     0  -165     0     0     0  1885   952\n",
      "  -465 -2311  3014 -2468 -3585 -2674   162 -2232 -1311 -9946 -3674     0\n",
      " -3035     0     0  -338  1073 -1019 -2024  -836   -95   848 -2573 -3164\n",
      " -1284 -1098 -1543     0 -2606     0 -1095  -107 -1692    77     0     0\n",
      " -1339  1844 -6686 -2883     0  -294 -2535 -1656 -3315  2565 -1885    94\n",
      "   519     0  -940   456   107     0     0     0    51  -180     0     0\n",
      "     0 -1098  -643     0  1662 -6212 -1892     0 -3189 -2131     0     0\n",
      "  1220 -2041 -1948 -2805   786 -1953     8     0 -1653 -3583     0 -5773\n",
      "     0     0   485 -3018  1846     0  2036     0 -1085  1624     0 -1906\n",
      "  -990  1750     0  2038 -1293 -9614 -3041     0 -3606  -751     0     0\n",
      "   983     0 -2429 -3706  1648 -1654  3937  -156 -1683 -1694 -1051  1680\n",
      "     0     0     0  -479 -1064  -170  -808 -1062 -1544     0 -3210 -1939\n",
      "  -933 -3294     0     0  -867   423 -2160     0 -2398 -1436  -779     0\n",
      "   521     0 -4960 -1048  -855 -2904 -4343 -1474 -3010     0  -597     0\n",
      "  -151     0 -3087  -983     0 -2078     0    74   703 -1090     0   809\n",
      " -1112     0     0 -3259     0   860  -147   274  -357 -1155 -4298 -1339\n",
      "  -506  -253 -1452 -1941 -2403 -1008     0 -4746 -2480     0 -2653     0\n",
      " -2834 -3244  -404 -1086 -2460     0  -619   -42  1041     0  1568  3261\n",
      "  1120   169 -1627  -116   572     0     0     0 -2721 -2465  -483 -1530\n",
      " -3234  -777 -2515 -2594 -1643  -921 -3094 -1903  4145     0     0     0\n",
      " -1848     0 -1167   -73     0     0 -1807 -1005 -3328  1231   227  -747\n",
      "     0     0     0  2049 -2093     0     0     0  2125 -1256     0     0\n",
      " -3719 -1904  2702 -2481  2932  3023  1925 -2549  -850  -430     0 -1835\n",
      "   196  -539 -2425  1973 -2978 -2516 -1461 -3119     0 -1950     0  -409\n",
      "     0     0     0 -3053 -2510     0     0     0    90 -2289  1719     0\n",
      " -1699 -2060  -538 -2496 -1256 -2185     0 -2757  1715 -2173 -1424 -2754\n",
      "  -512     0 -1533  -748 -5165    51 -1311  -710    59     0 -8186 -1744\n",
      "     0 -1126 -1623 -2806     0     0     0     0  1787     0     0 -1444\n",
      "     0  -451 -2343   276     0  2527   373 -1223]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1128.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1151.weight_quantized\n",
      "Shape: [2048, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[138]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1151.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1151.bias_quantized\n",
      "Shape: [2048]\n",
      "Weights: [  209     0 -1182 ...     0     0     0]\n",
      "\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1151.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1175.weight_quantized\n",
      "Shape: [512, 2048, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 2048, 1, 1)\n",
      "Features for Conv_1175.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2048\n",
      "  nnz_max: 2048\n",
      "  nnz_avg: 2048.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2048\n",
      "  bw_max: 2048\n",
      "  bw_avg: 2048.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995116\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.00048828124999976153\n",
      "\n",
      "\n",
      "Layer: Conv_1175.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [ -459  -382  -835  -616  -984  -849  -587  -639  -864  -980  -107     0\n",
      "  -716  -103  -934  -405  -446  -573  -577     0  -708  -754  -638  -470\n",
      "     0  -244  -848  -494  -904  -610  -980  -542  -870  -596  -422  -806\n",
      "  -955  -630  -288  -569  -356  -408  -521  -427  -643  -667  -962  -512\n",
      "  -551  -735  -727  -644  -844   945     0  -444  -337  -417  -333  -441\n",
      "  -472  -724    34  -763  -901  -455     0     0     0  -398  -376   -47\n",
      "  -671  -739  -620  -576 -1003  -117 -1149  -491  -696  -814  -432  -645\n",
      "  -390  -736  -319  -565  -202  -539  -538  -697  -328  -834  -588  -765\n",
      "  -334  -802  -781  -367  -279     0  -321  -661     0  -472  -741  -646\n",
      "  -781  -604  -694  -675  -873  -500  -598 -1415     0  -625  -596     0\n",
      "  -766  -558  -561 -1153     0  -631  -388  -202  -477  -551  -629  -736\n",
      "  -711  -619  -839  -777  -599  -667     0  -350  -685  -590  -515  -342\n",
      "  -579  -843     0  -568     0  -499  -300  -540     0  -643  -870  -618\n",
      "  -707  -570  -911  -514  -767  -803  -281  -556  -575  -767  -238  -331\n",
      "  -793  -570  -677  -659  -427  -800 -1042  -504  -573  -835     0  -802\n",
      "  -602  -315     0  -579     0     0  -882     0     0  -763  -731  -540\n",
      "  -149  -504  -632  -620  -599  -395  -918  -555  -619  -681  -806  -815\n",
      "  -572  -631  -834     0  -664  -747  -923  -549  -846  -723  -523  -758\n",
      "  -296  -809  -483  -254  -781  -756  -552  -652  -356     0  -358  -605\n",
      "  -550  -338  -430  -576  -426  -602     0  -887  -118   -16  -858  -437\n",
      "  -394  -401  -366     0  -897  -831  -348  -746  -409  -490  -714  -665\n",
      "  -344  -343  -384  -782  -890  -709  -589  -845  -365  -967    -4  -663\n",
      "     0  -700  -638  -402  -610  -218  -719  -712  -471  -286  -747  -297\n",
      "     0  -639  -571  -353  -596     0  -685 -1138  -680  -725  -666  -674\n",
      "  -534     0  -512  -711  -160  -731  -921  -440  -630  -548  -553  -477\n",
      "  -756  -903  -723  -421  -350  -219  -348  -457  -716  -807  -533  -580\n",
      "  -720  -520  -606  -741  -409  -526  -468  -476  -226  -377  -614  -558\n",
      "     0  -806  -631  -812  -553  -745  -242  -705  -692  -798  -372  -832\n",
      "  -398  -522  -430  -635  -428  -508  -614  -448  -693  -425     0  -596\n",
      "  -963     0     0  -621  -241  -696  -760  -779     0  -795  -402  -819\n",
      "  -660  -631   -54  -641  -277  -814  -600  -549  -696  -826  -770 -1227\n",
      "  -500     0  -376  -678  -177  -176  -867  -835  -915  -739  -365  -627\n",
      "  -649  -139  -653  -957  -820  -997  -572  -753  -713  -731  -821  -744\n",
      "  -785  -324  -518  -505  -381  -865  -630  -564  -279  -264  -216  -580\n",
      "  -707  -418  -427  -921  -501  -380  -478  -475  -999  -479  -921  -635\n",
      "  -730     0  -356  -747  -849  -850  -264  -518  -537  -818  -320  -764\n",
      "  -411 -1158  -473  -270  -762  -566  -575  -761  -219  -512  -643  -790\n",
      "  -515  -442     0  -565  -467  -633  -787  -474  -477  -505  -590  -924\n",
      "  -231  -495     0  -599  -653  -417  -525  -478  -198  -823  -540  -515\n",
      "  -921  -874  -687  -585  -219  -433  -683  -461  -805  -697  -568  -177\n",
      "  -733  -570 -1041  -700  -568  -543     0  -825  -605  -671  -862  -802\n",
      "     0  -795  -710  -563  -797  -160  -633  -201  -534  -695  -740  -500\n",
      "   -81  -486  -282  -192    90  -618  -718  -561]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1175.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1198.weight_quantized\n",
      "Shape: [512, 512, 3, 3]\n",
      "Weights: [[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1198.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 4608\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4608.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999997832\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.00021701388888884174\n",
      "\n",
      "\n",
      "Layer: Conv_1198.bias_quantized\n",
      "Shape: [512]\n",
      "Weights: [    6  -141    15   -37   -35    33    36     0   -70  -103  -245   -73\n",
      "    -1   -70    32   -64  -458   -97   -36    45  -112  -113   -25  -150\n",
      "     0   -25    40     0   -33    20     0   -44  -159  -109   -70  -310\n",
      "   -71    48   -94    46   -52  -143  -184   -65   -16  -278   -13    12\n",
      "   -10   -80    23  -168    17   -30   -50   -30  -138  -136    19    44\n",
      "     0   110   -70    59  -179  -269     0   -51   -73    16     0     0\n",
      "    42   -43   418    23   -32   -67    50   -58    13   -22    60   -99\n",
      "   -12  -214    -4  -119   -24    57  -125  -170   861  1058    15    11\n",
      "  -222    14     0   -64  -168     5    -1   -28  -299    36  -787   246\n",
      "  -288    42  -166   -38     0     7  -356   -71   -94    -9   -23  -147\n",
      "     0    46    22   346    60    13  -299   -32    -5    14  -218    24\n",
      "    37   -15    34    20    41   -63   -67  -144  -175   -62    41   -60\n",
      "  -335    17    28   -16  -163    21    32    69   -66  -410   -96  -101\n",
      " -1349    48  -120   -45    31    20    23   131  -145    24   -51    74\n",
      "  -551    13  -255   -26   548   -88    29    -4     0   -27  -447    11\n",
      "  -314    97  -132     7    20  -195    -1    36    27    52     5    11\n",
      "  -441   -11    -3  -195  -276  -425    21   -44  -220     0  -707   -98\n",
      "  -291  -144   -44    -7    57  -189   -61    75  -193    71   -29   289\n",
      "    90   -49    25   -66   -44     4    21  -108   -81     0  -150  -118\n",
      "    28     0    27  -151     0    10  -261    11    16    18    54  -456\n",
      "    60    87   -50    24     6    29  -106    25     0 -1569  -238   -76\n",
      "   396    27   -32    37  -150  -252  -159  -993   -98  -175     8   -66\n",
      "  -280   -19    12    25    38   -85   -64   -42   -82    44    46     0\n",
      "  -111    46    27    -2   -32    -3    38    20    17   -66     3    20\n",
      "  -104  -126   -37   -35  -112     0  -106   -20    32  -121   -93  -326\n",
      "    36   -54  -248  -299   304   -78  -264  -155    12   819  -126    31\n",
      "   -19   -62    53     0    39 -1074  -218   -60  -898   -14  -505  -244\n",
      "     0    36    32   -24  -133   -84     0   -79     0   -79   -80    36\n",
      "    15    62   -71 -1142   -65    27  -195  -114   -97   122   -24  -447\n",
      "   -22    31   -87   -25   -46  -494    22   -21   -84  -183     8   -72\n",
      "    38   -45   -10    23    26     1     0  -148  -116     0  -116   -29\n",
      "    19    26    43   -57  -300   114  -129   -87  -346   -86   -76   -52\n",
      "   -50    15    77  -258    17    42  -106     5     0   -48   -88   150\n",
      "  -231   -75    11  -148  -238  -114   -11  -475    -2   -18    39     0\n",
      "  -324   -79   -64    -3    30   -97   -31   -61  -100   -11  -405   -11\n",
      "     0  -635   -83  -349   -23  -382    86   -94    29 -1468  -130  -102\n",
      "    45   -33    -9  -192    47   -85  -130     6  -235  -172  -205  -113\n",
      "  -200     0  -194  -434  -345    20  -222   -54  2496  -145     3    37\n",
      "     0    47   -61    26   -61   -92  -159    67     0    56   -46    10\n",
      "  -331   -86  -122   -29  -288     9  -424   -60  -323  -862  -367  -330\n",
      "   -80   -18  -303   -40   -43  -177   -46   -61  -408    21    27  -965\n",
      "  -121     8   -16  -149  -206    55   -86    46     0    45   -72    -9\n",
      "  -133   -41  -539   -55     0     0    12  -189]\n",
      "\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1198.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1221.weight_quantized\n",
      "Shape: [2048, 512, 1, 1]\n",
      "Weights: [[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1221.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1221.bias_quantized\n",
      "Shape: [2048]\n",
      "Weights: [-864    0 -231 ...    0    0    0]\n",
      "\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1221.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: classifier.fc.weight, Weights: (1000, 2048)\n",
      "[[-0.07376207  0.         -0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.12108373  0.         -0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.          0.         -0.1097383  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.0622465   0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.04466717 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.11173791  0.          0.05249852 ...  0.          0.\n",
      "   0.        ]]\n",
      "Calculating features for matrix with shape: (1000, 2048)\n",
      "Features for classifier.fc.weight:\n",
      "  density: 0.256699\n",
      "  nnz_min: 102\n",
      "  nnz_max: 426\n",
      "  nnz_avg: 256.699\n",
      "  nnz_sd: 45.01991113940586\n",
      "  bw_min: 1962\n",
      "  bw_max: 2045\n",
      "  bw_avg: 2030.729\n",
      "  bw_sd: 10.750700395788174\n",
      "  scatter_avg: 0.1263876357662273\n",
      "  scatter_sd: 0.02204584034081943\n",
      "  clustering_avg: 0.8753109466765577\n",
      "\n",
      "\n",
      "Layer: classifier.fc.bias, Weights: (1000,)\n",
      "[ 7.18252314e-03 -3.35752890e-02 -2.54426375e-02 -5.53644001e-02\n",
      "  2.55135354e-02  9.38738056e-04 -2.39330046e-02  2.32885536e-02\n",
      "  1.90811995e-02 -2.56391261e-02 -3.68980244e-02 -2.95577887e-02\n",
      " -5.23597188e-02 -4.46471609e-02 -1.94348060e-02 -7.67116249e-02\n",
      " -1.62826143e-02 -3.53151597e-02  8.01827945e-03 -5.56148216e-02\n",
      " -7.35835359e-03  2.75577195e-02 -4.50191014e-02  2.31478773e-02\n",
      " -1.02905752e-02 -1.07335905e-02  1.20839570e-02 -1.92321241e-02\n",
      " -1.12573886e-02 -9.69969854e-03 -2.82136071e-02 -5.64677231e-02\n",
      "  2.39614733e-02 -1.68000441e-02 -2.80344021e-02 -2.91973967e-02\n",
      "  1.98813342e-03 -2.99713574e-02  1.26113072e-02  1.50025422e-02\n",
      " -3.05243675e-02  1.44059462e-02  4.45885258e-03 -3.83385345e-02\n",
      " -1.35191705e-03 -2.20567416e-02  5.07019646e-02 -4.59993072e-02\n",
      " -1.98413655e-02 -2.05305200e-02  4.12119692e-03  8.70289747e-03\n",
      "  1.42857172e-02  1.15778521e-02  3.67412493e-02  1.10353362e-02\n",
      "  7.23943636e-02 -3.73550951e-02  1.22396071e-02  8.72210320e-03\n",
      "  1.06228481e-03 -1.00748939e-02 -4.66751158e-02  2.95599960e-02\n",
      "  9.94852465e-03  2.75000203e-02 -6.20447695e-02 -9.05926991e-03\n",
      "  1.90301444e-02 -2.22626626e-02 -4.60606515e-02  6.91799389e-04\n",
      " -5.24906740e-02 -1.32625420e-02 -1.28821023e-02 -6.67677587e-03\n",
      " -9.44978930e-03  2.55744159e-02 -2.05248203e-02  3.00132092e-02\n",
      " -5.39222173e-02 -1.22784441e-02 -2.31894213e-04 -8.62111300e-02\n",
      " -2.68924553e-02 -7.62635097e-03 -4.28134315e-02  1.85105335e-02\n",
      " -2.41977931e-03  1.06674908e-02 -8.64088815e-03 -5.19136600e-02\n",
      "  3.56456265e-03 -2.23296192e-02  5.49065042e-03 -6.60474971e-02\n",
      " -1.61871444e-02 -3.11825983e-02 -4.86312211e-02 -6.12519123e-03\n",
      " -6.24928661e-02 -9.67207626e-02 -2.58080643e-02 -3.65212560e-03\n",
      "  4.00318354e-02 -9.68517642e-03  1.73281226e-02 -4.78103720e-02\n",
      " -3.67595367e-02 -7.11713284e-02 -5.15775867e-02 -1.55462651e-04\n",
      " -2.34559998e-02  7.43837794e-03 -1.21785828e-03 -7.57032260e-02\n",
      " -8.49532336e-02 -4.24969047e-02 -1.58447362e-02  1.35268476e-02\n",
      " -2.32606437e-02 -4.51708958e-02 -2.29440629e-02 -1.46913398e-02\n",
      "  3.04570682e-02 -6.25140294e-02 -6.56374916e-02 -3.90487676e-03\n",
      " -6.96432292e-02  2.13490613e-03 -4.06113900e-02 -3.04008443e-02\n",
      " -2.13773139e-02 -4.36647087e-02 -5.68110356e-03 -9.60441232e-02\n",
      " -4.30465415e-02 -6.58730343e-02 -4.91100363e-03 -7.67589137e-02\n",
      " -5.04581332e-02 -5.32960147e-02 -9.91171896e-02 -5.84154837e-02\n",
      " -4.96176705e-02 -1.18561005e-02 -1.18424594e-02 -4.70281057e-02\n",
      " -4.53852043e-02 -2.49479003e-02  4.14768048e-02  8.40545893e-02\n",
      " -4.34954949e-02  3.09330113e-02 -1.43264281e-03 -2.50886963e-03\n",
      "  1.93428826e-02 -2.26331037e-02 -2.87499987e-02 -3.57963587e-03\n",
      "  1.04560126e-02  4.31700945e-02  9.56360549e-02  7.95878656e-03\n",
      " -3.94814182e-03 -2.34819110e-02 -5.28947078e-02 -3.92696373e-02\n",
      "  5.80184069e-03 -1.75101887e-02  4.62254882e-03  8.82908776e-02\n",
      "  3.62370309e-04  2.13797539e-02  3.42648476e-02 -3.92200239e-02\n",
      "  2.58211396e-03 -1.66405365e-02  8.28758627e-02 -1.12814736e-02\n",
      " -1.88781209e-02 -3.46457376e-03  2.91015431e-02 -8.74293793e-04\n",
      "  3.79122831e-02  2.56398655e-02 -2.69081374e-03  1.14099225e-02\n",
      "  1.08558051e-02  2.02388112e-02 -1.13598248e-02  4.51581329e-02\n",
      "  5.02934754e-02 -2.22554225e-02 -1.54850287e-02  8.21526572e-02\n",
      "  3.25333253e-02  2.77841501e-02 -4.27683517e-02  3.76325548e-02\n",
      " -2.66984049e-02  3.76363359e-02  5.06996587e-02  1.92978494e-02\n",
      "  2.92993262e-02  2.43602917e-02 -4.69399020e-02  6.70401305e-02\n",
      " -4.18688208e-02  4.75240387e-02 -5.11391312e-02  7.15624094e-02\n",
      "  2.87443548e-02 -1.83035880e-02  2.19794037e-03 -4.72385064e-03\n",
      " -2.08121594e-02  4.51373234e-02 -1.35760673e-03  2.34064385e-02\n",
      "  1.38466377e-02 -3.41475978e-02  4.69664745e-02  6.70079738e-02\n",
      "  3.09959315e-02  4.48455736e-02 -4.10200842e-02 -9.33786854e-04\n",
      " -6.26267418e-02  4.17771228e-02  1.27360746e-02 -2.33355649e-02\n",
      "  7.37845674e-02  7.66109326e-04  4.05654535e-02  1.33664580e-03\n",
      "  5.05502075e-02  1.00131258e-02  1.53546892e-02  2.38651019e-02\n",
      "  3.06969844e-02 -5.47394156e-02  7.77995167e-03 -9.16940719e-03\n",
      "  1.89756900e-02  3.04921530e-02  1.12199755e-02  1.35886585e-02\n",
      "  5.02279177e-02 -2.75633093e-02  6.18715351e-03  5.15928343e-02\n",
      "  6.72806241e-03 -5.53373769e-02  3.88861559e-02  5.95839554e-03\n",
      "  2.82084849e-02  3.04579944e-03 -9.05625336e-03 -2.79196189e-03\n",
      "  1.09035540e-02 -3.15305851e-02  5.06598502e-04  3.76044400e-02\n",
      "  2.25221459e-03  3.88893038e-02 -1.64691545e-02  1.20385932e-02\n",
      " -2.91114524e-02 -1.57873407e-02  6.07315823e-02 -1.33506795e-02\n",
      " -1.15350476e-02 -1.44823873e-02 -3.40747163e-02 -5.28748930e-02\n",
      " -1.24264611e-02 -1.82421170e-02 -3.53795849e-02  1.04816502e-03\n",
      " -4.50929217e-02  9.98730659e-02 -2.58825399e-04  2.29471084e-02\n",
      "  7.30250403e-02  2.63193194e-02 -2.46336833e-02 -5.17481901e-02\n",
      " -7.86760747e-02 -2.11611744e-02 -4.66801673e-02 -6.48021325e-02\n",
      " -7.92479329e-03 -4.52685654e-02 -6.37900131e-03  1.81171242e-02\n",
      "  7.75867840e-03 -3.76741514e-02 -3.62528749e-02  5.71768507e-02\n",
      " -4.31748889e-02  2.59982841e-03 -2.35754214e-02 -7.63369491e-03\n",
      " -5.23303961e-03  2.93258391e-02  5.72896451e-02 -2.95589939e-02\n",
      " -2.35522706e-02  1.40334275e-02  5.24822213e-02 -5.27566634e-02\n",
      "  2.49925605e-03  7.80078173e-02  6.54300600e-02  1.47509370e-02\n",
      " -6.44391915e-03 -3.86217535e-02  2.40153950e-02 -1.63859818e-02\n",
      " -2.66221892e-02 -3.52781601e-02 -7.02990666e-02 -1.26462936e-01\n",
      " -5.76088242e-02 -6.03203848e-02 -4.83171269e-02 -3.90032157e-02\n",
      " -5.29044159e-02 -1.99443530e-02 -2.41541490e-02 -3.22387815e-02\n",
      " -1.43556660e-02 -6.51989505e-03 -9.15995392e-04 -3.75830159e-02\n",
      "  4.71829921e-02 -7.45838583e-02 -6.89497450e-03 -1.79417003e-02\n",
      " -3.61990854e-02 -3.99815030e-02 -3.91314626e-02 -2.94071692e-03\n",
      " -5.64100891e-02 -1.71448458e-02  9.62358317e-04 -3.12653519e-02\n",
      "  4.34440374e-02 -5.04198596e-02  7.26737361e-03 -2.63839643e-02\n",
      " -3.99747714e-02 -1.25080459e-02  1.11960410e-03  6.48772158e-03\n",
      "  1.80673972e-02 -5.06256744e-02  6.68015843e-03  4.78780083e-02\n",
      " -9.72009730e-03  3.90928090e-02  1.08393654e-02  2.69072019e-02\n",
      " -2.41655447e-02 -1.90282054e-02 -1.25126513e-02  1.58733297e-02\n",
      " -1.92229114e-02  2.28262749e-02  2.06411108e-02 -2.73236027e-03\n",
      " -3.73267718e-02  1.90801788e-02 -4.28575091e-02 -5.53110726e-02\n",
      " -2.81658061e-02 -1.96119305e-02  1.69495363e-02  4.30671759e-02\n",
      " -5.62820248e-02 -4.12275754e-02  2.68500596e-02 -2.74690823e-03\n",
      " -3.70294154e-02 -1.97445173e-02 -1.34705119e-02 -3.40751559e-02\n",
      " -5.26524596e-02 -2.21111666e-04  1.37637963e-03  3.61619741e-02\n",
      " -4.94093448e-02 -7.72251040e-02 -1.90033335e-02  1.66870072e-03\n",
      " -4.15676348e-02 -1.61344726e-02  4.01354693e-02 -1.03045674e-02\n",
      "  1.25134201e-03  6.67084977e-02 -1.72318369e-02 -2.06429865e-02\n",
      " -7.85827115e-02  2.06377706e-03 -1.96048692e-02 -2.63981465e-02\n",
      " -6.40849695e-02 -1.07236428e-03 -8.83797649e-03 -2.62845624e-02\n",
      "  1.48672266e-02  3.59479412e-02  3.26579884e-02 -2.76954081e-02\n",
      "  4.65284027e-02 -2.21029632e-02  7.46432878e-03 -1.39408084e-02\n",
      "  3.78831215e-02 -2.13591885e-02  5.62322885e-02  5.86267002e-02\n",
      "  6.94981590e-02 -2.38715876e-02 -5.92106730e-02 -1.55608170e-02\n",
      "  5.94555363e-02  1.07580656e-02 -7.23203225e-03  7.30812969e-03\n",
      "  4.50661890e-02  2.41007283e-02 -6.30479492e-03 -1.35143874e-02\n",
      "  1.04360189e-02 -3.01969610e-02  3.84220630e-02  3.25212963e-02\n",
      "  7.22598135e-02  1.96024366e-02  1.14221154e-02 -2.51224488e-02\n",
      "  4.09753434e-03  9.41155478e-02  1.57906709e-03 -1.12730367e-02\n",
      "  5.12705594e-02 -3.46709043e-02  1.06087318e-02 -1.73651297e-02\n",
      "  4.81646135e-03 -2.24487353e-02  3.80009040e-02 -6.81480998e-03\n",
      "  6.04430027e-02  3.92024107e-02 -2.24189945e-02  1.15536554e-02\n",
      "  1.45694222e-02 -5.75081166e-03  3.05278897e-02  3.59810591e-02\n",
      "  8.00202228e-03  4.72815707e-02 -3.76380421e-02  2.42949519e-02\n",
      "  1.20599056e-02  1.42742405e-02  5.00419401e-02 -9.24104080e-03\n",
      "  3.97515483e-03  4.54452373e-02 -4.64813784e-02 -3.10748033e-02\n",
      " -3.52716148e-02  2.03381423e-02 -7.58723868e-03  1.39714675e-02\n",
      "  1.98721439e-02  1.00243418e-03  2.24602013e-03 -4.64732945e-02\n",
      " -1.99527293e-02 -2.82824412e-02  1.25206010e-02  3.59674580e-02\n",
      " -1.23603093e-02  8.74696299e-03 -3.88959795e-02  2.18318589e-02\n",
      " -1.50361294e-02 -6.19697012e-02 -4.22389898e-03  1.81827396e-02\n",
      " -7.76115805e-03 -5.49771416e-04  2.60752073e-04 -1.29214814e-02\n",
      " -5.00403717e-02 -2.16999706e-02  9.42364987e-03  4.75236103e-02\n",
      "  8.96018185e-03  6.21284265e-03  7.48377852e-03 -1.96387637e-02\n",
      "  3.07415556e-02 -3.10038831e-02 -1.62189417e-02 -3.86554957e-03\n",
      " -1.91371460e-02  8.31129029e-03  2.33932119e-02  7.33992904e-02\n",
      " -2.95728743e-02  1.68679319e-02  1.27360737e-02  2.36912686e-02\n",
      " -4.69171554e-02  3.28385048e-02  6.04082383e-02  7.49708265e-02\n",
      " -6.77611679e-02 -2.52223890e-02  4.94622476e-02  4.05777059e-02\n",
      " -1.07373716e-02  4.74860854e-02  4.73299138e-02 -8.95804726e-03\n",
      "  2.87318453e-02 -8.99193063e-03  2.92627197e-02  1.57677438e-02\n",
      " -1.50692919e-02  5.23710065e-03 -1.13173025e-02  4.81495867e-03\n",
      " -6.31845370e-02  5.46683110e-02  4.47489368e-03 -4.76999907e-03\n",
      " -4.61963005e-03 -2.85100285e-02  9.71079431e-03 -6.27861470e-02\n",
      " -3.09952330e-02 -3.50382067e-02 -9.66852810e-03 -1.72530767e-02\n",
      "  4.22357060e-02  8.31449695e-04 -9.75531153e-03 -4.16986784e-03\n",
      " -1.19959526e-02  1.97797809e-02  6.99709579e-02  1.73912924e-02\n",
      " -4.01650369e-02 -1.74527820e-02 -3.34775709e-02  1.35434708e-02\n",
      " -1.61138121e-02 -3.34889479e-02  3.80612798e-02  4.68062907e-02\n",
      "  9.99592710e-04 -8.20438657e-03 -1.80208199e-02 -7.55078811e-03\n",
      "  2.87407986e-03  1.11032994e-02  3.59008415e-03  3.11695244e-02\n",
      " -1.00749256e-02  4.04902697e-02 -2.96245608e-02  4.80153859e-02\n",
      "  9.98696778e-03 -1.26952026e-02  3.21950242e-02  1.87113956e-02\n",
      "  8.32241029e-03  1.82579178e-02 -3.68237272e-02  3.85645665e-02\n",
      "  1.11557217e-02 -7.41084758e-03  3.26175354e-02  2.26446055e-02\n",
      " -2.24832017e-02  4.72698547e-03  1.33777056e-02  3.06831580e-03\n",
      "  7.30284750e-02 -4.02840646e-03 -1.83170289e-02  1.48521727e-02\n",
      "  7.34023675e-02 -5.88973844e-03 -1.13458384e-03 -2.63605639e-03\n",
      "  1.12277623e-02  1.05784936e-02 -4.43756441e-03 -3.70421843e-03\n",
      "  5.55956513e-02  3.07583669e-03  5.19277938e-02 -1.56008536e-02\n",
      " -4.64330465e-02 -2.66356766e-02 -3.12264953e-02 -3.68946232e-02\n",
      "  3.46648344e-03 -1.48153082e-02  3.24022472e-02  4.15379135e-03\n",
      "  8.11842009e-02  2.65256073e-02  7.18272179e-02  4.96286452e-02\n",
      "  5.48841767e-02 -4.04240377e-03  2.79567614e-02  3.42612229e-02\n",
      " -3.94623950e-02  3.52562517e-02 -1.52075570e-03 -3.40998406e-03\n",
      "  3.78481932e-02  5.08220531e-02 -2.57061422e-02 -5.16868532e-02\n",
      "  2.94825598e-03  9.13268235e-03 -1.78790241e-02 -3.34328413e-02\n",
      " -2.59217098e-02 -9.67487320e-03  3.06810662e-02 -5.51861804e-03\n",
      "  3.28109190e-02 -9.48090851e-03  5.79834580e-02 -2.98684146e-02\n",
      " -1.70240309e-02 -1.74296834e-02  1.02215774e-01  1.30645987e-02\n",
      "  1.65932477e-02  1.92038517e-03  7.99818430e-03  3.46367471e-02\n",
      " -1.19268764e-02  3.57079804e-02  8.60924367e-03  1.26649905e-02\n",
      "  4.03739791e-03 -3.43470201e-02 -5.02317119e-03  6.05154503e-03\n",
      "  1.08460952e-02  4.08123992e-02  5.91660989e-03  4.78741862e-02\n",
      " -3.78397666e-02 -2.80672312e-02  7.34836794e-03  5.94040006e-02\n",
      "  3.79171111e-02  2.64575966e-02  8.18701647e-03 -4.21180502e-02\n",
      "  1.41278515e-02  6.92677051e-02  4.74152202e-03  3.85521278e-02\n",
      "  1.73177589e-02  8.65727514e-02  1.26265669e-02  5.87336160e-02\n",
      "  5.17675560e-03 -2.11613141e-02  5.66407703e-02 -3.87915671e-02\n",
      " -2.43166834e-02 -2.40829270e-02 -2.63620485e-02  1.65263796e-03\n",
      "  6.50555342e-02 -4.73239161e-02 -2.39015575e-02  2.77605113e-02\n",
      " -6.94691669e-03  6.81776553e-03 -2.49780100e-02  1.47811333e-02\n",
      "  5.19632101e-02  1.85924489e-02 -7.19528040e-03  5.62330186e-02\n",
      "  5.28199337e-02 -3.72728147e-02 -1.97530426e-02  3.47018195e-03\n",
      "  5.37778996e-03  1.25001343e-02  2.27848589e-02  5.17205968e-02\n",
      " -1.41767543e-02 -6.13405043e-03  7.80964224e-03  1.10788634e-02\n",
      "  4.21589129e-02 -4.63499017e-02  3.61028612e-02  5.14625870e-02\n",
      "  2.92032175e-02  2.30591595e-02  5.65325506e-02 -3.28253605e-03\n",
      " -3.61529738e-02 -1.09613575e-02  1.47675816e-02 -3.08924243e-02\n",
      " -3.76163120e-03 -7.34792091e-03  1.84833119e-03  5.30264452e-02\n",
      "  1.57993101e-02  2.13637650e-02 -2.25506648e-02 -9.00146006e-06\n",
      "  2.29864754e-02  3.82045493e-03  4.07092134e-03  3.41424011e-02\n",
      "  8.84944294e-03 -6.04127683e-02  5.44783426e-03  6.49418635e-03\n",
      "  1.17050260e-02  1.51906470e-02 -5.95428199e-02 -1.10818604e-02\n",
      " -6.27598912e-02  5.85517474e-02 -9.01632104e-03  1.14181759e-02\n",
      "  9.81535576e-03  2.08565919e-03  6.28305972e-02 -2.28785822e-04\n",
      "  1.81676447e-02  1.62581969e-02  2.90769301e-02  3.32247503e-02\n",
      "  1.01278303e-02  3.46255302e-02  8.51717312e-03  1.38916848e-02\n",
      "  4.82633077e-02  1.45857744e-02 -3.85787361e-03  1.61923598e-02\n",
      "  2.10691430e-02  3.53563651e-02 -1.28372638e-02 -2.43942104e-02\n",
      "  5.61800003e-02 -7.32792076e-03  6.98898137e-02 -9.25239455e-03\n",
      "  2.59297565e-02  1.88225266e-02  7.51781370e-03 -1.20307766e-02\n",
      " -1.66276023e-02 -2.44783089e-02  3.98226008e-02 -1.58417914e-02\n",
      "  2.42285361e-03  2.52601001e-02 -9.76832025e-03 -3.54923941e-02\n",
      "  3.64566371e-02 -1.71446428e-02 -4.10583951e-02  5.72980940e-02\n",
      "  2.46458948e-02  9.24526900e-03 -3.92590761e-02 -4.46979441e-02\n",
      "  2.22252104e-02 -3.17246094e-02 -3.51827778e-02  1.00899637e-02\n",
      " -3.78479809e-02  1.51417572e-02 -1.31829791e-02 -6.92027947e-03\n",
      " -1.03293499e-02 -6.75903168e-03  3.01204603e-02  2.33729109e-02\n",
      "  8.03209841e-02  8.55365992e-02 -4.39848714e-02  5.33493720e-02\n",
      " -2.09722016e-02 -1.97011512e-02 -6.77236915e-02  1.41472444e-02\n",
      "  1.90450661e-02 -2.06097197e-02 -2.00109254e-03  1.35544976e-02\n",
      " -4.84633893e-02 -2.01981496e-02  7.61209009e-03  1.24151343e-02\n",
      "  2.12957039e-02  5.62712103e-02 -2.91593652e-02 -2.73171533e-02\n",
      "  8.72116387e-02 -2.93175988e-02  1.37344506e-02  3.02623045e-02\n",
      " -2.99081951e-02 -2.03594361e-02  5.36397435e-02  1.09541323e-02\n",
      "  1.41145401e-02  2.17450317e-02  5.19333743e-02  2.01438963e-02\n",
      "  7.50182793e-02 -8.00788868e-03  1.52769331e-02  3.44349374e-03\n",
      "  3.72605883e-02  3.88972126e-02  1.75631605e-02  2.26492528e-02\n",
      " -1.62068717e-02  3.97527888e-02  6.33424073e-02  2.42178068e-02\n",
      "  1.72313824e-02 -3.30158286e-02 -2.25533079e-02  1.79457793e-03\n",
      " -1.78509206e-02 -5.53703355e-03 -1.89933623e-03  3.99752110e-02\n",
      " -1.65853593e-02  7.21108764e-02 -1.24346120e-02 -9.31166206e-03\n",
      "  7.14718504e-03  9.71256662e-03 -7.65494211e-03 -9.19356197e-02\n",
      "  6.30787089e-02 -2.08592485e-03  8.44645500e-02 -2.50285026e-02\n",
      "  1.99639127e-02 -2.46400107e-02 -7.88571835e-02  2.08795201e-02\n",
      "  6.86209723e-02  4.13607759e-03 -2.35295780e-02  9.61092338e-02\n",
      "  9.62736607e-02  1.92294605e-02  5.88646494e-02  1.53824780e-02\n",
      "  3.26471031e-03  1.67917255e-02 -4.50745374e-02 -6.86977804e-02\n",
      "  9.11436102e-04  3.50236483e-02  2.37922296e-02 -1.84588227e-02\n",
      "  3.57549600e-02 -8.89143161e-03  1.84794273e-02  1.36224013e-02\n",
      "  3.04891057e-02  5.47935218e-02  4.60833013e-02 -2.24283198e-04\n",
      " -4.13055941e-02 -1.52314594e-02  4.67741005e-02  3.02934963e-02\n",
      " -4.44836505e-02 -3.44888642e-02  1.32174082e-02  4.26353440e-02\n",
      "  2.46818573e-03  4.31754254e-02  2.32428182e-02  1.13737453e-02\n",
      " -1.88741870e-02 -6.28587883e-03 -4.62327199e-03 -3.81393805e-02\n",
      " -2.45432667e-02 -3.21821906e-02  7.44311314e-04  1.18805971e-02\n",
      "  9.69686825e-03 -3.18137882e-03 -6.13028035e-02  4.93389787e-03\n",
      " -1.89146958e-02 -3.57759707e-02 -2.90820468e-02 -2.69499775e-02\n",
      " -4.69913287e-03  4.24175747e-02  4.10904177e-02 -1.65852124e-03\n",
      " -9.72106867e-03 -1.38050057e-02  3.58997025e-02 -2.14557480e-02\n",
      "  1.71033721e-02 -1.08194230e-02 -4.15962636e-02 -1.43990088e-02\n",
      " -1.12267546e-02 -3.92261036e-02 -2.98769306e-02 -8.98843911e-03\n",
      "  1.11961563e-03  8.66461173e-03 -1.09318141e-02 -7.57734990e-03\n",
      " -7.65322894e-03  3.26664597e-02  1.83220878e-02 -1.65540446e-03\n",
      " -2.04519872e-02 -5.23281656e-03  2.29477733e-02  4.74451436e-03\n",
      " -1.11407759e-02 -4.44319658e-03  1.63205378e-02 -6.43407255e-02\n",
      "  9.52454191e-03  5.92225008e-02 -3.38344052e-02 -3.10405605e-02\n",
      " -6.21453933e-02  9.12670512e-03  5.82372062e-02  2.45300774e-02\n",
      "  5.98502439e-03  5.72335115e-03 -1.28573738e-02  5.67653999e-02\n",
      "  4.07866947e-02  1.55827403e-02 -3.03320996e-02  7.26073161e-02\n",
      " -1.05377976e-02  3.06470674e-02  2.29384787e-02 -4.85584103e-02\n",
      "  2.48145945e-02 -3.22673796e-03  1.49996914e-02  2.49914918e-02\n",
      "  1.12740118e-02 -2.53327694e-02 -5.31691350e-02 -2.55221389e-02\n",
      " -4.54499125e-02  1.46564015e-03 -2.62080170e-02 -3.44166756e-02\n",
      " -3.46586369e-02 -1.01774342e-01  1.98942982e-02  2.07052822e-03\n",
      "  9.99164674e-03 -4.23510820e-02  2.71106716e-02 -6.61292393e-03]\n",
      "Calculating features for matrix with shape: (1000,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1000,)\n",
      "Skipping layer classifier.fc.bias due to None values in features.\n",
      "\n",
      "Layer: 3472, Weights: (1,)\n",
      "[-1]\n",
      "Calculating features for matrix with shape: (1,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1,)\n",
      "Skipping layer 3472 due to None values in features.\n",
      "\n",
      "Layer: 1434, Weights: ()\n",
      "0.018658448\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1434 due to None values in features.\n",
      "\n",
      "Layer: 1435, Weights: ()\n",
      "114\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1435 due to None values in features.\n",
      "\n",
      "Layer: 1437, Weights: ()\n",
      "0.018658448\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1437 due to None values in features.\n",
      "\n",
      "Layer: 1438, Weights: ()\n",
      "114\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1438 due to None values in features.\n",
      "\n",
      "Layer: 1447, Weights: ()\n",
      "0.005670221\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1447 due to None values in features.\n",
      "\n",
      "Layer: 1448, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1448 due to None values in features.\n",
      "\n",
      "Layer: 1460, Weights: ()\n",
      "0.039100595\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1460 due to None values in features.\n",
      "\n",
      "Layer: 1461, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1461 due to None values in features.\n",
      "\n",
      "Layer: 1463, Weights: ()\n",
      "0.039100595\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1463 due to None values in features.\n",
      "\n",
      "Layer: 1464, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1464 due to None values in features.\n",
      "\n",
      "Layer: 1467, Weights: ()\n",
      "0.03619409\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1467 due to None values in features.\n",
      "\n",
      "Layer: 1468, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1468 due to None values in features.\n",
      "\n",
      "Layer: 1470, Weights: ()\n",
      "0.03619409\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1470 due to None values in features.\n",
      "\n",
      "Layer: 1471, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1471 due to None values in features.\n",
      "\n",
      "Layer: 1480, Weights: ()\n",
      "0.006647352\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1480 due to None values in features.\n",
      "\n",
      "Layer: 1481, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1481 due to None values in features.\n",
      "\n",
      "Layer: 1499, Weights: ()\n",
      "0.012922951\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1499 due to None values in features.\n",
      "\n",
      "Layer: 1500, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1500 due to None values in features.\n",
      "\n",
      "Layer: 1502, Weights: ()\n",
      "0.012922951\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1502 due to None values in features.\n",
      "\n",
      "Layer: 1503, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1503 due to None values in features.\n",
      "\n",
      "Layer: 1512, Weights: ()\n",
      "0.009442109\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1512 due to None values in features.\n",
      "\n",
      "Layer: 1513, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1513 due to None values in features.\n",
      "\n",
      "Layer: 1531, Weights: ()\n",
      "0.01226136\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1531 due to None values in features.\n",
      "\n",
      "Layer: 1532, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1532 due to None values in features.\n",
      "\n",
      "Layer: 1534, Weights: ()\n",
      "0.01226136\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1534 due to None values in features.\n",
      "\n",
      "Layer: 1535, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1535 due to None values in features.\n",
      "\n",
      "Layer: 1544, Weights: ()\n",
      "0.024228053\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1544 due to None values in features.\n",
      "\n",
      "Layer: 1545, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1545 due to None values in features.\n",
      "\n",
      "Layer: 1556, Weights: ()\n",
      "0.030302765\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1556 due to None values in features.\n",
      "\n",
      "Layer: 1557, Weights: ()\n",
      "116\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1557 due to None values in features.\n",
      "\n",
      "Layer: 1559, Weights: ()\n",
      "0.030302765\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1559 due to None values in features.\n",
      "\n",
      "Layer: 1560, Weights: ()\n",
      "116\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1560 due to None values in features.\n",
      "\n",
      "Layer: 1565, Weights: ()\n",
      "0.03619409\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1565 due to None values in features.\n",
      "\n",
      "Layer: 1566, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1566 due to None values in features.\n",
      "\n",
      "Layer: 1575, Weights: ()\n",
      "0.012222475\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1575 due to None values in features.\n",
      "\n",
      "Layer: 1576, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1576 due to None values in features.\n",
      "\n",
      "Layer: 1587, Weights: ()\n",
      "0.06199674\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1587 due to None values in features.\n",
      "\n",
      "Layer: 1588, Weights: ()\n",
      "167\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1588 due to None values in features.\n",
      "\n",
      "Layer: 1590, Weights: ()\n",
      "0.06199674\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1590 due to None values in features.\n",
      "\n",
      "Layer: 1591, Weights: ()\n",
      "167\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1591 due to None values in features.\n",
      "\n",
      "Layer: 1595, Weights: ()\n",
      "0.019888569\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1595 due to None values in features.\n",
      "\n",
      "Layer: 1596, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1596 due to None values in features.\n",
      "\n",
      "Layer: 1598, Weights: ()\n",
      "0.019888569\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1598 due to None values in features.\n",
      "\n",
      "Layer: 1599, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1599 due to None values in features.\n",
      "\n",
      "Layer: 1608, Weights: ()\n",
      "0.005241309\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1608 due to None values in features.\n",
      "\n",
      "Layer: 1609, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1609 due to None values in features.\n",
      "\n",
      "Layer: 1627, Weights: ()\n",
      "0.012222596\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1627 due to None values in features.\n",
      "\n",
      "Layer: 1628, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1628 due to None values in features.\n",
      "\n",
      "Layer: 1630, Weights: ()\n",
      "0.012222596\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1630 due to None values in features.\n",
      "\n",
      "Layer: 1631, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1631 due to None values in features.\n",
      "\n",
      "Layer: 1640, Weights: ()\n",
      "0.01235195\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1640 due to None values in features.\n",
      "\n",
      "Layer: 1641, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1641 due to None values in features.\n",
      "\n",
      "Layer: 1659, Weights: ()\n",
      "0.013687315\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1659 due to None values in features.\n",
      "\n",
      "Layer: 1660, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1660 due to None values in features.\n",
      "\n",
      "Layer: 1662, Weights: ()\n",
      "0.013687315\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1662 due to None values in features.\n",
      "\n",
      "Layer: 1663, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1663 due to None values in features.\n",
      "\n",
      "Layer: 1672, Weights: ()\n",
      "0.0147471465\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1672 due to None values in features.\n",
      "\n",
      "Layer: 1673, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1673 due to None values in features.\n",
      "\n",
      "Layer: 1684, Weights: ()\n",
      "0.03125461\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1684 due to None values in features.\n",
      "\n",
      "Layer: 1685, Weights: ()\n",
      "122\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1685 due to None values in features.\n",
      "\n",
      "Layer: 1687, Weights: ()\n",
      "0.03125461\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1687 due to None values in features.\n",
      "\n",
      "Layer: 1688, Weights: ()\n",
      "122\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1688 due to None values in features.\n",
      "\n",
      "Layer: 1692, Weights: ()\n",
      "0.020248167\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1692 due to None values in features.\n",
      "\n",
      "Layer: 1693, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1693 due to None values in features.\n",
      "\n",
      "Layer: 1695, Weights: ()\n",
      "0.020248167\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1695 due to None values in features.\n",
      "\n",
      "Layer: 1696, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1696 due to None values in features.\n",
      "\n",
      "Layer: 1705, Weights: ()\n",
      "0.0036072396\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1705 due to None values in features.\n",
      "\n",
      "Layer: 1706, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1706 due to None values in features.\n",
      "\n",
      "Layer: 1724, Weights: ()\n",
      "0.010899873\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1724 due to None values in features.\n",
      "\n",
      "Layer: 1725, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1725 due to None values in features.\n",
      "\n",
      "Layer: 1727, Weights: ()\n",
      "0.010899873\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1727 due to None values in features.\n",
      "\n",
      "Layer: 1728, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1728 due to None values in features.\n",
      "\n",
      "Layer: 1737, Weights: ()\n",
      "0.0044515175\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1737 due to None values in features.\n",
      "\n",
      "Layer: 1738, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1738 due to None values in features.\n",
      "\n",
      "Layer: 1756, Weights: ()\n",
      "0.014887796\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1756 due to None values in features.\n",
      "\n",
      "Layer: 1757, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1757 due to None values in features.\n",
      "\n",
      "Layer: 1759, Weights: ()\n",
      "0.014887796\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1759 due to None values in features.\n",
      "\n",
      "Layer: 1760, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1760 due to None values in features.\n",
      "\n",
      "Layer: 1769, Weights: ()\n",
      "0.013305151\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1769 due to None values in features.\n",
      "\n",
      "Layer: 1770, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1770 due to None values in features.\n",
      "\n",
      "Layer: 1781, Weights: ()\n",
      "0.034788433\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1781 due to None values in features.\n",
      "\n",
      "Layer: 1782, Weights: ()\n",
      "118\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1782 due to None values in features.\n",
      "\n",
      "Layer: 1784, Weights: ()\n",
      "0.034788433\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1784 due to None values in features.\n",
      "\n",
      "Layer: 1785, Weights: ()\n",
      "118\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1785 due to None values in features.\n",
      "\n",
      "Layer: 1789, Weights: ()\n",
      "0.020523421\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1789 due to None values in features.\n",
      "\n",
      "Layer: 1790, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1790 due to None values in features.\n",
      "\n",
      "Layer: 1792, Weights: ()\n",
      "0.020523421\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1792 due to None values in features.\n",
      "\n",
      "Layer: 1793, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1793 due to None values in features.\n",
      "\n",
      "Layer: 1802, Weights: ()\n",
      "0.0051508993\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1802 due to None values in features.\n",
      "\n",
      "Layer: 1803, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1803 due to None values in features.\n",
      "\n",
      "Layer: 1821, Weights: ()\n",
      "0.014863739\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1821 due to None values in features.\n",
      "\n",
      "Layer: 1822, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1822 due to None values in features.\n",
      "\n",
      "Layer: 1824, Weights: ()\n",
      "0.014863739\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1824 due to None values in features.\n",
      "\n",
      "Layer: 1825, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1825 due to None values in features.\n",
      "\n",
      "Layer: 1834, Weights: ()\n",
      "0.00407923\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1834 due to None values in features.\n",
      "\n",
      "Layer: 1835, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1835 due to None values in features.\n",
      "\n",
      "Layer: 1853, Weights: ()\n",
      "0.015159572\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1853 due to None values in features.\n",
      "\n",
      "Layer: 1854, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1854 due to None values in features.\n",
      "\n",
      "Layer: 1856, Weights: ()\n",
      "0.015159572\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1856 due to None values in features.\n",
      "\n",
      "Layer: 1857, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1857 due to None values in features.\n",
      "\n",
      "Layer: 1866, Weights: ()\n",
      "0.010431468\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1866 due to None values in features.\n",
      "\n",
      "Layer: 1867, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1867 due to None values in features.\n",
      "\n",
      "Layer: 1878, Weights: ()\n",
      "0.04070269\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1878 due to None values in features.\n",
      "\n",
      "Layer: 1879, Weights: ()\n",
      "119\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1879 due to None values in features.\n",
      "\n",
      "Layer: 1881, Weights: ()\n",
      "0.04070269\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1881 due to None values in features.\n",
      "\n",
      "Layer: 1882, Weights: ()\n",
      "119\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1882 due to None values in features.\n",
      "\n",
      "Layer: 1887, Weights: ()\n",
      "0.020523421\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1887 due to None values in features.\n",
      "\n",
      "Layer: 1888, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1888 due to None values in features.\n",
      "\n",
      "Layer: 1897, Weights: ()\n",
      "0.008742018\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1897 due to None values in features.\n",
      "\n",
      "Layer: 1898, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1898 due to None values in features.\n",
      "\n",
      "Layer: 1909, Weights: ()\n",
      "0.03200717\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1909 due to None values in features.\n",
      "\n",
      "Layer: 1910, Weights: ()\n",
      "134\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1910 due to None values in features.\n",
      "\n",
      "Layer: 1912, Weights: ()\n",
      "0.03200717\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1912 due to None values in features.\n",
      "\n",
      "Layer: 1913, Weights: ()\n",
      "134\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1913 due to None values in features.\n",
      "\n",
      "Layer: 1917, Weights: ()\n",
      "0.020077087\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1917 due to None values in features.\n",
      "\n",
      "Layer: 1918, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1918 due to None values in features.\n",
      "\n",
      "Layer: 1920, Weights: ()\n",
      "0.020077087\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1920 due to None values in features.\n",
      "\n",
      "Layer: 1921, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1921 due to None values in features.\n",
      "\n",
      "Layer: 1930, Weights: ()\n",
      "0.0039075175\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1930 due to None values in features.\n",
      "\n",
      "Layer: 1931, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1931 due to None values in features.\n",
      "\n",
      "Layer: 1949, Weights: ()\n",
      "0.012288947\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1949 due to None values in features.\n",
      "\n",
      "Layer: 1950, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1950 due to None values in features.\n",
      "\n",
      "Layer: 1952, Weights: ()\n",
      "0.012288947\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1952 due to None values in features.\n",
      "\n",
      "Layer: 1953, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1953 due to None values in features.\n",
      "\n",
      "Layer: 1962, Weights: ()\n",
      "0.0064475914\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1962 due to None values in features.\n",
      "\n",
      "Layer: 1963, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1963 due to None values in features.\n",
      "\n",
      "Layer: 1981, Weights: ()\n",
      "0.010088305\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1981 due to None values in features.\n",
      "\n",
      "Layer: 1982, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1982 due to None values in features.\n",
      "\n",
      "Layer: 1984, Weights: ()\n",
      "0.010088305\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1984 due to None values in features.\n",
      "\n",
      "Layer: 1985, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1985 due to None values in features.\n",
      "\n",
      "Layer: 1994, Weights: ()\n",
      "0.0131183155\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1994 due to None values in features.\n",
      "\n",
      "Layer: 1995, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 1995 due to None values in features.\n",
      "\n",
      "Layer: 2006, Weights: ()\n",
      "0.031949148\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2006 due to None values in features.\n",
      "\n",
      "Layer: 2007, Weights: ()\n",
      "137\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2007 due to None values in features.\n",
      "\n",
      "Layer: 2009, Weights: ()\n",
      "0.031949148\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2009 due to None values in features.\n",
      "\n",
      "Layer: 2010, Weights: ()\n",
      "137\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2010 due to None values in features.\n",
      "\n",
      "Layer: 2014, Weights: ()\n",
      "0.02006774\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2014 due to None values in features.\n",
      "\n",
      "Layer: 2015, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2015 due to None values in features.\n",
      "\n",
      "Layer: 2017, Weights: ()\n",
      "0.02006774\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2017 due to None values in features.\n",
      "\n",
      "Layer: 2018, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2018 due to None values in features.\n",
      "\n",
      "Layer: 2027, Weights: ()\n",
      "0.004059489\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2027 due to None values in features.\n",
      "\n",
      "Layer: 2028, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2028 due to None values in features.\n",
      "\n",
      "Layer: 2046, Weights: ()\n",
      "0.010174835\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2046 due to None values in features.\n",
      "\n",
      "Layer: 2047, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2047 due to None values in features.\n",
      "\n",
      "Layer: 2049, Weights: ()\n",
      "0.010174835\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2049 due to None values in features.\n",
      "\n",
      "Layer: 2050, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2050 due to None values in features.\n",
      "\n",
      "Layer: 2059, Weights: ()\n",
      "0.004587772\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2059 due to None values in features.\n",
      "\n",
      "Layer: 2060, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2060 due to None values in features.\n",
      "\n",
      "Layer: 2078, Weights: ()\n",
      "0.009026982\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2078 due to None values in features.\n",
      "\n",
      "Layer: 2079, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2079 due to None values in features.\n",
      "\n",
      "Layer: 2081, Weights: ()\n",
      "0.009026982\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2081 due to None values in features.\n",
      "\n",
      "Layer: 2082, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2082 due to None values in features.\n",
      "\n",
      "Layer: 2091, Weights: ()\n",
      "0.016838977\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2091 due to None values in features.\n",
      "\n",
      "Layer: 2092, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2092 due to None values in features.\n",
      "\n",
      "Layer: 2103, Weights: ()\n",
      "0.02368021\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2103 due to None values in features.\n",
      "\n",
      "Layer: 2104, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2104 due to None values in features.\n",
      "\n",
      "Layer: 2106, Weights: ()\n",
      "0.02368021\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2106 due to None values in features.\n",
      "\n",
      "Layer: 2107, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2107 due to None values in features.\n",
      "\n",
      "Layer: 2111, Weights: ()\n",
      "0.020254865\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2111 due to None values in features.\n",
      "\n",
      "Layer: 2112, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2112 due to None values in features.\n",
      "\n",
      "Layer: 2114, Weights: ()\n",
      "0.020254865\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2114 due to None values in features.\n",
      "\n",
      "Layer: 2115, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2115 due to None values in features.\n",
      "\n",
      "Layer: 2124, Weights: ()\n",
      "0.0042239055\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2124 due to None values in features.\n",
      "\n",
      "Layer: 2125, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2125 due to None values in features.\n",
      "\n",
      "Layer: 2143, Weights: ()\n",
      "0.013323214\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2143 due to None values in features.\n",
      "\n",
      "Layer: 2144, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2144 due to None values in features.\n",
      "\n",
      "Layer: 2146, Weights: ()\n",
      "0.013323214\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2146 due to None values in features.\n",
      "\n",
      "Layer: 2147, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2147 due to None values in features.\n",
      "\n",
      "Layer: 2156, Weights: ()\n",
      "0.0067950087\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2156 due to None values in features.\n",
      "\n",
      "Layer: 2157, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2157 due to None values in features.\n",
      "\n",
      "Layer: 2175, Weights: ()\n",
      "0.015611949\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2175 due to None values in features.\n",
      "\n",
      "Layer: 2176, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2176 due to None values in features.\n",
      "\n",
      "Layer: 2178, Weights: ()\n",
      "0.015611949\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2178 due to None values in features.\n",
      "\n",
      "Layer: 2179, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2179 due to None values in features.\n",
      "\n",
      "Layer: 2188, Weights: ()\n",
      "0.012558858\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2188 due to None values in features.\n",
      "\n",
      "Layer: 2189, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2189 due to None values in features.\n",
      "\n",
      "Layer: 2200, Weights: ()\n",
      "0.031910703\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2200 due to None values in features.\n",
      "\n",
      "Layer: 2201, Weights: ()\n",
      "127\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2201 due to None values in features.\n",
      "\n",
      "Layer: 2203, Weights: ()\n",
      "0.031910703\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2203 due to None values in features.\n",
      "\n",
      "Layer: 2204, Weights: ()\n",
      "127\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2204 due to None values in features.\n",
      "\n",
      "Layer: 2208, Weights: ()\n",
      "0.021210445\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2208 due to None values in features.\n",
      "\n",
      "Layer: 2209, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2209 due to None values in features.\n",
      "\n",
      "Layer: 2211, Weights: ()\n",
      "0.021210445\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2211 due to None values in features.\n",
      "\n",
      "Layer: 2212, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2212 due to None values in features.\n",
      "\n",
      "Layer: 2221, Weights: ()\n",
      "0.004706465\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2221 due to None values in features.\n",
      "\n",
      "Layer: 2222, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2222 due to None values in features.\n",
      "\n",
      "Layer: 2240, Weights: ()\n",
      "0.018308194\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2240 due to None values in features.\n",
      "\n",
      "Layer: 2241, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2241 due to None values in features.\n",
      "\n",
      "Layer: 2243, Weights: ()\n",
      "0.018308194\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2243 due to None values in features.\n",
      "\n",
      "Layer: 2244, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2244 due to None values in features.\n",
      "\n",
      "Layer: 2253, Weights: ()\n",
      "0.0055183065\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2253 due to None values in features.\n",
      "\n",
      "Layer: 2254, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2254 due to None values in features.\n",
      "\n",
      "Layer: 2272, Weights: ()\n",
      "0.015635878\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2272 due to None values in features.\n",
      "\n",
      "Layer: 2273, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2273 due to None values in features.\n",
      "\n",
      "Layer: 2275, Weights: ()\n",
      "0.015635878\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2275 due to None values in features.\n",
      "\n",
      "Layer: 2276, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2276 due to None values in features.\n",
      "\n",
      "Layer: 2285, Weights: ()\n",
      "0.009911838\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2285 due to None values in features.\n",
      "\n",
      "Layer: 2286, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2286 due to None values in features.\n",
      "\n",
      "Layer: 2297, Weights: ()\n",
      "0.033000544\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2297 due to None values in features.\n",
      "\n",
      "Layer: 2298, Weights: ()\n",
      "110\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2298 due to None values in features.\n",
      "\n",
      "Layer: 2300, Weights: ()\n",
      "0.033000544\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2300 due to None values in features.\n",
      "\n",
      "Layer: 2301, Weights: ()\n",
      "110\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2301 due to None values in features.\n",
      "\n",
      "Layer: 2306, Weights: ()\n",
      "0.021210445\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2306 due to None values in features.\n",
      "\n",
      "Layer: 2307, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2307 due to None values in features.\n",
      "\n",
      "Layer: 2316, Weights: ()\n",
      "0.0061014015\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2316 due to None values in features.\n",
      "\n",
      "Layer: 2317, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2317 due to None values in features.\n",
      "\n",
      "Layer: 2328, Weights: ()\n",
      "0.020790493\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2328 due to None values in features.\n",
      "\n",
      "Layer: 2329, Weights: ()\n",
      "130\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2329 due to None values in features.\n",
      "\n",
      "Layer: 2331, Weights: ()\n",
      "0.020790493\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2331 due to None values in features.\n",
      "\n",
      "Layer: 2332, Weights: ()\n",
      "130\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2332 due to None values in features.\n",
      "\n",
      "Layer: 2336, Weights: ()\n",
      "0.018750697\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2336 due to None values in features.\n",
      "\n",
      "Layer: 2337, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2337 due to None values in features.\n",
      "\n",
      "Layer: 2339, Weights: ()\n",
      "0.018750697\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2339 due to None values in features.\n",
      "\n",
      "Layer: 2340, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2340 due to None values in features.\n",
      "\n",
      "Layer: 2349, Weights: ()\n",
      "0.0046094297\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2349 due to None values in features.\n",
      "\n",
      "Layer: 2350, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2350 due to None values in features.\n",
      "\n",
      "Layer: 2368, Weights: ()\n",
      "0.011240736\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2368 due to None values in features.\n",
      "\n",
      "Layer: 2369, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2369 due to None values in features.\n",
      "\n",
      "Layer: 2371, Weights: ()\n",
      "0.011240736\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2371 due to None values in features.\n",
      "\n",
      "Layer: 2372, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2372 due to None values in features.\n",
      "\n",
      "Layer: 2381, Weights: ()\n",
      "0.005618378\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2381 due to None values in features.\n",
      "\n",
      "Layer: 2382, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2382 due to None values in features.\n",
      "\n",
      "Layer: 2400, Weights: ()\n",
      "0.009066108\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2400 due to None values in features.\n",
      "\n",
      "Layer: 2401, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2401 due to None values in features.\n",
      "\n",
      "Layer: 2403, Weights: ()\n",
      "0.009066108\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2403 due to None values in features.\n",
      "\n",
      "Layer: 2404, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2404 due to None values in features.\n",
      "\n",
      "Layer: 2413, Weights: ()\n",
      "0.012480415\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2413 due to None values in features.\n",
      "\n",
      "Layer: 2414, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2414 due to None values in features.\n",
      "\n",
      "Layer: 2425, Weights: ()\n",
      "0.021611799\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2425 due to None values in features.\n",
      "\n",
      "Layer: 2426, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2426 due to None values in features.\n",
      "\n",
      "Layer: 2428, Weights: ()\n",
      "0.021611799\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2428 due to None values in features.\n",
      "\n",
      "Layer: 2429, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2429 due to None values in features.\n",
      "\n",
      "Layer: 2433, Weights: ()\n",
      "0.018507019\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2433 due to None values in features.\n",
      "\n",
      "Layer: 2434, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2434 due to None values in features.\n",
      "\n",
      "Layer: 2436, Weights: ()\n",
      "0.018507019\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2436 due to None values in features.\n",
      "\n",
      "Layer: 2437, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2437 due to None values in features.\n",
      "\n",
      "Layer: 2446, Weights: ()\n",
      "0.00557581\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2446 due to None values in features.\n",
      "\n",
      "Layer: 2447, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2447 due to None values in features.\n",
      "\n",
      "Layer: 2465, Weights: ()\n",
      "0.012343228\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2465 due to None values in features.\n",
      "\n",
      "Layer: 2466, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2466 due to None values in features.\n",
      "\n",
      "Layer: 2468, Weights: ()\n",
      "0.012343228\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2468 due to None values in features.\n",
      "\n",
      "Layer: 2469, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2469 due to None values in features.\n",
      "\n",
      "Layer: 2478, Weights: ()\n",
      "0.005385006\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2478 due to None values in features.\n",
      "\n",
      "Layer: 2479, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2479 due to None values in features.\n",
      "\n",
      "Layer: 2497, Weights: ()\n",
      "0.009310737\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2497 due to None values in features.\n",
      "\n",
      "Layer: 2498, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2498 due to None values in features.\n",
      "\n",
      "Layer: 2500, Weights: ()\n",
      "0.009310737\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2500 due to None values in features.\n",
      "\n",
      "Layer: 2501, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2501 due to None values in features.\n",
      "\n",
      "Layer: 2510, Weights: ()\n",
      "0.014936916\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2510 due to None values in features.\n",
      "\n",
      "Layer: 2511, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2511 due to None values in features.\n",
      "\n",
      "Layer: 2522, Weights: ()\n",
      "0.020829618\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2522 due to None values in features.\n",
      "\n",
      "Layer: 2523, Weights: ()\n",
      "122\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2523 due to None values in features.\n",
      "\n",
      "Layer: 2525, Weights: ()\n",
      "0.020829618\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2525 due to None values in features.\n",
      "\n",
      "Layer: 2526, Weights: ()\n",
      "122\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2526 due to None values in features.\n",
      "\n",
      "Layer: 2530, Weights: ()\n",
      "0.021444649\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2530 due to None values in features.\n",
      "\n",
      "Layer: 2531, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2531 due to None values in features.\n",
      "\n",
      "Layer: 2533, Weights: ()\n",
      "0.021444649\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2533 due to None values in features.\n",
      "\n",
      "Layer: 2534, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2534 due to None values in features.\n",
      "\n",
      "Layer: 2543, Weights: ()\n",
      "0.0047103507\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2543 due to None values in features.\n",
      "\n",
      "Layer: 2544, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2544 due to None values in features.\n",
      "\n",
      "Layer: 2562, Weights: ()\n",
      "0.012271775\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2562 due to None values in features.\n",
      "\n",
      "Layer: 2563, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2563 due to None values in features.\n",
      "\n",
      "Layer: 2565, Weights: ()\n",
      "0.012271775\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2565 due to None values in features.\n",
      "\n",
      "Layer: 2566, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2566 due to None values in features.\n",
      "\n",
      "Layer: 2575, Weights: ()\n",
      "0.005423147\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2575 due to None values in features.\n",
      "\n",
      "Layer: 2576, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2576 due to None values in features.\n",
      "\n",
      "Layer: 2594, Weights: ()\n",
      "0.011694969\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2594 due to None values in features.\n",
      "\n",
      "Layer: 2595, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2595 due to None values in features.\n",
      "\n",
      "Layer: 2597, Weights: ()\n",
      "0.011694969\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2597 due to None values in features.\n",
      "\n",
      "Layer: 2598, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2598 due to None values in features.\n",
      "\n",
      "Layer: 2607, Weights: ()\n",
      "0.012898033\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2607 due to None values in features.\n",
      "\n",
      "Layer: 2608, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2608 due to None values in features.\n",
      "\n",
      "Layer: 2619, Weights: ()\n",
      "0.02359147\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2619 due to None values in features.\n",
      "\n",
      "Layer: 2620, Weights: ()\n",
      "118\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2620 due to None values in features.\n",
      "\n",
      "Layer: 2622, Weights: ()\n",
      "0.02359147\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2622 due to None values in features.\n",
      "\n",
      "Layer: 2623, Weights: ()\n",
      "118\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2623 due to None values in features.\n",
      "\n",
      "Layer: 2627, Weights: ()\n",
      "0.027397124\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2627 due to None values in features.\n",
      "\n",
      "Layer: 2628, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2628 due to None values in features.\n",
      "\n",
      "Layer: 2630, Weights: ()\n",
      "0.027397124\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2630 due to None values in features.\n",
      "\n",
      "Layer: 2631, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2631 due to None values in features.\n",
      "\n",
      "Layer: 2640, Weights: ()\n",
      "0.0048056194\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2640 due to None values in features.\n",
      "\n",
      "Layer: 2641, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2641 due to None values in features.\n",
      "\n",
      "Layer: 2659, Weights: ()\n",
      "0.012544154\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2659 due to None values in features.\n",
      "\n",
      "Layer: 2660, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2660 due to None values in features.\n",
      "\n",
      "Layer: 2662, Weights: ()\n",
      "0.012544154\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2662 due to None values in features.\n",
      "\n",
      "Layer: 2663, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2663 due to None values in features.\n",
      "\n",
      "Layer: 2672, Weights: ()\n",
      "0.0068750535\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2672 due to None values in features.\n",
      "\n",
      "Layer: 2673, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2673 due to None values in features.\n",
      "\n",
      "Layer: 2691, Weights: ()\n",
      "0.012150355\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2691 due to None values in features.\n",
      "\n",
      "Layer: 2692, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2692 due to None values in features.\n",
      "\n",
      "Layer: 2694, Weights: ()\n",
      "0.012150355\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2694 due to None values in features.\n",
      "\n",
      "Layer: 2695, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2695 due to None values in features.\n",
      "\n",
      "Layer: 2704, Weights: ()\n",
      "0.014904658\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2704 due to None values in features.\n",
      "\n",
      "Layer: 2705, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2705 due to None values in features.\n",
      "\n",
      "Layer: 2716, Weights: ()\n",
      "0.031942867\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2716 due to None values in features.\n",
      "\n",
      "Layer: 2717, Weights: ()\n",
      "98\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2717 due to None values in features.\n",
      "\n",
      "Layer: 2719, Weights: ()\n",
      "0.031942867\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2719 due to None values in features.\n",
      "\n",
      "Layer: 2720, Weights: ()\n",
      "98\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2720 due to None values in features.\n",
      "\n",
      "Layer: 2724, Weights: ()\n",
      "0.026211606\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2724 due to None values in features.\n",
      "\n",
      "Layer: 2725, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2725 due to None values in features.\n",
      "\n",
      "Layer: 2727, Weights: ()\n",
      "0.026211606\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2727 due to None values in features.\n",
      "\n",
      "Layer: 2728, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2728 due to None values in features.\n",
      "\n",
      "Layer: 2737, Weights: ()\n",
      "0.0045373575\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2737 due to None values in features.\n",
      "\n",
      "Layer: 2738, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2738 due to None values in features.\n",
      "\n",
      "Layer: 2756, Weights: ()\n",
      "0.016443836\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2756 due to None values in features.\n",
      "\n",
      "Layer: 2757, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2757 due to None values in features.\n",
      "\n",
      "Layer: 2759, Weights: ()\n",
      "0.016443836\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2759 due to None values in features.\n",
      "\n",
      "Layer: 2760, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2760 due to None values in features.\n",
      "\n",
      "Layer: 2769, Weights: ()\n",
      "0.007936166\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2769 due to None values in features.\n",
      "\n",
      "Layer: 2770, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2770 due to None values in features.\n",
      "\n",
      "Layer: 2788, Weights: ()\n",
      "0.031183232\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2788 due to None values in features.\n",
      "\n",
      "Layer: 2789, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2789 due to None values in features.\n",
      "\n",
      "Layer: 2791, Weights: ()\n",
      "0.031183232\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2791 due to None values in features.\n",
      "\n",
      "Layer: 2792, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2792 due to None values in features.\n",
      "\n",
      "Layer: 2801, Weights: ()\n",
      "0.012595718\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2801 due to None values in features.\n",
      "\n",
      "Layer: 2802, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2802 due to None values in features.\n",
      "\n",
      "Layer: 2813, Weights: ()\n",
      "0.03574642\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2813 due to None values in features.\n",
      "\n",
      "Layer: 2814, Weights: ()\n",
      "149\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2814 due to None values in features.\n",
      "\n",
      "Layer: 2816, Weights: ()\n",
      "0.03574642\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2816 due to None values in features.\n",
      "\n",
      "Layer: 2817, Weights: ()\n",
      "149\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2817 due to None values in features.\n",
      "\n",
      "Layer: 2821, Weights: ()\n",
      "0.02031845\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2821 due to None values in features.\n",
      "\n",
      "Layer: 2822, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2822 due to None values in features.\n",
      "\n",
      "Layer: 2824, Weights: ()\n",
      "0.02031845\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2824 due to None values in features.\n",
      "\n",
      "Layer: 2825, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2825 due to None values in features.\n",
      "\n",
      "Layer: 2834, Weights: ()\n",
      "0.0042139324\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2834 due to None values in features.\n",
      "\n",
      "Layer: 2835, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2835 due to None values in features.\n",
      "\n",
      "Layer: 2853, Weights: ()\n",
      "0.009938193\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2853 due to None values in features.\n",
      "\n",
      "Layer: 2854, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2854 due to None values in features.\n",
      "\n",
      "Layer: 2856, Weights: ()\n",
      "0.009938193\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2856 due to None values in features.\n",
      "\n",
      "Layer: 2857, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2857 due to None values in features.\n",
      "\n",
      "Layer: 2866, Weights: ()\n",
      "0.020041121\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2866 due to None values in features.\n",
      "\n",
      "Layer: 2867, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2867 due to None values in features.\n",
      "\n",
      "Layer: 2885, Weights: ()\n",
      "0.024274016\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2885 due to None values in features.\n",
      "\n",
      "Layer: 2886, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2886 due to None values in features.\n",
      "\n",
      "Layer: 2888, Weights: ()\n",
      "0.024274016\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2888 due to None values in features.\n",
      "\n",
      "Layer: 2889, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2889 due to None values in features.\n",
      "\n",
      "Layer: 2898, Weights: ()\n",
      "0.052959803\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2898 due to None values in features.\n",
      "\n",
      "Layer: 2899, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2899 due to None values in features.\n",
      "\n",
      "Layer: 2910, Weights: ()\n",
      "0.16136523\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2910 due to None values in features.\n",
      "\n",
      "Layer: 2911, Weights: ()\n",
      "66\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2911 due to None values in features.\n",
      "\n",
      "Layer: 2913, Weights: ()\n",
      "0.16136523\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2913 due to None values in features.\n",
      "\n",
      "Layer: 2914, Weights: ()\n",
      "66\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2914 due to None values in features.\n",
      "\n",
      "Layer: 2919, Weights: ()\n",
      "0.02031845\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2919 due to None values in features.\n",
      "\n",
      "Layer: 2920, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2920 due to None values in features.\n",
      "\n",
      "Layer: 2929, Weights: ()\n",
      "0.07489582\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2929 due to None values in features.\n",
      "\n",
      "Layer: 2930, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2930 due to None values in features.\n",
      "\n",
      "Layer: 2941, Weights: ()\n",
      "0.16670407\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2941 due to None values in features.\n",
      "\n",
      "Layer: 2942, Weights: ()\n",
      "50\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2942 due to None values in features.\n",
      "\n",
      "Layer: 2944, Weights: ()\n",
      "0.16670407\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2944 due to None values in features.\n",
      "\n",
      "Layer: 2945, Weights: ()\n",
      "50\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2945 due to None values in features.\n",
      "\n",
      "Layer: 2949, Weights: ()\n",
      "0.16626795\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2949 due to None values in features.\n",
      "\n",
      "Layer: 2950, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2950 due to None values in features.\n",
      "\n",
      "Layer: 2952, Weights: ()\n",
      "0.16626795\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2952 due to None values in features.\n",
      "\n",
      "Layer: 2953, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2953 due to None values in features.\n",
      "\n",
      "Layer: 2962, Weights: ()\n",
      "0.0020797148\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2962 due to None values in features.\n",
      "\n",
      "Layer: 2963, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2963 due to None values in features.\n",
      "\n",
      "Layer: 2981, Weights: ()\n",
      "0.01461363\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2981 due to None values in features.\n",
      "\n",
      "Layer: 2982, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2982 due to None values in features.\n",
      "\n",
      "Layer: 2984, Weights: ()\n",
      "0.01461363\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2984 due to None values in features.\n",
      "\n",
      "Layer: 2985, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2985 due to None values in features.\n",
      "\n",
      "Layer: 2994, Weights: ()\n",
      "0.008441465\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2994 due to None values in features.\n",
      "\n",
      "Layer: 2995, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 2995 due to None values in features.\n",
      "\n",
      "Layer: 3013, Weights: ()\n",
      "0.009625321\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3013 due to None values in features.\n",
      "\n",
      "Layer: 3014, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3014 due to None values in features.\n",
      "\n",
      "Layer: 3016, Weights: ()\n",
      "0.009625321\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3016 due to None values in features.\n",
      "\n",
      "Layer: 3017, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3017 due to None values in features.\n",
      "\n",
      "Layer: 3026, Weights: ()\n",
      "0.09111444\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3026 due to None values in features.\n",
      "\n",
      "Layer: 3027, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3027 due to None values in features.\n",
      "\n",
      "Layer: 3038, Weights: ()\n",
      "0.101760626\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3038 due to None values in features.\n",
      "\n",
      "Layer: 3039, Weights: ()\n",
      "83\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3039 due to None values in features.\n",
      "\n",
      "Layer: 3041, Weights: ()\n",
      "0.101760626\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3041 due to None values in features.\n",
      "\n",
      "Layer: 3042, Weights: ()\n",
      "83\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3042 due to None values in features.\n",
      "\n",
      "Layer: 3046, Weights: ()\n",
      "0.16612937\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3046 due to None values in features.\n",
      "\n",
      "Layer: 3047, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3047 due to None values in features.\n",
      "\n",
      "Layer: 3049, Weights: ()\n",
      "0.16612937\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3049 due to None values in features.\n",
      "\n",
      "Layer: 3050, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3050 due to None values in features.\n",
      "\n",
      "Layer: 3059, Weights: ()\n",
      "0.0018061957\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3059 due to None values in features.\n",
      "\n",
      "Layer: 3060, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3060 due to None values in features.\n",
      "\n",
      "Layer: 3078, Weights: ()\n",
      "0.034167048\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3078 due to None values in features.\n",
      "\n",
      "Layer: 3079, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3079 due to None values in features.\n",
      "\n",
      "Layer: 3081, Weights: ()\n",
      "0.034167048\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3081 due to None values in features.\n",
      "\n",
      "Layer: 3082, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3082 due to None values in features.\n",
      "\n",
      "Layer: 3091, Weights: ()\n",
      "0.009397319\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3091 due to None values in features.\n",
      "\n",
      "Layer: 3092, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3092 due to None values in features.\n",
      "\n",
      "Layer: 3110, Weights: ()\n",
      "0.011096133\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3110 due to None values in features.\n",
      "\n",
      "Layer: 3111, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3111 due to None values in features.\n",
      "\n",
      "Layer: 3113, Weights: ()\n",
      "0.011096133\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3113 due to None values in features.\n",
      "\n",
      "Layer: 3114, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3114 due to None values in features.\n",
      "\n",
      "Layer: 3123, Weights: ()\n",
      "0.16579606\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3123 due to None values in features.\n",
      "\n",
      "Layer: 3124, Weights: ()\n",
      "128\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3124 due to None values in features.\n",
      "\n",
      "Layer: 3135, Weights: ()\n",
      "0.21070026\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3135 due to None values in features.\n",
      "\n",
      "Layer: 3136, Weights: ()\n",
      "72\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3136 due to None values in features.\n",
      "\n",
      "Layer: 3138, Weights: ()\n",
      "0.21070026\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3138 due to None values in features.\n",
      "\n",
      "Layer: 3139, Weights: ()\n",
      "72\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3139 due to None values in features.\n",
      "\n",
      "Layer: 3145, Weights: ()\n",
      "0\n",
      "Calculating features for matrix with shape: ()\n",
      "Skipping feature calculation for scalar tensor with shape ()\n",
      "Skipping layer 3145 due to None values in features.\n",
      "\n",
      "Layer: Conv_13.weight_quantized, Weights: (64, 3, 7, 7)\n",
      "[[[[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 132 131 128]\n",
      "   [132 135 138 ... 139 134 128]\n",
      "   ...\n",
      "   [126 118 113 ... 116 124 128]\n",
      "   [128 128 133 ... 138 136 135]\n",
      "   [128 131 132 ... 131 130 129]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 129]\n",
      "   [128 128 132 ... 137 134 132]\n",
      "   [134 138 144 ... 142 132 124]\n",
      "   ...\n",
      "   [120 112 102 ... 109 122 128]\n",
      "   [128 128 132 ... 145 142 139]\n",
      "   [128 133 137 ... 136 133 130]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   [129 132 133 ... 136 132 128]\n",
      "   ...\n",
      "   [125 123 118 ... 123 128 128]\n",
      "   [128 128 133 ... 136 133 132]\n",
      "   [130 128 128 ... 128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128 ... 128 128 127]\n",
      "   [128 128 128 ... 128 134 128]\n",
      "   [128 128 125 ... 128 135 128]\n",
      "   ...\n",
      "   [128 130 124 ... 124 128 131]\n",
      "   [128 133 128 ... 124 128 131]\n",
      "   [128 133 133 ... 124 126 128]]\n",
      "\n",
      "  [[128 128 128 ... 134 133 123]\n",
      "   [126 128 125 ... 136 140 131]\n",
      "   [128 123 120 ... 131 144 141]\n",
      "   ...\n",
      "   [130 131 119 ... 113 129 139]\n",
      "   [135 139 128 ... 114 124 135]\n",
      "   [128 138 138 ... 118 121 130]]\n",
      "\n",
      "  [[128 128 128 ... 132 130 122]\n",
      "   [127 128 126 ... 133 136 129]\n",
      "   [128 128 121 ... 130 138 136]\n",
      "   ...\n",
      "   [129 131 123 ... 118 128 135]\n",
      "   [132 136 128 ... 119 125 133]\n",
      "   [128 136 136 ... 121 124 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128 ... 128 128 123]\n",
      "   [128 128 125 ... 137 133 130]\n",
      "   [128 125 117 ... 128 135 134]\n",
      "   ...\n",
      "   [128 136 140 ... 128 121 124]\n",
      "   [127 128 128 ... 137 132 128]\n",
      "   [128 127 125 ... 128 128 128]]\n",
      "\n",
      "  [[122 128 128 ... 131 128 128]\n",
      "   [128 122 123 ... 143 141 137]\n",
      "   [128 123 109 ... 120 137 141]\n",
      "   ...\n",
      "   [135 142 151 ... 128 112 117]\n",
      "   [122 128 137 ... 145 132 125]\n",
      "   [126 122 123 ... 134 134 128]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 124 128 ... 137 133 131]\n",
      "   [128 125 117 ... 126 133 135]\n",
      "   ...\n",
      "   [133 134 139 ... 128 119 122]\n",
      "   [128 128 132 ... 139 128 125]\n",
      "   [123 125 125 ... 128 134 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[131 128 130 ... 128 128 128]\n",
      "   [128 128 128 ... 125 126 128]\n",
      "   [129 128 128 ... 124 124 125]\n",
      "   ...\n",
      "   [129 126 124 ... 118 119 121]\n",
      "   [128 125 124 ... 119 122 122]\n",
      "   [128 128 126 ... 122 125 125]]\n",
      "\n",
      "  [[125 128 126 ... 128 128 129]\n",
      "   [126 128 128 ... 132 132 128]\n",
      "   [127 128 129 ... 134 135 135]\n",
      "   ...\n",
      "   [128 131 134 ... 142 140 140]\n",
      "   [128 132 134 ... 140 138 137]\n",
      "   [128 128 134 ... 139 137 136]]\n",
      "\n",
      "  [[129 128 128 ... 128 128 128]\n",
      "   [130 128 128 ... 126 126 128]\n",
      "   [128 128 127 ... 126 125 123]\n",
      "   ...\n",
      "   [128 127 126 ... 124 124 124]\n",
      "   [128 126 125 ... 124 123 124]\n",
      "   [128 128 124 ... 122 122 123]]]\n",
      "\n",
      "\n",
      " [[[125 139 114 ... 138 127 124]\n",
      "   [142  97 154 ...  80 142 131]\n",
      "   [118 150 128 ... 213 110 121]\n",
      "   ...\n",
      "   [128 106 190 ...  73 222  82]\n",
      "   [128 128 128 ... 214  57 155]\n",
      "   [128 128 120 ...  99 143 125]]\n",
      "\n",
      "  [[119 141 111 ... 130 128 128]\n",
      "   [131 106 158 ...  86 146 128]\n",
      "   [119 156 128 ... 228 104 123]\n",
      "   ...\n",
      "   [143  95 191 ...  64 239  86]\n",
      "   [128 128 128 ... 230  55 138]\n",
      "   [128 128 128 ...  91 146 132]]\n",
      "\n",
      "  [[128 139 113 ... 147 113 128]\n",
      "   [143  97 156 ...  94 151 128]\n",
      "   [113 140 152 ... 197 105 123]\n",
      "   ...\n",
      "   [128 101 171 ...  99 209  80]\n",
      "   [134 128 128 ... 201  42 165]\n",
      "   [124 136 120 ...  86 165 116]]]\n",
      "\n",
      "\n",
      " [[[129 128 129 ... 128 128 130]\n",
      "   [128 128 128 ... 128 128 129]\n",
      "   [128 128 128 ... 124 128 128]\n",
      "   ...\n",
      "   [128 128 125 ... 121 123 126]\n",
      "   [129 128 128 ... 122 125 128]\n",
      "   [131 130 128 ... 126 128 130]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 128 128 128]\n",
      "   ...\n",
      "   [128 126 126 ... 128 126 127]\n",
      "   [128 127 127 ... 126 126 128]\n",
      "   [128 128 128 ... 126 127 128]]\n",
      "\n",
      "  [[128 128 128 ... 128 128 128]\n",
      "   [128 128 128 ... 130 128 128]\n",
      "   [128 128 128 ... 131 127 128]\n",
      "   ...\n",
      "   [128 129 131 ... 137 133 131]\n",
      "   [128 128 129 ... 133 131 129]\n",
      "   [125 128 128 ... 131 129 128]]]]\n",
      "Calculating features for matrix with shape: (64, 3, 7, 7)\n",
      "Features for Conv_13.weight_quantized:\n",
      "  density: 0.9998937074829932\n",
      "  nnz_min: 146\n",
      "  nnz_max: 147\n",
      "  nnz_avg: 146.984375\n",
      "  nnz_sd: 0.12401959270615269\n",
      "  bw_min: 147\n",
      "  bw_max: 147\n",
      "  bw_avg: 147.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9998937074761913\n",
      "  scatter_sd: 0.00084367069867557\n",
      "  clustering_avg: 0.006910469667271964\n",
      "\n",
      "\n",
      "Layer: Conv_13.bias_quantized, Weights: (64,)\n",
      "[  502  2449  2908  2217  1431  2526  1388     0  2405  2476  3263  1480\n",
      "  2118  2578     0     0  2670  1402  5580  2602  1817  2642 -4031  2445\n",
      "  2303  2604     0  2560   600  1854 -5320  2840  5602 15369  6077   971\n",
      " -3694 -4502  3352  1044  3122  1395  2059  2031  3353  3302  1830 11378\n",
      "  1167 -3398  3675  2520     0  1894 -2073  3931    58  1634  1968  2318\n",
      " 17784  9238  3085  5617]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_13.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_37.weight_quantized, Weights: (64, 64, 1, 1)\n",
      "[[[[145]]\n",
      "\n",
      "  [[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 77]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[103]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[137]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[152]]\n",
      "\n",
      "  [[125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[131]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  [[135]]]]\n",
      "Calculating features for matrix with shape: (64, 64, 1, 1)\n",
      "Features for Conv_37.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_37.bias_quantized, Weights: (64,)\n",
      "[-1477   615  3969  3359  1582  1853   837  3852  1069   586  1100  1991\n",
      "  2132  1282 -1438  2941  6170 -6713  2784  1209  1807  1920     0 -2709\n",
      "   438  1532  2773  1182 -2083  2103  -207  1097  1129  -125  2675  2473\n",
      "  1586  1725  1425  1287  5002 -6307  1451  1004  1720  3521  1469 -1860\n",
      "  5783  1990  2608  3726  4646  1957  1301  2174  -655   349  4417 -1877\n",
      "  5343  1460  1994  -922]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_37.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_60.weight_quantized, Weights: (64, 64, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[133 133 134]\n",
      "   [133 128 134]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [133 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[135 128 135]\n",
      "   [132 128 139]\n",
      "   [137 135 137]]]\n",
      "\n",
      "\n",
      " [[[122 124 121]\n",
      "   [125 113 121]\n",
      "   [128 123 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 142 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 133]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 143 130]\n",
      "   [128 122 128]\n",
      "   [128 114 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [136 136 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 150 136]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 124 128]\n",
      "   [128 116 117]\n",
      "   [142 152 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 133]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 136 114]\n",
      "   [128 133 128]]\n",
      "\n",
      "  [[128 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 135 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 115]\n",
      "   [128 150 128]\n",
      "   [120 128 113]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [113 111 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 110 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[133 142 141]\n",
      "   [128 133 138]\n",
      "   [128 137 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [118 128 128]]\n",
      "\n",
      "  [[128 134 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 117 128]\n",
      "   [128 120 128]]]]\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_60.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_60.bias_quantized, Weights: (64,)\n",
      "[  5019  -1430   2212   3038   1883  -3903  -1109    413   4875    157\n",
      "   4532   4178   1868   3423   1020   3999  -5731   1257   -812  -1769\n",
      "  -1622  -3293  -5529     81  -4092   5583   3345  -7069    417  -2522\n",
      "  -2443      0  -3616   1634   3873    328   4257  -9223   5522  -5813\n",
      "  -1333  -6256  -3196  -4988 -15301  -1049   2541   5118   5370   2457\n",
      "   5403  -8471    133   -191    209  -7706  -5731   -847  -4800    272\n",
      "   4445  -1001  17561  -3091]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_60.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_83.weight_quantized, Weights: (256, 64, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[143]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[130]]]\n",
      "\n",
      "\n",
      " [[[139]]\n",
      "\n",
      "  [[129]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_83.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_83.bias_quantized, Weights: (256,)\n",
      "[   38   418  -570  3750   163  1410  -995  -421  -548 -1505   213     0\n",
      "  1334   628    66  1112   896     0  -744     0     0 -1184   737  -140\n",
      "   275   462  -146  2398     0  2349   991     0  1652  2571 -2698  -216\n",
      "    55  -563  -582  -201   372     0     0   177     0   506  1429     0\n",
      "  -831   133   557   247  1928     0 -1474    37   606  -597     0     0\n",
      "  -242  -531  1415     0  -725  -173  -278  -313     0    23    -6     0\n",
      "   457 -1471 -1733  1360     0  -142  -177     0  1880  -897  2210  1004\n",
      "  -176 -2300     0     0     0  2002   715  -369  -648  -632  2311   179\n",
      "   346  1025  -326   305     0  -386     0     0  1560   -59  1810  -670\n",
      "  -425   547   689     0     0     0     0     0     0   -20 -3329  2913\n",
      " -1455     0  1160  -741  1192   -70  1504  -536     0   665     0  2198\n",
      "  -754   485     0     0     0   159     0     0  1619  -715   281     0\n",
      "  1218 -2891     0   259     0  -810     0     0  1482     0  -873  2141\n",
      "   544  -434  3383     0  -259  -408   478   532   596  -780  1120  -168\n",
      "     0   -36     0 -2977     0   265   450  1826     0   101  1804   204\n",
      "  -573  2263 -1080 -1051  -686     0     0   815   491   303     0   211\n",
      "   699   266  1043  -111   800   585   750  1757     0  -654  1289     0\n",
      "  -684   152     0     0 -1017  1294  -183     0   244     0     0  -163\n",
      "   996     0   905     0  -486     0     9   563     0  1842     0     0\n",
      "   485   808   186  -328  -446     0     0     0 -1699  -329  -696  -436\n",
      "   414     0  1151  -567  1537   699   608 -1564   411   741  -202     0\n",
      "  -203   184  -671   985]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_83.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_105.weight_quantized, Weights: (256, 64, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[134]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[102]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[118]]\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[104]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_105.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_105.bias_quantized, Weights: (256,)\n",
      "[  488   137   642  -713   546  -576   484  1279   214  1265  -150     0\n",
      "  1199   101   600   158 -2215     0  -962     0     0 -1321  -528  1180\n",
      "  1958  -556    79 -1375     0 -1039  8862     0   939   312  -800   548\n",
      "   300  1399   384   478  2315     0     0   -69     0  1489  -794     0\n",
      "  -225  5654   345  1436   723     0  -523  1307   777   -51     0     0\n",
      "  2136   -51   997     0  1721   -26 -1215   197     0   201    41     0\n",
      "  1713 -1314 -1363  -136     0   514   527     0  -859  -527  -687  3123\n",
      "  -329    67     0     0     0   163 -1633  1497   959  1377  1128   731\n",
      " -1813  -118   226   -54     0  1067     0     0   289  1536  1332   532\n",
      "  1604   115  1046     0     0     0     0     0     0  1212  1235   451\n",
      "  -515     0  -309   268  1624  -229   293  4062     0   948     0 -1793\n",
      "   917  1788     0     0     0  -192     0     0   649  2951  3538     0\n",
      "   285   339     0  1220     0   345     0     0   279     0   924 -1326\n",
      "  -346  -302  1623     0   605 -2036  -311   107 -1090  5197   720   -44\n",
      "     0  1900     0   706     0     4  -376  -280     0  1575  -304  -269\n",
      "  2124  3160  -111  2812  -340     0     0  1172   -66   284     0  2140\n",
      "   390   335   419   740   565   694   201   410     0  1147   934     0\n",
      "  1117   273     0     0  1018   596   660     0  1649     0     0  1696\n",
      "  3769     0    87     0   341     0   886  -361     0   106     0     0\n",
      "  1359   386   632   -80   192     0     0     0   945   614  1474   831\n",
      "  -357     0   155  -415 -1087    78   393  -790     6   -74   709     0\n",
      "  -683   -86   864  -232]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_105.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_129.weight_quantized, Weights: (64, 256, 1, 1)\n",
      "[[[[115]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[108]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[136]]\n",
      "\n",
      "  [[147]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[107]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[117]]\n",
      "\n",
      "  [[151]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (64, 256, 1, 1)\n",
      "Features for Conv_129.weight_quantized:\n",
      "  density: 0.99993896484375\n",
      "  nnz_min: 255\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 255.984375\n",
      "  nnz_sd: 0.12401959270615269\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999938964839844\n",
      "  scatter_sd: 0.0004844515340065226\n",
      "  clustering_avg: 0.003967763863342343\n",
      "\n",
      "\n",
      "Layer: Conv_129.bias_quantized, Weights: (64,)\n",
      "[12834  1934 -1646  1064 -4286  3437  5578  6415  3257   786   740  2128\n",
      "   757 -4956 -3501 -1838  -237  1729  1376   934   588 -2336 -1293 -3506\n",
      "  1743  4447  1038  3369   727  3284 -3312 -2814  1440   941 -1955  1694\n",
      "  1187  2205  6455 -1966  3733 -4143  2825 -3446  1693 -1219 -1683 -3463\n",
      "  -372  -118 -2123  -690 -5525  5902  6304    -8 -3010 -3209  3514  2639\n",
      "  3443   553   193  4577]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_129.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_152.weight_quantized, Weights: (64, 64, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 125 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 123]\n",
      "   [128 128 128]\n",
      "   [128 128 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 130 128]\n",
      "   [128 128 124]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 129 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [127 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [123 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 131 128]]\n",
      "\n",
      "  [[119 128 122]\n",
      "   [128 123 128]\n",
      "   [128 124 136]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 134]\n",
      "   [128 123 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 132 128]\n",
      "   [128 128 128]\n",
      "   [128 126 128]]\n",
      "\n",
      "  [[128 131 128]\n",
      "   [133 128 125]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 119]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 126 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 127]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 122 128]\n",
      "   [128 128 128]\n",
      "   [132 135 130]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[136 134 128]\n",
      "   [128 128 128]\n",
      "   [128 133 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_152.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_152.bias_quantized, Weights: (64,)\n",
      "[ 1020  1794  2396  2621  2188  1816  2157     0  1683   175  3477 -2470\n",
      "   886 -3116  6011   786     0  1056  1274  2328     1    68  1123 -1637\n",
      "   452  1282  5163   808  1451  1236 -2359   453  2488  1082  1708  3070\n",
      "  1775   116  1450  2515  2069   932   454  -665  2445  -916  1410   867\n",
      "  -677  3520   745     0   767  2545  1226   351     0 -1644  1582  2508\n",
      "  2263 -2077   504  1001]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_152.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_175.weight_quantized, Weights: (256, 64, 1, 1)\n",
      "[[[[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[123]]\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[151]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[133]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[114]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[107]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[113]]]]\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_175.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_175.bias_quantized, Weights: (256,)\n",
      "[ -626  -953     8  3692  1363 -1419    63  -516    29    93   906  2466\n",
      "   600  -254    18  -143     6     0  -121   626     0    18 -2521    83\n",
      "    18    51  1097   282    55  1175    35   200    37   -23    14    12\n",
      "  1215    17    17   784 -1841  -314  -629 -1396  2069    32    47  -248\n",
      "   -62    28    43    26    38  -244    -6   137   570    13   166  1194\n",
      "  -862  -248   233 -2201   760  -654    29 -2109   448    27    37  1830\n",
      "    25    10    52 -1190     0    13 -1951   -66  -483  -922  -527    23\n",
      "  1851    31   747   702     0    37  -860  -186  3424   641     9 -2051\n",
      "  -181   608   -20    72     0  -132  1208  -629  -275   560  2635   416\n",
      "    26   896   221  1309   150   977   498  -155     0 -1393    26    35\n",
      " -1221  -384   942    19  -623   -59  -457    28  -925    20  3296  -780\n",
      "  -575    14  1177 -1161     0   244  -684    91   425 -1946    17 -1733\n",
      " -1256     3  -747    18   608  1368     0  1302   116  -275     2    64\n",
      "  2090  2596    32   378 -1088    13    74 -1597   146    23  1011  -974\n",
      "   741 -2077   940    31 -1228 -2309    21    99 -1740    22  1963  -834\n",
      "   683     0   117    10    89     0   780 -1341    27  -460 -1272 -2069\n",
      "  2957   279   455 -1256   784   -30    52  -793   247  2130  -286   723\n",
      "    45    -7  1735 -1392    60   493  -389 -1383   371  1219 -3172   115\n",
      "    36 -2517 -1055   821 -1455  1014 -1123   619     0    24     0   252\n",
      "    15    53    38   312    11     0     0 -2222   362  2182   -99   820\n",
      "  1112  2131   440  -398  1456 -4102    16    31  -154  -996  2963 -2132\n",
      "    49  -337  1681   669]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_175.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_199.weight_quantized, Weights: (64, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[153]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[103]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[138]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[152]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (64, 256, 1, 1)\n",
      "Features for Conv_199.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_199.bias_quantized, Weights: (64,)\n",
      "[ 3865   831 -1323   658  5495  1233  3945  5014 -1803  1338  -752  1721\n",
      "  1376 -3033  3615  1752  6130 -5932   920  4475   438   323  2751 -1928\n",
      "   913   451  2191  -670  1358 -2980  -545  -526   775   626 -3472   592\n",
      "   126  2540     0  -964  3307  5149  -562  1426  3421  3624  -702 -2313\n",
      "   901  2015  2004  3039  1710  2921  6563  4936  -272 -2662  -207   652\n",
      " -3206  3920 -3335  4682]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_199.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_222.weight_quantized, Weights: (64, 64, 3, 3)\n",
      "[[[[128 115 128]\n",
      "   [128 141 128]\n",
      "   [119 128 128]]\n",
      "\n",
      "  [[128 128 112]\n",
      "   [128 133 128]\n",
      "   [128 132 128]]\n",
      "\n",
      "  [[128 119 147]\n",
      "   [128 117 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [120 128 128]]\n",
      "\n",
      "  [[133 117 128]\n",
      "   [128 128 116]\n",
      "   [128 120 155]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [108 135 105]\n",
      "   [128 153 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 145]\n",
      "   [128 106 103]\n",
      "   [128 128 151]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[117 128 128]\n",
      "   [128 106 112]\n",
      "   [128 160 154]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128  98 110]\n",
      "   [128 128 152]]\n",
      "\n",
      "  [[139 147 128]\n",
      "   [128 105 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 130 136]\n",
      "   [116 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 140]\n",
      "   [142 104 128]\n",
      "   [128 135 128]]\n",
      "\n",
      "  [[128 114 128]\n",
      "   [144  89 168]\n",
      "   [128 114 142]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 139]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128  99]\n",
      "   [128 149 114]]\n",
      "\n",
      "  [[128 128 134]\n",
      "   [144 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 108]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 132]\n",
      "   [112 161 109]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [100 139 137]\n",
      "   [128 150 128]]\n",
      "\n",
      "  [[128 128 122]\n",
      "   [128 112 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [104 157 104]\n",
      "   [128 144 116]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 138 128]\n",
      "   [124 128 128]\n",
      "   [140 117 128]]\n",
      "\n",
      "  [[128 128 122]\n",
      "   [128 128 121]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[114 128 128]\n",
      "   [128 155 128]\n",
      "   [117 128 135]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [142 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [143 128 113]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 113 128]\n",
      "   [128 135 129]]\n",
      "\n",
      "  [[128 117 140]\n",
      "   [128 128 122]\n",
      "   [128 140 117]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126 138 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[137 144 128]\n",
      "   [128 105 108]\n",
      "   [128 128 149]]\n",
      "\n",
      "  [[128 128 152]\n",
      "   [128  89 128]\n",
      "   [128 138 128]]]]\n",
      "Calculating features for matrix with shape: (64, 64, 3, 3)\n",
      "Features for Conv_222.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 576\n",
      "  nnz_max: 576\n",
      "  nnz_avg: 576.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 576\n",
      "  bw_max: 576\n",
      "  bw_avg: 576.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999982638\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.0017361111111080971\n",
      "\n",
      "\n",
      "Layer: Conv_222.bias_quantized, Weights: (64,)\n",
      "[ 10372   5483   6402  -1918   1561   2258  -5370   2314  -5619   1486\n",
      "   1261 -15081   6986   3368  -2966   4236  -4541   2354   9803   6244\n",
      "  -5982   5642   -846   2192  -3317   7094  -9560   -569  -4704   3552\n",
      "   3644   -144  10376   4057   8797   2958   8283   7064   -443   -728\n",
      "    241   6765  -5985 -12638  -3037   2969  11904  -2646   6707  -3374\n",
      "   -616   8272  -2507   1211  -6315  -4734  -5204  11451  -1708  -2823\n",
      "   5440  -1860   4505  10173]\n",
      "Calculating features for matrix with shape: (64,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (64,)\n",
      "Skipping layer Conv_222.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_245.weight_quantized, Weights: (256, 64, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[133]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[140]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[111]]\n",
      "\n",
      "  [[ 80]]\n",
      "\n",
      "  [[164]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 64, 1, 1)\n",
      "Features for Conv_245.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 64\n",
      "  nnz_max: 64\n",
      "  nnz_avg: 64.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 64\n",
      "  bw_max: 64\n",
      "  bw_avg: 64.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.999999999984375\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.01562499999975586\n",
      "\n",
      "\n",
      "Layer: Conv_245.bias_quantized, Weights: (256,)\n",
      "[   41  -149     7   -12  -304  -622    -2    18     7     9 -2582  -922\n",
      " -1057 -2547    16  1039    -3    81   -79   902 -4585     6 -1826     6\n",
      "     3    12   -21  -383 -1028    25    13  -124    29     3  -126    13\n",
      "    13    -7     8   260 -1645     8    41  -360 -1564    18    -8 -1913\n",
      "   930     2    19    26   212 -1102    14  1625  -312     5 -1617  -925\n",
      "   -65 -1345   792   187 -1263    44    22 12883 -1237    30  -233   874\n",
      "     5     6  1840  1248  -963     7  -126  -421    19  -389 -2108    19\n",
      "  -662    14  1694   756  1577     8     2    38  1241    42     6  1489\n",
      " -2463 -2295   614    18  1342  -400 -2060    22 -3219  1440    21  -540\n",
      "    20 -1517   111 -2585   835 -2315  -229   227  4539    51     8     1\n",
      "   191  1590    15    25  -376   106    -7     6 -1019   -10    30 -3932\n",
      " -1005    20  -872   516  4338   287  6621  -332   913  -591     2  1431\n",
      " -1151    17   621     8 -4922 -1806  1672 -1948  -154  -769    -6   833\n",
      "     3     7     8    23     6     7    19  1628    23    16  3376  -348\n",
      " -2008    37  -170     5  2004 -4578    -2     8 -1977    15  -788    55\n",
      "   705     4   -73    12    10   282  1134  -159    49  -192  -802 -1386\n",
      " -2826  1319 -1291   124   307   -13    17   413 -2634   818  -387 -1831\n",
      "   -17     8  -337  1729   -18 -1930 -1235 -1808    65 -2264 -2926    -2\n",
      "     4 -4997    12  -836   -92  -788  -289  -580  1147    34  -747  3645\n",
      "     2 -2046    26 -1419     0   384 -6792    31  -592 -1983 -1540  -606\n",
      " -1243   941 -3019  -194  -763 -8520     5  2275   556  1399  -298    22\n",
      "    20    48  -984 -1249]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_245.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_269.weight_quantized, Weights: (128, 256, 1, 1)\n",
      "[[[[ 87]]\n",
      "\n",
      "  [[ 73]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[148]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[158]]\n",
      "\n",
      "  [[108]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[142]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[113]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (128, 256, 1, 1)\n",
      "Features for Conv_269.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_269.bias_quantized, Weights: (128,)\n",
      "[ -214  -532 -1818 -1817   809 -9544  -662    16 -2590   294   377   -92\n",
      "  2388  1121  2067 -4185   707 -6425   661   942  1812 -2121   542 -3626\n",
      "   403     0  1175 -1606  2498 -1695   971 -1211  -534   703   722 -1465\n",
      "  1522  -282  3835  -654  1171   480 -1449   964   880  -370 -1245   240\n",
      "  -241  1213  1718  1669  2784   589  -860 -2653   376 -4514   -91  4579\n",
      "  1411  -131  -350  -595  1186  -350   498     0   815  4578   665 -1345\n",
      "  2011 -2989 -1660  1066  -632   -17 -1149  2147  -919  1691 -1745   618\n",
      "  2741   504   478  3045  3441 -1954   362  -219 -2094  1925  2136  -939\n",
      "   579   285   731  -911 -1930  1558   607 -1577  2435  1290   843   238\n",
      "   346   422  -656  -770    95  -872  1625  1846  3672 -3737  8074 -3172\n",
      " -1904 -1001  1450   160  2087 -2380   252   214]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_269.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_292.weight_quantized, Weights: (128, 128, 3, 3)\n",
      "[[[[128 128 119]\n",
      "   [128 120 121]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 120]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[124 128 128]\n",
      "   [117 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 133]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[124 128 128]\n",
      "   [128 128 118]\n",
      "   [128 115 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 124]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 123 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 135 128]\n",
      "   [128 139 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 114]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143 156 144]\n",
      "   [147 158 155]\n",
      "   [128 141 147]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[109 102 103]\n",
      "   [128 113 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 140]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[116 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[134 128 128]\n",
      "   [145 128 128]\n",
      "   [128 137 132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_292.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_292.bias_quantized, Weights: (128,)\n",
      "[   388    -45   3853   -375   1022   -670   -470   8750    342   7863\n",
      "  -3941   7329  -1398   3269   -588   4839     30   6677   6319   1088\n",
      "   5431   2879   2406   6281   2331   2479   4726   -528  -1367   3880\n",
      "    -55   1128   4536   3093 -11005  -2594   8401   3865    251   6113\n",
      "   3934   1529  -2423  -3032    277   7824   8621   1034   4506   -918\n",
      "  -1706    662    809  -1065   -674     13  -3521   -409   -496  -1537\n",
      "  -3909   2355  -1009   3243   -194   6816  -1467    376     53   4461\n",
      "  12178    620  -1534    432   3660   -899   1890  -2274   1291   -850\n",
      "   2520   4616  -1144   3533  -2773   4713   4574  -1028   9735  -1464\n",
      "  -1806   2971   3465  -3312   4405   7463   1719    438   9228   -774\n",
      "   3595  -1393   -209   2404    439    894   3512   -760  -2317   1169\n",
      "   8542   -199   2988  -3323   7122   -741   7369   1672   -697   4841\n",
      "   2984   7805   3225   2093   2747   4374  -3095   2939]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_292.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_315.weight_quantized, Weights: (512, 128, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[138]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[108]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[147]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[168]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n",
      "Features for Conv_315.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_315.bias_quantized, Weights: (512,)\n",
      "[    0  1145   107  4142   556  -685  3516     0  2113  1576   316  1007\n",
      "    87  1562   849  1408   584 -2991  5610   337   387   890     0  -480\n",
      "     0  -171   710   589     0     0     0    83  1646     0     0   304\n",
      "    32     0   987  1087   -10     0  1093     0   677  -755     0     0\n",
      " -2163     0     0   354   861 -3511   367  -504     5  -290  2831  1604\n",
      "   150     0   524   159  -749 -1299  2007  2839   895     0  -438     0\n",
      " -4035  -290   240  -814 -1171   362   328  2565     0     0   375     0\n",
      "     0  -421   657 -5102     0   694   847     0     0   615  1320     0\n",
      "  2303   426   808     0  3375  1154  1818  -572     0   735     0   176\n",
      " -2509   514  -230 -5523 -1874  1108   219 -1458 -1987     0  -197   694\n",
      "   715  -132   230  2170   307     0  4916     0  1392  1930     0     0\n",
      "   618     0  -727     0  1884  3157   306   275   305 -1818  -363   927\n",
      "   642  -558  -397 -1540     0     0   613   564   579 -4195   428   525\n",
      "     0  -276     0   683 -1363   244  3177 -1673     0     0   768   781\n",
      "   286   428   397  -304   851  3678  -888     0  1192  2833     0     0\n",
      "     0   245  1961     0  3463   405     0 -2071    33   198  -237   760\n",
      "  -316   406  1165  1391  2356  1189  -379  2954  1182  1573   609  1549\n",
      "   737 -3503  -230  4613    93   873   318  -719     0  -986     0     0\n",
      "     0   339   603   503   924     0  3680    99  -479   676  2338  2801\n",
      "     0   696  3313     0   259 -1294 -1883  3985   506  1193  1150  3238\n",
      "   436  -354   392   404  -856     0     0  1910     0   737   444 -1548\n",
      "     0   805     0    93   652     0  -495     0 -3559  -705    29    -1\n",
      "  2814     0   -48  1234     0   359  1431     0   542 -1950     0   264\n",
      "   524 -2016  2801   266 -2022   252 -1945   860     0  1795     0   715\n",
      "  1506  -662 -1398  1504   440   813   -56   157  4279  1098     0  -249\n",
      "     0   -56     0     0     0 -2325  1029  -626   802     0     0     0\n",
      "   325     0     0 -3150     0     0  -725  6270   -11     0     0     0\n",
      "     0   625     0 -1183 -5357  -171  1119  1188   200     0  -298     0\n",
      "  -377   164  2398   243   539  1296  3672  -863 -2844  -148  1168     0\n",
      "  -158     0   156  9629   942  -701     0  1972 -3011   477     0  1596\n",
      "     0     0     0  -185  1450 -3212 -1748   353   302  -710   315   647\n",
      " -1248  -966    67  1529  -247   -35  3380     0 -2086  -527 -1677   -10\n",
      "     0  5832     0     0  -155  -416  4414  2801     0     0     0   962\n",
      "   128   428     0 -2149  1197  1454 -8382     0    16   505 -1095  -676\n",
      "   858   835   769   367   760   582 -2320     0   185     0     0     0\n",
      "    15  6537     0  1765  -834  1027  -595  2581   272  2489  1762   224\n",
      "  2144 -1106     0   437  1268 -2299   -85   -43     0  -741 -1611     0\n",
      "  -667   674   805     0  1355  2657  -241     0   990     0     0  -304\n",
      "  2611   913 -3516     0  1879 -1799  1969   884     0  2068   710  3176\n",
      "   799 -1851     0  1240     0 -1190  -311  4023  1557  1216  2998     0\n",
      " -6277   -21   785   895  2453   878   708   315   135   496   394  1243\n",
      "     0     0     0  -140    16  1881    23 -1707 -1101     0     0     0\n",
      "   991   757  -360   675 -1180   183   -16   649]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_315.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_337.weight_quantized, Weights: (512, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 256, 1, 1)\n",
      "Features for Conv_337.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_337.bias_quantized, Weights: (512,)\n",
      "[    0  -114   -87  -658    94   -83  -205     0  -154  -168  -420   722\n",
      "   274  1546  3235   484  1211  1789   694  1386  9615   -89     0   307\n",
      "     0  -501 -3580   595     0     0     0  -957  1930     0     0  1116\n",
      "   348     0  1148  1852   711     0   175     0  3343  4262     0     0\n",
      "    58     0     0  -366  3021   353   -50  -395   -72    61  -140    59\n",
      "  2700     0  -771  4871  -105  2233 -1333   739  4378     0   633     0\n",
      "  1486   528  1815 -1292  -300  2125   247  1466     0     0  -502     0\n",
      "     0   264  2355  1567     0   -89  -912     0     0 -1636  1449     0\n",
      "  1688  1270   -65     0   687   330   -79 -4843     0  1085     0  1067\n",
      "  1293  1057   303    87   439   467  1879  -209  -514     0   204  1685\n",
      " -3363   913   783    23   183     0   606     0  1264  6309     0     0\n",
      " -2421     0   182     0   -19  -159  1552  1054  1316   289   554   255\n",
      "   -76  1193   -73  -128     0     0 -3714   -78 -1759   111   499  -384\n",
      "     0  1666     0   -50 -1899  1446   920    55     0     0    63   110\n",
      "  -111   790  3819  -145   952  1667  -210     0 -1664   234     0     0\n",
      "     0   797  3149     0  -197   821     0  -543   234  -537   716   709\n",
      "   -26  1825  3403   350  2496   199   319  -381    -9  1576  1950  -229\n",
      "  -140  -239   165   -79  -472 -1041   -93  1613     0   326     0     0\n",
      "     0  1170   938  2960  2544     0   232 -2769 -1075    67   897  -151\n",
      "     0  1565   906     0   409 -1195    70  1629  1403   -70   373  1047\n",
      "    44   545  -651    66    89     0     0   243     0  1730   140  1298\n",
      "     0  -297     0 -1797  1751     0    74     0   381   107  1160    -1\n",
      "  -776     0   266  2425     0  -156    53     0  -494  -307     0  -443\n",
      "  1304 -2026  1140  1385   334   192  -474  2414     0  -269     0  -179\n",
      "   581  -458   533  3232  -342   -19  -218  -326    73  5146     0   898\n",
      "     0   856     0     0     0 -2012  -345  -339  -754     0     0     0\n",
      "   784     0     0  -394     0     0   100   -57   616     0     0     0\n",
      "     0   582     0 -2784  -329    16  -217   673   439     0   217     0\n",
      "  -525   311 -2371  1299  1310  -387   -12  -481   875   539  -210     0\n",
      "   938     0  -611 -2812  3226   -23     0 -1862   537    96     0  -896\n",
      "     0     0     0   182  -330    41   143  -476    63  -393  1917  3686\n",
      "  -461   426  -470   -41   882  1223    41     0  -111  -362  -832    -9\n",
      "     0   493     0     0   126  -410   794   812     0     0     0    49\n",
      "   869   824     0  1805  1508  2483   899     0  1620  1583  1775 -4104\n",
      "  4311    31   296  -391  -135   638  -705     0  -231     0     0     0\n",
      "   344   499     0   231  -351  -360  -318  4059   601   612   407  1043\n",
      "   599   430     0  -338  -250  1994   326 -3828     0  -183   962     0\n",
      "   414   125  -150     0  -532  2300  1958     0   150     0     0    57\n",
      "   598   966  -349     0  -188  -192   598  1691     0  -813 -4377   385\n",
      "  2149  -459     0  1746     0   361   815   537  1506  -758  1638     0\n",
      "  2194   543  1389  -689  2165  -385   950  1274   200 -1186 -1154  -173\n",
      "     0     0     0   593   601    43  -112    11 -1420     0     0     0\n",
      "   711   547   893 -3107   214   103  -536  -676]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_337.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_361.weight_quantized, Weights: (128, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_361.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_361.bias_quantized, Weights: (128,)\n",
      "[ 5460  2934  1963 -1810  5163 -3674     0   354     0 -1167     0  3609\n",
      "  1437 -1121 -1292     0  1958 -1812 -1027  1364     0 -1709     0     0\n",
      " -1422  1752 -4025 -2316   567  5443  1684  -521  -994  8382 -2755  9407\n",
      "   362  4683     0 -1930  1710 -4231     0   512  5067  2489 -1873  1723\n",
      "  4343 -2364     0 -1206 -1058 -1708  3174   613 -3346  5162  1405  7593\n",
      "  4279 -9115  1108  1645  3216  3363  -925 -1783  3258  1002  2104    74\n",
      "     0   137     0  5802  2134  7249   726  2614 -1369     0  3035     0\n",
      "  1634  5174  1789     0  -835  -339  2862  3519     0 -3291  -322 -1972\n",
      "  1865  2263  2273  1807  3222  7934 -3862     0 -4183  1351   294   303\n",
      "   865  7331  -480  4331  2556 -2210     0   983 -4499 -2063  1560  -417\n",
      "  1009   856 -1512  1351  1604     0     3   274]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_361.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_384.weight_quantized, Weights: (128, 128, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[144 163 148]\n",
      "   [128 128 128]\n",
      "   [118 102 114]]\n",
      "\n",
      "  [[130 137 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 120 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[135 141 136]\n",
      "   [128 128 128]\n",
      "   [120 109 115]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 137 137]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[122 128 128]\n",
      "   [106 128 128]\n",
      "   [116 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 120]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [139 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 137]\n",
      "   [128 128 128]\n",
      "   [111 107 116]]\n",
      "\n",
      "  [[128 142 136]\n",
      "   [128 128 128]\n",
      "   [128 117 122]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 116 128]\n",
      "   [128 128 128]\n",
      "   [128 141 144]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 150 128]]]]\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_384.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_384.bias_quantized, Weights: (128,)\n",
      "[    0 -5445 -4043     0     0  5187     0 11779 -2794 -6981     0 -4991\n",
      "  5369     0 -3907  -307 -6248     0     0 -3408 -2881 -4728 24408  -883\n",
      "     0 -5140 -3353 13797     0 -1814 -5999 -4752     0   626 -1328  1139\n",
      "     0 -4650  1405     0 -6486  2119 -1412     0 -2863 -9754     0  7913\n",
      "   -65  -338 -7341  4662 -3354   718 -4970  -309     0  1009 -4681 15364\n",
      "  9358     0 -1648     0   160  -375 -3564 -3859  -481 -5940 -2295 -3895\n",
      " -2042   773  3187     0 -3982 -4874     0 -1693 -5681 -7225 -6751 -5412\n",
      " -1950 -3325 -3169 -2922 -4286 -5799 -7192     0 -5282 -1832   569     0\n",
      " -4593 -7942 -7275     0   -82     0 -2579 -6534     0     0 -6214 -4798\n",
      "     0     0  -522 -2656 -4823     0  4755  1990 -5076     0  5996  -905\n",
      " -3322 -3489 -7270 -4437     0 -4954 -2634 -3100]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_384.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_407.weight_quantized, Weights: (512, 128, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_407.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_407.bias_quantized, Weights: (512,)\n",
      "[     0    -74   -653    -68     26   -125  -1949   2673     22    -82\n",
      " -10493  -2873     14   1692   -641   -256     20   -240    516  -1258\n",
      "   -866   1258   1456   -163      0   3084  -3722     31      0      0\n",
      "      0  -1488   -890      0      0     14   -907    372    -75   1203\n",
      "     -6    729     16   1884  -2267    -91   1427   1332   1034      0\n",
      "    437     63  -2188    -14   1055    110     18  -2567    112   1295\n",
      "    708    996   -160  -2370   -115    101   -293    155  -1179    103\n",
      "   -417   1557    123   -446     40  -3341    -86   -405    604  -1658\n",
      "    613      0      0      0   1921    -70   -564   -322  -1331      3\n",
      "   1214      0   -763    944  -4120   1512  -2028    175     60      0\n",
      "   -432     62     65  -2079      0     34    549    -46    537   -687\n",
      "    -44   5303   -673    119     49   -161      0    417   -118  -1664\n",
      "  -1331     43    173  -2421   1750    628     39   -813    624  -1250\n",
      "      0      0    923   2573    791      0   1526    236  -2457    173\n",
      "     59  -1330    -15    -14    -49    452     -9   -104    499  -1794\n",
      "    286    -60  -1882     39    933    -12   6682    643   5051     -7\n",
      "   -758   -718    106   -191   1785    583    571     99    -68    -67\n",
      "  -6071   -118  -1154   -391    -29   1298    439   -394      0   -448\n",
      "   1962     32  -3261  -2260   -582    -21   1737   1214     63   4681\n",
      "   -710   1428    -44  -1951  -1473    167    -80  -1285   -205    -85\n",
      "    -27    337    242    -99   1094     -2    286     52   -902   3606\n",
      "      9    -72   1125    -27      0      0   1620    524    -52    -15\n",
      "  -2944   2169    425   1147    -31   -288     53    -16      0  -1556\n",
      "     -9      0   -374    -21     22      5    210     46     36   -205\n",
      "   -171   1517  -2225    135     -7    957   1200   -546    236      3\n",
      "    -34     24      0  -1587   1041  -1565  -3517      0     14  -8534\n",
      "    194    120    121     -1    482   1596    -36   -418   1733    499\n",
      "    -23   3236     10     42    314  -3006    121  -1953    -12  -1141\n",
      "    693    893   -497   1745    -17     15      0     26   -224     56\n",
      "   -410  -2335   -110    -85   -116    -78  -4693  -2438   1098   1920\n",
      "      0    317   1758      0   1393     95    -11    -53   2261   -295\n",
      "      0  -2100    -81   1381      0   -128   3944   1459    -19    113\n",
      "   1425    521   2535     89      0     17      0   -489    -15   -123\n",
      "      8  -3083  -2116      0   1765   -975      7    948   -821   -943\n",
      "   -482    -85    -50   -305     13     26     52      0  -1658   1936\n",
      "   -663  -6651   -227   -177    739  -1248     59   -395      0  -1577\n",
      "      0   2347      0   -887  -1966      3     62    127   -553   -307\n",
      "   -661   1359    556  -1002   -163     74      1   -519    104   3997\n",
      "    -26   -166    865   1309   2042    123    605      0     17    -75\n",
      "     24    -57      0   1652    899    -43     73  -2916      0  -1086\n",
      "    132  -1932   -668    453  -1882    594     25  -3413  -2525   -695\n",
      "  -1394   -265    -83  -1693   -314      0    212   -549      0      0\n",
      "   1923     21      0    -52   -206    878    -59   -366   1120     16\n",
      "  -1806    -68     29     -7      0    -23   -117  -1803   1139    806\n",
      "    188     60   -767    796   -153    203   -415      0   -185      6\n",
      "    -12   1434     -6    994    956    -98   -491    137     75   -440\n",
      "    -99    -20    125    435      0   -199  -2542     51    451   -236\n",
      "   2535   -365      0   1230     44    157   1524  -1114      7      0\n",
      "   -447   2507   -136  -2169  -1116    -42  -2634   1470    -37    688\n",
      "   -118  -2000      0      0   2806  -2111   1596     18  -1481   2261\n",
      "   3040   1807      0   2489  -1909     11    -59    115   -942   -899\n",
      "   1215   -178]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_407.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_431.weight_quantized, Weights: (128, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[169]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[139]]\n",
      "\n",
      "  [[105]]\n",
      "\n",
      "  [[108]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_431.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_431.bias_quantized, Weights: (128,)\n",
      "[-2170  2705  -417  -199   194  -749  1429  2414  3490  3284  -727 -3695\n",
      "   926  2411  4061  2005 -1750  3015  2800 -1480  4207  4690  3927  5384\n",
      "  2020  8753  -856 -1463  3632 -2594  6187  1721 -2298 -1094  3731  1196\n",
      "  2803  4812 -4619   195    21  2420 -2867  3414 -1516 -1523  7010 -2805\n",
      "  3114  2447 -2517  -950  1516  2916  3840   470 -3486  3803   201  1409\n",
      " -3714 -3759  -406 -4413  -340  1894  3043  4707 -1037 -1155   557  3191\n",
      "   796  -271  7376  3028  4083  3200   595  2254  -989 -5839  -911  1252\n",
      " -3670 -8439  -947  2283  3862 -9533  3477 -2487  1152   440   247  1414\n",
      " -2352  -977  1279  2182 -4206  5925  2523   547  -625  1511  -286  1554\n",
      "  2883  2327  1867  1280   505   342 -2771  2014  1397   425 -2804  4785\n",
      "  3853  2634   -33   476 -3655 -2888  -284 -4823]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_431.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_454.weight_quantized, Weights: (128, 128, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 117 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 100 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [147 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 150 128]\n",
      "   [113 156 128]\n",
      "   [128 153 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 134]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 148]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 113 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 109]\n",
      "   [128 128 106]\n",
      "   [128 128 117]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 105  84]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [110 128 128]\n",
      "   [128 141 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 116]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_454.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_454.bias_quantized, Weights: (128,)\n",
      "[  4329    240     40  -1067   7522   4806   2126  11119   1103  -5146\n",
      "   2364   7606  -2269 -10326  11227    795      0  10608  -5158   -464\n",
      "   2992   6623   6374    386  -8555   5345  -3145   2717  -1988   1203\n",
      "  -2411      1  13540    174  -4640   -386  -4076   9148  -3940   5539\n",
      "  -3127   1008    247   1872  -5772   4074   2774    265     63  15920\n",
      "  -2438 -11887  -3734  -6886   1226  -4164   2941   9156   9512   1832\n",
      "   5622  -2764  -3919   4658  15357   2913   4140   -834   1207   3027\n",
      "  -2358  -5092   2292   4785 -13144     18   2053  -2336   2199   7003\n",
      "  -4353   4140   1044  -2603   5401  -2578   2477  10833   3768   8696\n",
      "   7727   3627   6335   -748   1625  -4398  -3199  -4088   2811      0\n",
      "  -4515    391   2597   5384  -1246  -3784   -150   -816   3407  -1148\n",
      "  -3678      0  -3028   5821  -1979   4414   5398    572  -3344   5673\n",
      "  -3228  -9060  -4037   5999    685   -389  10105  -2575]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_454.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_477.weight_quantized, Weights: (512, 128, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[135]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n",
      "Features for Conv_477.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_477.bias_quantized, Weights: (512,)\n",
      "[    0  -653  -222   653  -905    21  1831  -390  -468 -1313  -520 -1018\n",
      "  -718 -1995 -1822 -3023 -2743 -1277  1736  -442 -2290 -1635  -962   -50\n",
      "  1071  -649   102    67     5     0 -1119  1313 -2161  1528     0 -1307\n",
      "  -165 -2262  -212   162  -665 -1306 -2170 -1454   151   465  -348  -471\n",
      "  1957     0  -932    20 -3053 -3331   142  -429 -3818 -2277  -385   -61\n",
      "   -65 -1459    44 -1626   302 -1535 -2854 -1343  -882  -936 -1557  -136\n",
      " -2013   259 -1844  -166 -1528  -353  -773 -1902  1868 -1065  -482     0\n",
      "  -709 -1202  -871   -44  -837  -287 -1854  -953  -133  -461   356 -1580\n",
      "   130 -1151  -722  2720 -3193  -341 -1949  -735  1231   -62 -1683  -105\n",
      "  -261  2568 -1428  3810 -2938  1055  -512  -445    53  -202 -1303     1\n",
      "  1535  -437 -1808  -794  -986  -902  2375 -1408  -280 -1608   854  -250\n",
      " -2679  -878 -2177   393 -1538   185  -816 -1706  -749  -265 -1857 -2099\n",
      "  -179 -1709 -1560   -65  -454  -643 -2027  -242 -1118 -1590 -1233  -483\n",
      " -1219 -1837 -1201 -2160   363  -462 -1195   681 -1619  -319   557 -3922\n",
      "  -761  -325   682 -1256   -20    51 -4823 -2522    65   157     0  -940\n",
      " -1240  -472  -186 -1418 -2261  -118  -672 -2312  -867   141  -701  -588\n",
      "   159 -2551    25  -687 -2630 -1921   785  -738 -2434 -2323   963 -1090\n",
      "  -592 -1533   354  -668 -3503 -6210 -2157 -2684  -451 -1917   982 -1147\n",
      "  -698   194 -1562 -1854   365  -369  -246 -1939  2465    19   700   806\n",
      "     0   226   -12  2402 -1685     7  -411 -1236 -1420  -154 -2029   -35\n",
      "  -537 -1610 -1438  1097  -140 -1620 -2102 -1406  -443  -801   338  -887\n",
      "   290  -390    56 -3154 -3359     0   287 -1058  -162    13   170  -295\n",
      " -5641  -436 -1375  -178   574   999 -1259  -628   -67 -2523  -477  1649\n",
      " -1918   -53  1109  -581 -3027  -856 -1961   140 -1218    38 -1813    31\n",
      " -1708  -210 -2697 -2257   670   132   131  -678 -1072 -1421  -862 -2480\n",
      "  1297 -1975  -431   -79 -1157  1760  1197   -17 -1711   -98  1415  -185\n",
      " -1803 -1367 -2497  -141  1338  -207 -2090 -2228   804 -1090 -1966  -328\n",
      "   948  -612  1101  -173 -3826  -412  -363   807  -542     0 -2973    59\n",
      "  -315    41 -1547 -3675  -756 -1694  -140   -42  -143  1346    31   885\n",
      " -2546  -172 -3129   -71 -1388  1511   -58 -2564  -483 -4509  -760 -4152\n",
      "     0 -1020     0 -2551    36   148 -1704   102 -1283 -3438   263 -2788\n",
      " -2593   381   721  -131  -380 -1917   426  -304    54   194  -996 -2528\n",
      "  -721 -4599   -40  3551  1284 -2124  -247   323  -168  -544 -1581   441\n",
      "   -80  -885     0   251  -537 -1198   -25  -401  -637 -1059   -38  -500\n",
      " -2741   144 -1055  -453  -316  -879 -4248     0    62  -139  -364     0\n",
      " -2526     5 -1968  -293  -660  -925   284  -279 -2177    49 -2738 -2153\n",
      " -2164 -1728  2151    34  -780   392   667 -2371  -542   250 -1854 -1489\n",
      "   305 -1642   376     0  -617  -751 -1245  -925 -1487 -2055  -653   212\n",
      "    23   -78 -1682    95 -1219    -4  -671 -2848     0 -3263 -1229  -997\n",
      "   105  -119  -925 -1167  1987 -1415 -1090  -924 -2669  -365 -2553     0\n",
      "    12   524 -1846   319    85 -1902 -1071 -2544    94 -4277 -5023 -3510\n",
      "  3460   912   314  -480  -509  -898   527 -1575 -5141 -2074   682  -532\n",
      " -1757  -311 -1090   -70   -56 -1115  -182 -1735]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_477.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_501.weight_quantized, Weights: (128, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 82]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[103]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (128, 512, 1, 1)\n",
      "Features for Conv_501.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_501.bias_quantized, Weights: (128,)\n",
      "[ -3286  -2689   -572      0  -2390   3591  -6860  -4988   1805   2247\n",
      "      0   3137   -660  -3695  -1881   1256  -1108  -1344    250  -2925\n",
      "  -1791   2597    580  -2420  -1534   1360    745   -567    789  -3713\n",
      "   3697   -906   -853   2148   1303   2361      8   -713  -3087  -1509\n",
      "    839   3675   2078   3537      0  -1506   1510    892  -2658      0\n",
      "   1431    610      0  -1981   5298   -289    133   3164      0   5041\n",
      "   3595      0   4828   3597  -4210  -2623  -2956   3849  -7893   1229\n",
      "  -4819    325   1024      0   4814   4280  -4510  -3689  -4180  -2673\n",
      "  -3808   -659  -4890      0  -3647  -4390   2506   3515  -1400 -12978\n",
      "   2215   2119  -2452   3404    295   4274     25      0  -1878      0\n",
      "  -2862  -2858  -4152   1018   2039  -1736   3484   2554  -3120  -2325\n",
      "  -1084  -1800  -3571   1271  -1564   -186   2681   -460    456   3477\n",
      "  -3685   1305   4508   -628   2207  -2616  -2302   2356]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_501.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_524.weight_quantized, Weights: (128, 128, 3, 3)\n",
      "[[[[122 128 132]\n",
      "   [128 128 128]\n",
      "   [141 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [120 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 116]\n",
      "   [128 134 128]\n",
      "   [115 128 139]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [121 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [137 128 128]\n",
      "   [128 146 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 118]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 107 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [135 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 118]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [143 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 150]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[132 136 128]\n",
      "   [133 137 128]\n",
      "   [134 134 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 137 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (128, 128, 3, 3)\n",
      "Features for Conv_524.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1152\n",
      "  nnz_max: 1152\n",
      "  nnz_avg: 1152.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1152\n",
      "  bw_max: 1152\n",
      "  bw_avg: 1152.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999991317\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.0008680555555548018\n",
      "\n",
      "\n",
      "Layer: Conv_524.bias_quantized, Weights: (128,)\n",
      "[ 3276 -6772 -2305   829   750  3144 -1635 -1288 -5470    42   176     2\n",
      "  1433  4767   358 -1297  5042  1475  -678   807 -2258  3771  2320  -585\n",
      "   702  -189 -3505   454  4482  -319 -1285  1398 -6578  3064 -2683   679\n",
      "  1512  -592  1667 -1049 -5156  -982  2889 -9459  2817  1171 -1328 -2862\n",
      " -3197  -256  1052  1884  -202  -247  -297   619  -250 -1504 -1061  -150\n",
      "  2916  -560  1719  1243   135  -347  2832   523   655 -1807  -541  -824\n",
      "    69  1434   647  4316   -50  -983  1291  3601  2034 -1652   647   766\n",
      "  -426  -790  4168   851   292    79 -2057  3569  1188 -2668 -1558  -871\n",
      "   587 -1043   907 -1200  1419 -2237   535  6551  -353  6655   545  -190\n",
      "  3053  -794 -5554  1193   196     0  3914 -2111  4400   750  3335  -927\n",
      "  -118 -2932  -477   781   925  1254 -1501 -6713]\n",
      "Calculating features for matrix with shape: (128,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (128,)\n",
      "Skipping layer Conv_524.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_547.weight_quantized, Weights: (512, 128, 1, 1)\n",
      "[[[[170]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[136]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 128, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_547.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 128\n",
      "  nnz_max: 128\n",
      "  nnz_avg: 128.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 128\n",
      "  bw_max: 128\n",
      "  bw_avg: 128.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999921876\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0078124999999389655\n",
      "\n",
      "\n",
      "Layer: Conv_547.bias_quantized, Weights: (512,)\n",
      "[ -160  -156   531 -2727 -1106  -451    32     4  -310   423   -20   584\n",
      "  -468 -2707  -329  -416  -504  -980  -562    -3   344   -56   -90   681\n",
      "  2113  -614   -25   -37   -60 -1180   -95    76  -244  -130  -393  1152\n",
      "  -894     5    -2    -8  -340     2  1345   -68  -300   534     2    24\n",
      "   761   542  -133   394 -1298 -3697  -103 -1322   -71  -751    85 -4285\n",
      "  -485     3   571  -232  -592   -31    70   183    81  -676    14     0\n",
      "  -151   -41   -37  -136  1152   -79   -80    29  1191 -1511  -492   969\n",
      "    77  -579    73    29  -144  -906  -240  2562     3  -251    -3  -368\n",
      "    50   -22  -921 -1167  -907    28   507  -263    46    25    18  -153\n",
      "    60   317  -125  -972  -810   551  -663  -324  -444     6  1099  -106\n",
      "    29  -261    40    26  -730   -48  -649 -1285 -1605    72   297 -2539\n",
      " -2731  -117 -1058   -81  -713  1627  -301    -2   -31  -145  -971   231\n",
      "   -45  -106   763   -23  -394  -145  -312   212     6    -6   904  -538\n",
      "  -947  -468    17  -989    25     1    -7   -61     0   626     1   -65\n",
      "     2   277 -1471   292   207   -39 -2175     3    96  -402  3123    34\n",
      "    11  -236    -6     4   119   165     1 -3369    -1    10   -79  -935\n",
      "   -15    39    36  -462  -178  -418  -437  -489  -507    -1  1044  2264\n",
      " -1530    24  1393   145  -164 -1152 -1118    81    28  2075  1788 -1758\n",
      "  -119  -916   140    -4    53     3  -500  -637  -370  -614  -228 -1176\n",
      "  2360    26    -6  -764  -305  -489  -578   525    -3  -534  -681    86\n",
      " -1859  -366  -353  2260  -635   -70     4     0  -550 -1102 -1462  -106\n",
      " -3825   -13     1 -2229 -1798  2601    10 -1311   138   469   245 -2630\n",
      "  -720  -228    14  -733 -1025     0   402     0  -636  -246   -77 -2101\n",
      "    -1   132  -466   140 -1531 -1106   635    29     3  -343   686    82\n",
      "   -54  -256  -155    -2   230   208  -768  -330  -518  -114     6   -44\n",
      "  -499  -514    -1 -1342   -31  -110  -575   260   188     2 -1201     2\n",
      "  -197   -28    74  2083 -1027 -1846    49   214  -336   -14     1     3\n",
      "  1475   171   928   -48 -2358   584 -1663   477    -3   518 -1145   -44\n",
      "    -1    23  -271  -380     1  -635   681 -1367    29 -1863   589  1452\n",
      "  -635  -139  -357   900  -396    87  -339 -1044  -230  1725  3928 -1666\n",
      "  2268   286 -3092  -162  -144   471  -367 -1626  -778  -390    99  -620\n",
      "  -118  -995 -4559   -63   -72  -823 -1061    -5    37  -971   -69   -89\n",
      "     3  -655  -584    68   122 -1154  -209   176   401  -179   -54  -374\n",
      "   -29  -585   240   -13 -1208    12  -810    28  -376     4    90  -266\n",
      "  -401  -193  -520   -46   729  -672   -39  1589  -566   -18   825   515\n",
      "   -53    -4 -2465   474  1437  -847  -511   105  -131    30  -158  -311\n",
      "   -25 -1836  -265 -1164   303     1  -375  -101     2   304   -80  -634\n",
      "   336    77   175   828   530    16    -2    36  -116  -300     1   970\n",
      "  -132   682  -840 -1418  -640 -1066  -543   -46   375  -393    25   -89\n",
      "  -423  -224     7    18  -570   -95  -145  -927  -237  -154   -19 -2713\n",
      "  -107     0  -196    -6   339  -618    -4     3  2398  -921  -384  -675\n",
      "  2861  -787 -1921  -563  -980  -302   394  1123   -70     4  -386     3\n",
      "  -380   269 -2203     1   -38   -78  -151   275]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_547.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_571.weight_quantized, Weights: (256, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[108]]\n",
      "\n",
      "  [[112]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[138]]\n",
      "\n",
      "  [[149]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[143]]]\n",
      "\n",
      "\n",
      " [[[114]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[165]]\n",
      "\n",
      "  [[150]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[133]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[156]]\n",
      "\n",
      "  [[106]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[ 96]]]]\n",
      "Calculating features for matrix with shape: (256, 512, 1, 1)\n",
      "Features for Conv_571.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_571.bias_quantized, Weights: (256,)\n",
      "[ -724  4196   315  2021   951  -492  1420 -1857 -1434   451  -122 -1894\n",
      "   -23  1825 -2865  -953 -2893 -1357  1271 -2008  2678  -539 -2817  1085\n",
      "  -221  3003   -41  2973  3500  2602  -370  -587   932 -2312  1208 -1632\n",
      " -1682 -4339 -2337   574  -844  2721  1588 -2042   -91  1141 -2373 -2136\n",
      " -5245  -699  1269  -291  -338  3500   -41 -4755   -21 -1478 -2899 -4276\n",
      "   652  3979   620  2197  1492  -211  -228  -481  -286  3544   393   391\n",
      "  1431   272 -3652   445 -2422  1008  -368  1417 -1846   291 -2168 -1325\n",
      "  1286  -282 -3866  -937 -1198 -7934 -3275 -1318  1051 -1721  -782   375\n",
      "   306 -2369 -4135 -2170 -2310 -3499 -3431  -968 -2623 -1336  -280    70\n",
      " -1973  1940 -3707  1960  -238  -943  -442  2744 -2009 -1026  3368  -552\n",
      "  -260  1977 -2347 -5084  2300  2071  -875  1182 -2255  3944   230  3072\n",
      " -3367 -2420 -2303   -98  2026  3384  -462 -2738  1451 -1747  1992   642\n",
      "   727   218  2559   930   679  -864 -4445  -331  5864   554   543 -2949\n",
      "  5526  1208 -4242 -1302   148 -5773  2484   663  2850 -1160  2401 -3044\n",
      " -1994 -3929 -2984 -1881 -2169  -392  2201  -151  1214 -2079  1507  -536\n",
      " -5434 -2792  4578   863  1706  -487 -1383 -3086  -106  -375 -1527 -1433\n",
      " -1296  -293  3919 -4630  1723   130  -175   278  2160 -1737  3318   287\n",
      " -3476   804  -145  2122 -4205 -2473  -367  3258 -4607    29  1477  -621\n",
      " -4258   221 -3142   108 -3717   740   149   495  2705  1842   343 -2570\n",
      "  1984  1995  3688  -976  2074  -367 -2192 -2377 -5764  2136 -3164    93\n",
      "  -268 -1185  1717 -1388 -1264 -2685  -782  -863  1684   564 -4229  4004\n",
      " -2643  3277  3804  -326]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_571.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_594.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[145 151 144]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 137 143]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [175 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 116 122]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 142]\n",
      "   [128 128 138]\n",
      "   [128 133 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [124 121 122]\n",
      "   [117 111 112]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 132]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 136]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 113 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 133 132]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_594.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_594.bias_quantized, Weights: (256,)\n",
      "[-2008  -970  3422   231  2858 -1612  3452  2784  -825  1680  -669  3679\n",
      "  2359   474  1274 -1810  2731  3964  1502  2671  3207 -1177  3297  3228\n",
      " -1697  3580   697   572  2767  1333  3249  3888  1753    13  -258   726\n",
      " -2671  2014   422  1360 -3292  -223 -1073 -1144 -1663   197    75  3175\n",
      "  -228  -100 -3674  2804  2792  1731 -1057 -2386  -368  2801  1383  -506\n",
      "  -713  2884  2118  2783   624  3136  -147  2692   958  1074 -1509  2279\n",
      " -1545  2762  1436   474   673   568   204   520  -153    75   308  1158\n",
      "  3491  3449 -3362 -1436 -3259    28   262   258  2262 -1019  1337  2794\n",
      "  1149   682  1115  5733  3891   409  1226 -1546  -151  2046 -1529  3355\n",
      "  -656 -3102  4113  3117  3409  4005  1553  -877  1849  -599   869  2733\n",
      " -1967  -444  1173   249  4690  1360  1963  2775   -43   434  -609  2356\n",
      " -1032  1264  2317  1050  1033  2782  -429   761 -2472  3239   342  3986\n",
      "  -259  -382 -2051  3805  1862   211  2134  2569  2871  -588 -3042   537\n",
      "  2570 -2399  -338  -364 -1369  2467   387  2349  1716  1771 -1409 -2321\n",
      "   948  -903 -1796  1977  1570   574  4852  2920   789  1551 -1399  4213\n",
      "  -465   936  1385  -281   352   -60   894   343  2877   -30  2867  4430\n",
      " -1161  4341 -1032 -1792   691 -1129  -997    -5  5731   595  4777  4327\n",
      "  3083 -1176 -3193  2963  5248 -1768  1357 -1822  1847  1706   352 -1726\n",
      "  -374   959  -823  1880 -2467  1573   443  3386  -795  2017  -542  -756\n",
      "  -338  3978  1824  1843  -464   482 -1460   300  -285  -478  -636  1149\n",
      "  2288  4235 -2945  3846   -40  2132  4528  -826  3672   359  1861   -84\n",
      "  1504  5591 -2322   396]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_594.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_617.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[138]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[144]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_617.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_617.bias_quantized, Weights: (1024,)\n",
      "[ -619 -1549   266 ...  -600     0 -1085]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_617.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_639.weight_quantized, Weights: (1024, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 512, 1, 1)\n",
      "Features for Conv_639.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_639.bias_quantized, Weights: (1024,)\n",
      "[-2093  -438  1142 ... -1333     0   604]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_639.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_663.weight_quantized, Weights: (256, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 84]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[109]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_663.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_663.bias_quantized, Weights: (256,)\n",
      "[    0  2267     0     0     0     0  -773     0 -5066   328     0     0\n",
      "   897     0     0 -2584  -223  2972     0  2393     0     0     0     0\n",
      "     0 -1360     0 -1501     0  2749  3675     0     0 -2671     0  -285\n",
      "     0  2914     0  1125     0  3454     0 -3751 -2327     0  3648  2620\n",
      "  1671  1942     0 -2860     0 -2011 -4977 -1944 -1681     0 -4293 -3263\n",
      "     0   786     0  2950     0 -4058   769     0     0     0 -4458     0\n",
      "     0 -2071  4643     0  4699 -3796     0   517 -1502  4483 -1751     0\n",
      " -3437     0     0     0  1529  3345     0     0     0     0     0  4067\n",
      "  1032     0  2851     0     0     0  1485  1112 -2850 -3720  1965 -1600\n",
      "     0  3696 -1223 -1607     0     0 -2078     0   380     0   971     0\n",
      "     0     0 -2587  -441  2581     0     0     0     0     0   480    71\n",
      "     0  -399     0     0 -6071 -3361     0   779     0 -1401     0 -3472\n",
      "  2229  2139     0     0     0     0 -5577     0  1357     0 -5403    62\n",
      "   779     0  1097  2899     0     0     0     0     0 -3314 -3834     0\n",
      "     0     0     0     0  -656   887     0 -1614  -721  2584     0     0\n",
      "  -817     0  2776     0   -95     0     0     0     0     0 -3383  2714\n",
      "     0 -1181     0     0  3071 -2697     0   821     0     0 -1524     0\n",
      "     0     0     0  1565     0     0 10154  2228  3161  1715     0 -3146\n",
      " -3479  2515     0 -3077  -829 -8000 -2848     0  2738     0     0 -3007\n",
      "  -144 -3626  1784     0     0 -3320     0     0 -4433 -1067 -2200 -3272\n",
      " -3856 17335     0     0 -3688  3106 -3019 -2803 -1783     0     0     0\n",
      " -3632     0 -3125     0]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_663.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_686.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_686.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_686.bias_quantized, Weights: (256,)\n",
      "[  -312      0  -1641   1840  -1080  -2160  -1151   -855  -3442   -257\n",
      "      0   5130  -1911   -664   1054   4368  -3003   2561    -25  -3931\n",
      "    632   -312  -3642  -6078   1149   -163      0  -1471  -3486    -59\n",
      "   -922      0      0  -3361      0   3131    487      0  -1341  -2006\n",
      "    705   -245  -3528  -2134   -540  -1107  -1809  -7127      0  -6552\n",
      "  -1511  -1146      0      0  -4429   2837  -1579      0   1702  -4743\n",
      "  -3194   4390  -2617      0   8221    822  -3525  -3273      0  -4404\n",
      "  -2445  -2777   3600  -1674    282      0      0  -2159    -28      0\n",
      "      0     42  -1752  -5911   -650    109   -989  -1268 -10549      0\n",
      "      0  -1130      0   -278      0  -3418      0  -1173  -2251  -1155\n",
      "  -1404    231  -1176  -4451   -264      0  -1007      0      0  -3408\n",
      "   1656  -3388  -4066   4529   1041   1496   2950  -2995   3575   2330\n",
      "      0  -3396   -348   -129   -920      0    745  -2148      0  -3717\n",
      "    722   -736      0  -2610  -1674     33  -1961      0    943   9489\n",
      "  -3088 -10410  -7615   -187   -331  12360  15830      0      0      0\n",
      "  -5103  -3321   2514     -2  -3270  -1237   2747      0   -415      0\n",
      "      0      0  -1468  -3033   5417  -2236  -1698  -1241   1109      0\n",
      "  -1701  -3811  -4611  -1302  -2011    905    -81      0   -836      0\n",
      "  -1266  -1374      0  -5459  -1814   3805  -2201  -1970   6088  26231\n",
      "  -7949  10600  -1644  -1717    -29      0  -1578   -957   1074  -3269\n",
      "  -4077      0  -1720      0  -1229      0   -288   6158      0   1692\n",
      "      0  -7761   -453  -3223      0  -1930  -9016  -2909   7287   1129\n",
      "  -2074  -3097  -1263  -2260    509   -894  -4610 -10766      0   -208\n",
      " -10362     49  -1520   -849  -3553      0      0     85   2789   -506\n",
      "      0  -2903  -3393  -2883  -3261    730   3707      0  -4902    219\n",
      "  -7998  -3459   -414      0   -225   8786]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_686.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_709.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[106]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[141]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[135]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_709.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_709.bias_quantized, Weights: (1024,)\n",
      "[-1241  -608   701 ...   433  2335  -627]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_709.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_733.weight_quantized, Weights: (256, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[118]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[139]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_733.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_733.bias_quantized, Weights: (256,)\n",
      "[-1977   402   434     0     0 -4102   -22     0     0     0 -2807     0\n",
      "     0     0 -4326     0   523     0     0  -562     0 -1279  -342 -1660\n",
      " -2286 -1302  6147 -2344     0  3618  1973  1688  1241  1563     0  1149\n",
      "     0   -39   575 -1647 -1662  -354 -2372 -2322     0 -1360 -1831     0\n",
      "     0 -2519   250 -4349     0 -2209 -1430 -1076   607 -1636 -1268  1729\n",
      "     0  -664     0     0     0  2943     0   721 -3088     0     0 -1750\n",
      "     0   488 -2860  -588   763  1068  2811  -647     0   355  2359 -1513\n",
      "     0  2283     0     0 -4152    34 -4983     0     0   179 -1223   582\n",
      "  2250  2745   577  -850 -3356     0     0 -1558 -1017 -3180  -704 -4861\n",
      "     0     0   902     0 -3717     0  1681 -5298 -3899 -1898 -1603 -1990\n",
      "   576     0     0 -1892  3379 -5832 -3592   145     0 -3837  -855 -1147\n",
      "     0  -671   887  -100  -119     0 -1801 -3257 -1937     0 -1427 -2434\n",
      "     0  1501  -693 -4524   -17 -2692 -3890     0 -1518     0  2131     0\n",
      "  1592   249   334    -1 -1006  -131 -2215   331 -3078   516  6282     0\n",
      "   296  2443 -3256 -1713     0     0 -1466 -1059 -1927 -2918  1173     0\n",
      "     0 -3049   986     0     0 -1065   457     0  -596  1621 -2492 -2570\n",
      "     0     0  1663     0 -1326 -1093 -3010 -1690     0   873  1684     0\n",
      "     0 -1804     0   292  -589 -1576     0  2641 -2221 -3197     0   218\n",
      "     0  -789  -570  1416 -2854 -2138 -2026     0 -1489   106     0 -1645\n",
      "  1069 -2513   -16  1341  -252 -2719 -4929     0 -1376    38     0     0\n",
      " -1391 -1050  1389  1303   303     0 -1410 -1133  1438 -3227 -1476  1858\n",
      "  4147  -446 -1351 -3606]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_733.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_756.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 148]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 126]\n",
      "   [128 132 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [134 128 135]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_756.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_756.bias_quantized, Weights: (256,)\n",
      "[ -3275      0   -169     52   -617 -10049   -908    170  -3730      0\n",
      "  -3806   2510   -180   2157      0  -6625  -2257  -1866    -63   5865\n",
      "  -1331      0    595   -966      0      0  -1912  -2138  -8078  -2139\n",
      "  -2382  -4832   -153      0    457  -3461      0   -116   1782      0\n",
      "  -2551      0   2119      0  -4918   2031  -2618   -737      0    695\n",
      "  -2541    193  -3071  -2972  -4573  -3950  -1850   -404  -4417   -668\n",
      "   -233  -2727  -3830   -280    328   3254      0   -188  -3311      0\n",
      "      0    513      0   3956   -920  -2747   -873    595   -460  -1079\n",
      "   -790  -2939   2781   2454   2080  -3056    157   -467   7361  -3219\n",
      "  -5941    153  -1809   -646  -3162  -3848  -2943  -3617  -1414  -2232\n",
      "  -6498    466   5321     11   4033      0    201      0   6085  -6817\n",
      "  -2438      0  -5906   -957   -588  -1550    758      0   -220  -2062\n",
      "  -3210   2595   7736  -3232   7325  -4083  -2205  -2407  -6771   -590\n",
      "  -4615   3884 -11936   2277  -5712   1655      0      0   3978      0\n",
      "  -5618  -3082      0  -1241  -1022  -1539  -3491    145    322   4385\n",
      "  -2519      0      0  15369  -1855  -3335  -2472      0  -1560    928\n",
      "   -265      0  -5474    800   5667   7252    457      0      0  -2886\n",
      "   -105  -2941   -249   -733  -2208  -2312  -1838      0      0   -734\n",
      "      0    365  -2981  -1944      0   -825  -1868   3314  -4093    122\n",
      "      0  -1231      0   1376      0   -509  -4473  -3815   3339  -1293\n",
      "   -243      0  -1723   1445   1204    632      0  -2917   -942   -285\n",
      "     53  -1382   -544   -508   1336   -401  -5303   -364   6225  -3448\n",
      "    635   -423  -1927    153  -2547      4      0   4818  -2525   1373\n",
      "   7250   4510    469      0      0  -2511   -832  -1107   4229    902\n",
      "   3574  -6062      0   2690      0   6184  -5824  -1844      0  -1834\n",
      "  -2225  -4583   -704      0   8517      0]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_756.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_779.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[140]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[117]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[115]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[134]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_779.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_779.bias_quantized, Weights: (1024,)\n",
      "[ -727  -467 -1159 ...  -837  -559  -177]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_779.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_803.weight_quantized, Weights: (256, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[130]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[110]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[125]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_803.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_803.bias_quantized, Weights: (256,)\n",
      "[ 1623  -583  2936     0  1718 -6357  -738     0     0 -2604 -2208  -466\n",
      "  -411     0     0 -3047 -1434     0     0 -3008 -1104     0     0 -3650\n",
      " -1280     0 -2164  -538     0  -992  -616   481     0 -1666  -981  3591\n",
      "     0 -2025 -2107 -1868     0     0 -2784     0     0     0     0 -2083\n",
      "     0     0     0     0  -469     0     0     0 -1050 -1518 -4174  -846\n",
      "  -378 -1220 -1004     0   520    -2 -2278 -1312  1376  1190  1345     0\n",
      "   857     0 -3957     0     0  1778     0 -1641   774     0     0     0\n",
      "   867     0     0 -3481     0   420     0     0  -391 -6206     0   329\n",
      "   954 -3983     0   583  -865 -1247     0 -3952     0     0 -1521    73\n",
      "     0     0   -16     0     0 -3751 -2232     0  2894   112 -3664 -2386\n",
      " -2169 -1356 -1240   733  -540 -3161     0 -2377 -1080  -295  1689 -4333\n",
      "   901  -115     0  1145   884     0 -1370   175  -754 -1828 -2310     0\n",
      "     0   769     0   390     0     0 -1295  2068     0 -5824     0 -3492\n",
      " -2346 -3780     0 -2438 -1653     0     0  2786     0   442 -3562  2900\n",
      " -1811  -211 -4588     0  -979  1388   455  2136     0  -441     0 -1198\n",
      "     0   557     0  2183     0  1597  1026     0 -6455   640  3975  1490\n",
      " -4937     0  1191     0    18  3156  -686 -6871     0  -231     0  1117\n",
      " -4545     0  1687     0     0  -926     0     0  1664 -1345 -1118     0\n",
      " -3075  2126     0 -1977 -1264  1343     0     0  -265  2559  2588 -1165\n",
      "  1500 -1686 -1480     0     0   567     0  2596 -3883   200  -904 -2745\n",
      "     0   333   585     0 -3043     0 -2604  2487   751 -2634 -1215  -245\n",
      " -1153   939  1470     0]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_803.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_826.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[104 128 173]\n",
      "   [104 128 146]\n",
      "   [ 88  86 128]]\n",
      "\n",
      "  [[128 128 151]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 110 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 120]\n",
      "   [128 128 128]\n",
      "   [128  97 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [141 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[107 128 111]\n",
      "   [128 128 128]\n",
      "   [128 150 164]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 106 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_826.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_826.bias_quantized, Weights: (256,)\n",
      "[ -3907  -3824   -973   2236   -204      0   4791  -8509  -6147      0\n",
      "      0      0   2084  -8670   -454   3618  -1171      0      0      0\n",
      "  -2290      0    459  -2495      0      0    413   1327    668    959\n",
      "  -5270   2234  -2366      0  -3043  -2413    303  -1424  -3295   3290\n",
      "  -1118      0   4390      0  -1568  -8348    841      0   2045      0\n",
      "  -4745  -5384   -994   2193      0   6864   4976  -2649   2661  -2865\n",
      "   1620   7244      0   -567  -2783  -8214   -110  -4483      0      0\n",
      "   2210      0  -1822      0  -3001    270   1627      0  -5752  -2630\n",
      "  -5216  -4764  -1999      0  -2340  -5122    158  -1356      0  -2003\n",
      "      0 -10600  -2665   1012   3671      0   1059     67  -3929   2689\n",
      "      0   3339      0   2696    148    -47      0      0   4236      0\n",
      "  -9159      0  -3674  -2475      0      0    161  -1613  -1052     33\n",
      "  -1034   -288      0   -148   3375  -1490  -3818  -2805   1246  -6610\n",
      "     39  -3094  -2048  -1667      0   1329     12      0   2184   -746\n",
      "  -2057   3740      0  -2740   -215      0      0   -116   4309    771\n",
      "      0      0  -3507  -1957   7220      0  -6196   -869   -177   1412\n",
      "    672  -4480      0    246      0   4552  -1395   -447      0   1487\n",
      "   3129   2323   -486      0  -2316   2600  -3726  -2434  -3544  -1135\n",
      "   -878      0    932   5525  -6054      0  -1428   -415      0  -7605\n",
      "   -180    863  -5716      0    825  -1641      0   -231    -94   1423\n",
      "  -1748    956  -2155   -406   4547  -2514   -859   1132  -3194   2500\n",
      "   -478     84  -2267   4484      0   2041  -2558    312   6876  -1372\n",
      "      0      0  -7021      0    502  -4804   2525   2125  -1020      0\n",
      "   -942   2703    237   2152   -766   3829      0    695  -2564      0\n",
      "   -262    265      0  -8112    204   -346  -1428   4572      0      0\n",
      "      0   -129      0    246  -2784  -1453]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_826.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_849.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[111]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[112]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_849.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_849.bias_quantized, Weights: (1024,)\n",
      "[-1124 -1032   -14 ... -1939   424    58]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_849.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_873.weight_quantized, Weights: (256, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[151]]\n",
      "\n",
      "  [[123]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[140]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_873.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_873.bias_quantized, Weights: (256,)\n",
      "[    0 -2699 -1020     0     0  1080 -3317     0 -1886     0 -3968  -947\n",
      "     0 -1558     0     0     0   -90  1893 -1314     0 -1286 -3360     0\n",
      "     0     0 -1944  -546  1864  1417  -917 -3085     0  -804     0  -260\n",
      " -1959  -828 -1093   -70     0 -1135  -447     0 -3684 -1810 -1110 -1645\n",
      "     0     0     0     0     0  1747     0     0  -882     0 -1577  -250\n",
      "  1430     0 -1243     0 -1115     0 -2024  -645  -175     0 -1179   -35\n",
      "     0     0 -1150  -710     0     0  -252    40   479     0 -1485     0\n",
      "     0     0     0 -2493     0  2662     0 -1924     0    63     0     0\n",
      " -1475     0     0     0     0     0 -3457     0  -273 -4573     0     0\n",
      "   864  -938     0  2109  2291  -540 -1703    -8  -807  -589     0     0\n",
      "   118   833  1072  -706  -600 -4169 -1957  -766     0 -1417   643     0\n",
      "  -291 -2524 -1646  2025  1120     0   137     0     0     0  -365     0\n",
      "  -140  1873 -1938   -27     0     0     0     0 -2516 -1061     0     0\n",
      "  1916  1027 -2540 -1701 -2995 -2382  -716 -1926     0 -4661  -769 -2460\n",
      "     0 -1281     0 -1069  -794 -1607     0  -498     0  -891 -1695 -3073\n",
      "     0  -678     0  1925     0     0   375  -501  -591  -368  -235 -4047\n",
      "  -226 -3147  -306  -817  -821    41   651  -295     0  -156 -1937     0\n",
      " -1424     0  -944   682  1033 -3554  -977     0 -1370     0 -2343     0\n",
      "    99 -1863  -219  1478     0     0  -577     0   -44  -979  -407     0\n",
      " -1844     0   154  -643     0     0  -151     0    52   916     0     0\n",
      "     0 -1225     0     0     0   341 -3307     0     0     0   274  -395\n",
      "  -321     0     0     0]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_873.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_896.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 142 145]\n",
      "   [128 128 128]\n",
      "   [128 128 112]]\n",
      "\n",
      "  [[128 128 116]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 162 148]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128  94]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[117 128 128]\n",
      "   [128 128 113]\n",
      "   [128 128 112]]\n",
      "\n",
      "  [[113 128 128]\n",
      "   [128 128 137]\n",
      "   [117 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_896.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_896.bias_quantized, Weights: (256,)\n",
      "[  -78   184   814     0 -6360   996     0     0     0     0     0     0\n",
      "   530     0     0   469  -356 -1273     0  -840     0     0  -997 -1103\n",
      "   709     0     0 -1347 -1501  2702     0  -132  -811 -4289     0 -1634\n",
      "  1299  -781 -3255     0  2663   853 -3153  -141 -1338  1245  -285     0\n",
      "     0 -7787 -2073     0  2488 -3076   -48   627  -491 -3181     0 -1385\n",
      " -1009 -5773     0   103     0 -5758     0  2236  2710     0 -1785     0\n",
      "   596 -1859  4358 -1064  3659   666 -1249     0   184  -338     0  -422\n",
      "     0 -2243   -95  2090 -2096  2531     0   369  1151 -2237  1498   375\n",
      "   328 -2156  1483     0     0   998 -2054     0     0 -1755     0  -735\n",
      "  4447    12     0 -2657  -371     0  4651     0  -423  -330  3569     0\n",
      " -2829  -366 -2896     0  1674     0  1803 -2419  2230     0 -2837 -6761\n",
      "     0   -95 -2115  1264  -224     0 -3364     0  -135     0   866     0\n",
      "   170 -1049 -1891  1005     0 -1602    40     0 -1050 -1304  1784 -2130\n",
      " -2718  1787     0   228  -194  1003  -628  1276 -1396  -318 -3501   -16\n",
      "  3028  3535   436   371     0  -875  1398 -1426   418     0 -1461 -4761\n",
      " -1217 -2288   -47     0  3424  -811 -1388   838     0     0     0     0\n",
      "     0     0  3196   547     0     0 -3063  -271  3516     0  -379     0\n",
      "  1068     0 -1040 -1203  3355 -2258  4685 -2658     0  3146     0     0\n",
      "  -231  1936   -65     0 -1557 -2153  2944 -1123     0  -992  -276     0\n",
      "  5925  -979     0     0     0  -572     0 -1730     0     0 -1078 -4169\n",
      "  1082     0 -1568     0   132     0  3868 -2811     0   194  -502 -2042\n",
      "  1368   885  2100  5422]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_896.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_919.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[118]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_919.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_919.bias_quantized, Weights: (1024,)\n",
      "[-1736   -90  -522 ...  -274  -788   -12]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_919.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_943.weight_quantized, Weights: (256, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (256, 1024, 1, 1)\n",
      "Features for Conv_943.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_943.bias_quantized, Weights: (256,)\n",
      "[-2821 -1184     0 -1112 -1215 -1287   272     0  1230  1875 -1535  -857\n",
      "   208     0  1126   726  -469  1513 -1714     0     0 -1768 -2223 -2188\n",
      "    24 -2169     0 -1920  1203     0     0     0  -577     0     0 -5262\n",
      "     0     0     0  -147 -2097     0 -1865  -330 -1570     0 -1992  3000\n",
      "     0 -2560 -2430     0     0     0 -1724 -1726     0   714     0  -248\n",
      "  -880  -952     0 -2401  2781     0 -3527  1556     0 -1152     0 -2350\n",
      "  1541 -1227 -1863  -885     0  -933     0  -922 -2875  -720     0  -104\n",
      "   673 -1839   239 -1321  -974     0   291 -1900     0     0     0     0\n",
      " -2310  3762     0  -672 -4890     0     0   437 -2072 -1546     0   236\n",
      "  -613 -1111     0     0 -2701 -2946 -1517     0     0  -608     0  -847\n",
      "     0     0  -645     0  -296     0     0 -1490 -1644   196     0   386\n",
      "     0  -733 -2661  1208 -1183     0   450 -2307 -2018     0     0 -1198\n",
      "  -635  -389  -271   629     0     0     0     0  -338     0     0 -4012\n",
      " -2032  -535 -1514     0  -161     0  1867  1214     0  -482     0     0\n",
      "     0   179     0     0  -819     0     0 -1556 -3185   180  1129     0\n",
      "  1874     0     0     0  -236 -1549 -2173 -1628     0     0     0     0\n",
      "  -802 -2671 -2238     0   651  -476 -1488     0     0  -254 -2396 -1006\n",
      " -1246 -1601  -233  1250 -1386     0     0  -289  -931     0 -1457 -1377\n",
      "     0     0  1929 -2037  -719 -2877   445   213     0   576   844  -353\n",
      "   535     0     0   285  -387   718 -1659    76     0   238     0     0\n",
      "     0 -1232  -403   272 -1179  -526 -5243 -1456  1269     0     0     0\n",
      "   210     0 -1889 -3983]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_943.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_966.weight_quantized, Weights: (256, 256, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[121 128 128]\n",
      "   [118 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 148 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [144 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (256, 256, 3, 3)\n",
      "Features for Conv_966.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2304\n",
      "  nnz_max: 2304\n",
      "  nnz_avg: 2304.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2304\n",
      "  bw_max: 2304\n",
      "  bw_avg: 2304.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995662\n",
      "  scatter_sd: 2.220446049250313e-16\n",
      "  clustering_avg: 0.00043402777777758954\n",
      "\n",
      "\n",
      "Layer: Conv_966.bias_quantized, Weights: (256,)\n",
      "[    0     0 -3619     0 -1040     0     0 -2499  -184     0  -901   574\n",
      " -1883     0   230     0     0 -3108     0 -1208  1179  2443  2426     0\n",
      "  2470 -1246  -533 -1113     0     0 -2847     0 -1318 -2203   598     0\n",
      "  -616 -1631   -20     0     0  -771     0     0   787     0 -1827     0\n",
      "   330     0     0     0 -6523 -1331 -1001 -5680     0     0     0   541\n",
      "     0     0  -955 -1302 -1241     0     0   582   -27  1629 -2442 -1010\n",
      "     0     0     0  3651  1076   864  -532     0     0   678   456 -1889\n",
      "     0     0  4537     0 -5900  3240  1260 -2282     0     0     0   355\n",
      " -1278   -97  1668  -676     0 -1074 -1288 -1079     0  -585     0  -144\n",
      "     0     0     0     0  -930     0     0  1774  -319     0     0     0\n",
      "  -219     0  2315     0  -421     0   274     0     0 -3421     0  1701\n",
      " -2919     0 -1064     0  -916  -880 -5429   342   191     0  -942 -1501\n",
      "  -580 -1148     0     0     0  -556     0     0     0  2059  2093   259\n",
      "     0 -4406  2225     0   -74 -1480     0 -1146     0  1083     0     0\n",
      "     0  -493  -129   562  3209  1037  4491 -1723     0   332  -794     0\n",
      " -1053 -4047     0     0  1147 -1318  -870  2683  2848     0  -634  2003\n",
      "  -398  -689  1493  -804   960  -788 -1634 -1242     0 -1029     0     0\n",
      " -1269     0 -1982  1784  2624   111  2404 -1251  1067  -258 -1327     0\n",
      "     0 -1064     0     0  -226  3188     0  -928     0 -2981 -2501  1386\n",
      " -3101 -1917  -923   976     0  1863     0   548     0  2904     0 -2730\n",
      "     0 -1342     0  -901   425  2133   562     0     0   199   852   817\n",
      " -1367  -903     0     0]\n",
      "Calculating features for matrix with shape: (256,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (256,)\n",
      "Skipping layer Conv_966.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_989.weight_quantized, Weights: (1024, 256, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (1024, 256, 1, 1)\n",
      "Features for Conv_989.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 256\n",
      "  nnz_max: 256\n",
      "  nnz_avg: 256.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 256\n",
      "  bw_max: 256\n",
      "  bw_avg: 256.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999960938\n",
      "  scatter_sd: 0.0\n",
      "  clustering_avg: 0.0039062499999847414\n",
      "\n",
      "\n",
      "Layer: Conv_989.bias_quantized, Weights: (1024,)\n",
      "[-148 -582 -349 ...   42  244  131]\n",
      "Calculating features for matrix with shape: (1024,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (1024,)\n",
      "Skipping layer Conv_989.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1013.weight_quantized, Weights: (512, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[119]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[116]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[145]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[124]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 1024, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1013.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_1013.bias_quantized, Weights: (512,)\n",
      "[  876 -1204   788 -4608  -438   208  -430  1448 -3987 -1064 -1946     0\n",
      "     0 -1555   508   122   -79   547 -1191 -1824   360  -738  1157  -350\n",
      " -2957  -673  -315 -1861 -1074  -769     0   -60  -195 -1872  -508 -1321\n",
      " -1868  -899  -385 -2042 -2275   706  -195   134     0  -577 -1439   601\n",
      " -5189  -434 -1193 -1991  -494 -2779 -1773   375 -2548    10  -584  -901\n",
      "   137 -2997  -785  -699   711  -708 -1501  1250   816 -1203     0   481\n",
      "   503  -469 -1709 -2496   867 -1565 -2951 -1940 -1086  -115  -343 -1522\n",
      "  -951  -562   620  -312 -1717 -1275 -1688   301 -1960  -420   194   -38\n",
      " -1291  1132 -2778   739 -1473   680  1512  -614 -1410  -308   616   686\n",
      "    94  -153 -1346  -722  -325  -137  1558   275    21   512     0 -1136\n",
      "     0   -86 -3897  -422   967 -3049   734 -1031 -1519  -105 -1427   -28\n",
      " -1753   357 -1861  -477   328 -1182 -1118   -95 -2460  -859   446   406\n",
      " -1136 -1696  -866  -332 -1320 -3529   744 -1483  -226   985     0   101\n",
      " -2174  -384   992 -1396  -833 -1123 -3767 -3529  -454  -539     0 -1443\n",
      "     0 -1326 -1469 -1581   593  -895 -1818 -1421 -2312 -1786   300   629\n",
      "   -97   161  -558  -656  -783 -1991  -341 -1047 -1941   562 -1693 -1573\n",
      "  -377  -545     0  -229  -702    40 -1212     0     0  -319   185   322\n",
      "  -948 -1731 -1209  -411  -201 -1228  -519   932   583 -1153 -1041   -26\n",
      "  -126 -3102  -917  -526   509   487  1111  -361  -972  -878  -728   480\n",
      " -1165   237  -252  -480  -467 -1073 -1108   966   317     0  -303  1327\n",
      "   -77 -1990 -1024 -2151  -200  -638 -2296     0   232  -508  -726  -613\n",
      "  -670 -1193  -933   701   -51  -690     0  -259 -1709  1540  2252  -281\n",
      "  1726   102  -750 -3432  -356  -229 -1756 -1094   807  -967  -857     0\n",
      " -1386  -925 -1098   440     0  -896  -450 -2629   122 -1758  -416  -963\n",
      "  -597  -971 -2183  -467   524   611     0 -1177    60 -1181   783   184\n",
      "   407  -945   703  -311    62   165   872   785  -419 -1436 -2269 -1381\n",
      "    87     0 -1460   822  -836   138  -329 -1623 -1034  -859   415  1170\n",
      "  -755 -1021     0  -475 -1340   546   460  -984   903     0   364  -698\n",
      " -1564 -2834  -564 -2432  -296   922 -2244   385  -428    76 -2776  -727\n",
      "  1261  -523  -324  -601  -557  -220  -161  -284  1875  -700 -1968  -297\n",
      " -2218 -1202  -387  -426   140   131     0 -1869 -1325  -911  -662 -2717\n",
      "   207 -1446 -2738  -781  -130 -1120  1591   847  1191  -207  1668  -854\n",
      "  -551  1914 -2020   819 -1270  -872  -590     0  -488     0  -367 -1358\n",
      "  -780 -2960     0  1177 -2314 -3817   620  -168  -965 -1559  -829 -2900\n",
      "  -236 -1043 -3187     0 -1726   467 -1703   522   322     0  -756  -124\n",
      "   142  -860 -2716 -1445 -2138   919 -1031 -4187 -2152 -1311 -1332     0\n",
      "     0 -1685   262  -533   626  -629  -731   361   682 -1861 -1434 -2353\n",
      "  -247   626  -417 -2733 -2181  -498   928   367 -1155  -510   -74  -364\n",
      "     0  -949 -1787 -1354   321     0   204 -1378  -515 -1235  -390   922\n",
      " -1301   172  -901   986    18 -1199 -3861 -1580  2272  -864 -1058 -1617\n",
      "  -905    32   433 -2807 -1259   277   701  -116  1291  -412  -573 -1382\n",
      "  -724 -1443  -815 -1937   311  1174 -1161 -1629    59   153 -1315 -2201\n",
      " -2285    97  -542  -980 -1379  -673     0   405]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1013.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1036.weight_quantized, Weights: (512, 512, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 112 114]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1036.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 4608\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4608.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999997832\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.00021701388888884174\n",
      "\n",
      "\n",
      "Layer: Conv_1036.bias_quantized, Weights: (512,)\n",
      "[ -605  -654  -242  -328 -1208  -363  -558  1257  -109  -341 -1306  -446\n",
      "  -283  -991  -462   -38  -243  -487  -193  -383  -237  1810  -715  -543\n",
      "  -311  -433  -355  -357  -311 -1502  -498  -488 -1244   -90   575  -185\n",
      "  -209  -310  -293  -979  -696  -918  -528  -752  -723  -559  -380  -192\n",
      "  -486  -482 -1075  -530  -114  -688   -32  -174  -599 -1170   231  -500\n",
      " -1380   -98  -688   -85  -159  -829  -747 -1349  -462 -1515  -330  -448\n",
      "  -437   -49  -509 -1092  -303    64 -1510 -2737   -48  -367   -96  -295\n",
      "     7  -756  -798   -46  -608  1246     0  -279  -416  -523  -510   147\n",
      "   148  -320  -203  -395   765  -221  -120  -230  -689  -543    24  -424\n",
      " -1823  -414  -541  -887  -175   676  -343   -64   -72  -738 -1064     0\n",
      "  -216  -361  -207  -613  -107 -1007  1210  -276  -774   -39  -356  -397\n",
      "  -725  -263  -601  -278  -694  -514   130  -337  -389  -533  -202  -180\n",
      "  -136  -645  -834  -450  -679  -653  -333   369    33  -159 -1428  -102\n",
      "  -324  -713  -562    32  -428  -279   -91 -1258  -433     0  -514  -559\n",
      " -1068  -556  -355  -347 -1963  -438   -99  -537  -567  -462  -398  -215\n",
      " -1706  1110  -666  -202  -174  -587  -136  -217  -122  -168  -733  -644\n",
      "   574  -327  -666   -97  -358 -1059  -236  -684  -191 -2034  -730    74\n",
      "   -33  -386 -1846  -256  -702  -792  -283  -436  -287    -9 -1056   251\n",
      "    15   -44  -865  -672  -704  -414  -529  -595 -1693  -177  -374   -72\n",
      "  -351  1679  -379 -1131  -329  -163  -293  -167  -208  -685  -318  -153\n",
      "  -945  -260  1664  -418  -641  -155  -534  -714  -333  -631  -284  -378\n",
      "  -453  -315  -501  -404  -416  -512  -583  -390  -461  1975   341   279\n",
      "  -122  -284  -882  -232  -260    36  -149   317    74  -199  -413  -151\n",
      "  -524  1453  -221  -353  -337     0  2219  -807  -371  -645   241  -321\n",
      "  -213  -623  -440  -337   -84  -916  -597   437  -277  -286  -139  -870\n",
      " -1274   -78  -442  -219  -418  -511  -239  -810  1693  -758  -114    36\n",
      "  -620   -87  -174  -101     0  -708   -93  -271  -379  -241  -404 -1360\n",
      "  -329  -170    37   121   -83  -545  -288     0  -233  -236 -1365  -367\n",
      "  -219  -239  -224  -441  -675  -144  -844  -691 -1088  -355  -312  -212\n",
      "  -126 -1236  -603   715  -549  -664  -104  -234     0 -2267  -466   149\n",
      "  -770  -505   120   -50  -373   -97  -660  -850  -916  -295     4 -1509\n",
      "  -245 -1523  -823  -408 -1585     0 -1305  -167  -363  -195  -598 -1258\n",
      " -1008 -2303  -478  -726  -562   -70  -275  -642  -188  -443    53   -14\n",
      " -1504  -891   -55  -368 -1214  -416  -185  -490  -161  -394   -82   -34\n",
      "  -265  -315  -577   -13  -350 -1363  -195  -181  -189  -137  -245  -109\n",
      "  -490  -379  -367  -608 -1038  -603  -220 -1115  -211     1  -481  -295\n",
      "  -507  -766  -528  -158 -1265  -402  -405  -428  -611  -100 -1238  -622\n",
      "  -547  -290  -179  -510  -226  -845  -482  -193  -432  -798  -266  -489\n",
      "  -463     0  -159  -209  -722  -375  -233  -869 -1871  2644  -255  -181\n",
      "   569  -779   205  -281 -1024  -226  -856  -191  -225  -371  -156  -143\n",
      "  -583 -2240  -253    19  1846  -409  -394  -748  -401 -1192  -319  -129\n",
      "  -991  -290  -519  -420 -3274  -459  -391  -550     0  -414  2959  -450\n",
      "  -457  -400  -311  -222   -11  -521  -477  -235]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1036.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1059.weight_quantized, Weights: (2048, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[122]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1059.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1059.bias_quantized, Weights: (2048,)\n",
      "[ 581    0 -672 ...    0    0    0]\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1059.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1081.weight_quantized, Weights: (2048, 1024, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[121]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (2048, 1024, 1, 1)\n",
      "Features for Conv_1081.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 1024\n",
      "  nnz_max: 1024\n",
      "  nnz_avg: 1024.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 1024\n",
      "  bw_max: 1024\n",
      "  bw_avg: 1024.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999990231\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.000976562499999046\n",
      "\n",
      "\n",
      "Layer: Conv_1081.bias_quantized, Weights: (2048,)\n",
      "[-297    0 -140 ...    0    0    0]\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1081.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1105.weight_quantized, Weights: (512, 2048, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 2048, 1, 1)\n",
      "Features for Conv_1105.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2048\n",
      "  nnz_max: 2048\n",
      "  nnz_avg: 2048.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2048\n",
      "  bw_max: 2048\n",
      "  bw_avg: 2048.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995116\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.00048828124999976153\n",
      "\n",
      "\n",
      "Layer: Conv_1105.bias_quantized, Weights: (512,)\n",
      "[    0  -700     0     0     0  -140   187     0     0   512     0   373\n",
      "     0   938     0   202   467     0     0     0   267   407     0     0\n",
      "     0   317     0  -203     0     0     0  -346     0     0  -133     0\n",
      "   -45   268     0     0     0    21    76  -276   234    72     0     0\n",
      "   132     0     0     0     0     0     0   289  -177     0     0     0\n",
      "     0  -259     0   140     0   425     0   741     0  1032   490     0\n",
      "     0  -353     0     0     0     0   295   582     0  -259     0     0\n",
      "     0   365     0  -170     0   -85     0     0    30   455   459   -18\n",
      "     0     0     0   -75   556     0  -921   -96   511   -67  -758     0\n",
      "   297     0     0     0     0     0   804     0     0   -87     0     0\n",
      "     0   344     0  -123  -261     0     0     0  1159   611     0     0\n",
      "   206     0   321     0   206     0  1709     0   227     0     0     0\n",
      "  -860     0     0     0     0     0     0     0   318     0     0     0\n",
      "   -56     0   743    41   500     0     0     0     0     0     0     0\n",
      "     0     0   487     0     0     0     0     0     0   913     0  -127\n",
      "     0     0     0     0     0     0  -261     0   272  -446     0     0\n",
      "   -49     0     0     0     0     0     0     0     0     0   -40     0\n",
      "     0     0     0     0     0     0     0     0     0     0   -61   177\n",
      "     0     0   503     0   556  -865     0   681     0     0  -356   970\n",
      "     0     0   122     0     0   106     0     0     0     0     0     0\n",
      "     0     0    81     0   534     0   673     0     0     0     0     0\n",
      "   394     0  -308     0   250    60     0    54   606     0     0   215\n",
      "     0     0     0  -224  1030     0   136     0  -716     0 -1146     0\n",
      "   105     0   214     0   474     0     0    34    13  2428     0     0\n",
      "     0     0  -340     0     0     0     0   737     0    26     0     0\n",
      "  -145     0     0   113     0     0  -139     0     0     0     0  -347\n",
      "    90     0     0     0     0     0     0  -118     0     0  -341   246\n",
      "     0   747     0     0   851   -92     0  -657     0  -355     0     0\n",
      "     0     0 -1243     0     0     0     0     0     0     0   -24   533\n",
      "     0     0   257  -199   902     0     0  -196     0     0     0     0\n",
      "   672     0     0     0     0   635     0   385     0     0     0  -114\n",
      "     0     0     0   606   209     0     0     0     0     0   182     0\n",
      "   200     0    92   408   464     0     0     0     0  -584  -173     0\n",
      "   186     0   164     0   153     0     0     0     0 -1031  -528     0\n",
      "  -966     0   504    60     0   373     0     0     0   324   407     0\n",
      "   -28  -692   304     0     0     0   307     0     0     0    48   548\n",
      "     0  -371   549     0     0   294     0    53     0   -10     0     0\n",
      "   473   585  -506     0     0     0   448     0     0  -606     0  -506\n",
      "     0   401     0  -708     0   -58     0     0   452  -694     0     0\n",
      "     0     0   653     0     0     0     0   -17     0     0     0   863\n",
      "     0     0     0   673   400  -324     0     0     0     0     0     0\n",
      "     0  -778   392     0     0     0     0   541     0     0  -185    33\n",
      "   460     0     0     0   466  -500     0     0]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1105.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1128.weight_quantized, Weights: (512, 512, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 138 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1128.weight_quantized:\n",
      "  density: 0.9999995761447482\n",
      "  nnz_min: 4607\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4607.998046875\n",
      "  nnz_sd: 0.044150994357255134\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999995761445315\n",
      "  scatter_sd: 9.581378983777146e-06\n",
      "  clustering_avg: 0.0002174379281454624\n",
      "\n",
      "\n",
      "Layer: Conv_1128.bias_quantized, Weights: (512,)\n",
      "[  113  -611  -630   -38   842     0     0 -1419     0  -966     0 -2003\n",
      "     0   662   661 -1526     0    12  -787  -476     0 -2105     0     0\n",
      "     0     0  -339 -2518 -2716     0   783     0     0  2674     0 -1217\n",
      " -1657 -2598 -2423 -1025   577 -1654 -2470 -1548     0 -7072  -193 -1439\n",
      "     0     0 -1927     0 -3192 -1752 -2626     0     0 -2543 -1963 -1568\n",
      " -1097 -5826     0  -880  2706     0  -875 -3858 -1126  2319     0     0\n",
      "    -9 -5719 -1105     0  -823 -2110 -1445   254 -1352  -116     0  -540\n",
      "     0     0  1959  -868 -3885 -1827 -2245  -823  -772     0     0 -1085\n",
      " -2116     0     0  1707     0  2111 -7258     0   633 -2605 -2790     0\n",
      "     0     0     0   940     0 -2253 -3871 -2129     0  -433     0   198\n",
      " -2134  -778  6408   290 -1513  -627  -512  -529     0  1077  -772   -50\n",
      "     0 -1728 -1966  -444     0  -222 -1224  1055     0 -2983     0     0\n",
      "     0     0  -847 -1915  2668  -312 -1582     0  -382     0 -1815 -1539\n",
      "  1355 -3532 -1994 -3784 -2035 -3350     0 -2197     0     0     0     0\n",
      "  -938    12     0 -1773 -1609     0  -165     0     0     0  1885   952\n",
      "  -465 -2311  3014 -2468 -3585 -2674   162 -2232 -1311 -9946 -3674     0\n",
      " -3035     0     0  -338  1073 -1019 -2024  -836   -95   848 -2573 -3164\n",
      " -1284 -1098 -1543     0 -2606     0 -1095  -107 -1692    77     0     0\n",
      " -1339  1844 -6686 -2883     0  -294 -2535 -1656 -3315  2565 -1885    94\n",
      "   519     0  -940   456   107     0     0     0    51  -180     0     0\n",
      "     0 -1098  -643     0  1662 -6212 -1892     0 -3189 -2131     0     0\n",
      "  1220 -2041 -1948 -2805   786 -1953     8     0 -1653 -3583     0 -5773\n",
      "     0     0   485 -3018  1846     0  2036     0 -1085  1624     0 -1906\n",
      "  -990  1750     0  2038 -1293 -9614 -3041     0 -3606  -751     0     0\n",
      "   983     0 -2429 -3706  1648 -1654  3937  -156 -1683 -1694 -1051  1680\n",
      "     0     0     0  -479 -1064  -170  -808 -1062 -1544     0 -3210 -1939\n",
      "  -933 -3294     0     0  -867   423 -2160     0 -2398 -1436  -779     0\n",
      "   521     0 -4960 -1048  -855 -2904 -4343 -1474 -3010     0  -597     0\n",
      "  -151     0 -3087  -983     0 -2078     0    74   703 -1090     0   809\n",
      " -1112     0     0 -3259     0   860  -147   274  -357 -1155 -4298 -1339\n",
      "  -506  -253 -1452 -1941 -2403 -1008     0 -4746 -2480     0 -2653     0\n",
      " -2834 -3244  -404 -1086 -2460     0  -619   -42  1041     0  1568  3261\n",
      "  1120   169 -1627  -116   572     0     0     0 -2721 -2465  -483 -1530\n",
      " -3234  -777 -2515 -2594 -1643  -921 -3094 -1903  4145     0     0     0\n",
      " -1848     0 -1167   -73     0     0 -1807 -1005 -3328  1231   227  -747\n",
      "     0     0     0  2049 -2093     0     0     0  2125 -1256     0     0\n",
      " -3719 -1904  2702 -2481  2932  3023  1925 -2549  -850  -430     0 -1835\n",
      "   196  -539 -2425  1973 -2978 -2516 -1461 -3119     0 -1950     0  -409\n",
      "     0     0     0 -3053 -2510     0     0     0    90 -2289  1719     0\n",
      " -1699 -2060  -538 -2496 -1256 -2185     0 -2757  1715 -2173 -1424 -2754\n",
      "  -512     0 -1533  -748 -5165    51 -1311  -710    59     0 -8186 -1744\n",
      "     0 -1126 -1623 -2806     0     0     0     0  1787     0     0 -1444\n",
      "     0  -451 -2343   276     0  2527   373 -1223]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1128.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1151.weight_quantized, Weights: (2048, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[138]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1151.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1151.bias_quantized, Weights: (2048,)\n",
      "[  209     0 -1182 ...     0     0     0]\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1151.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1175.weight_quantized, Weights: (512, 2048, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[120]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (512, 2048, 1, 1)\n",
      "Features for Conv_1175.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 2048\n",
      "  nnz_max: 2048\n",
      "  nnz_avg: 2048.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 2048\n",
      "  bw_max: 2048\n",
      "  bw_avg: 2048.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999995116\n",
      "  scatter_sd: 1.1102230246251565e-16\n",
      "  clustering_avg: 0.00048828124999976153\n",
      "\n",
      "\n",
      "Layer: Conv_1175.bias_quantized, Weights: (512,)\n",
      "[ -459  -382  -835  -616  -984  -849  -587  -639  -864  -980  -107     0\n",
      "  -716  -103  -934  -405  -446  -573  -577     0  -708  -754  -638  -470\n",
      "     0  -244  -848  -494  -904  -610  -980  -542  -870  -596  -422  -806\n",
      "  -955  -630  -288  -569  -356  -408  -521  -427  -643  -667  -962  -512\n",
      "  -551  -735  -727  -644  -844   945     0  -444  -337  -417  -333  -441\n",
      "  -472  -724    34  -763  -901  -455     0     0     0  -398  -376   -47\n",
      "  -671  -739  -620  -576 -1003  -117 -1149  -491  -696  -814  -432  -645\n",
      "  -390  -736  -319  -565  -202  -539  -538  -697  -328  -834  -588  -765\n",
      "  -334  -802  -781  -367  -279     0  -321  -661     0  -472  -741  -646\n",
      "  -781  -604  -694  -675  -873  -500  -598 -1415     0  -625  -596     0\n",
      "  -766  -558  -561 -1153     0  -631  -388  -202  -477  -551  -629  -736\n",
      "  -711  -619  -839  -777  -599  -667     0  -350  -685  -590  -515  -342\n",
      "  -579  -843     0  -568     0  -499  -300  -540     0  -643  -870  -618\n",
      "  -707  -570  -911  -514  -767  -803  -281  -556  -575  -767  -238  -331\n",
      "  -793  -570  -677  -659  -427  -800 -1042  -504  -573  -835     0  -802\n",
      "  -602  -315     0  -579     0     0  -882     0     0  -763  -731  -540\n",
      "  -149  -504  -632  -620  -599  -395  -918  -555  -619  -681  -806  -815\n",
      "  -572  -631  -834     0  -664  -747  -923  -549  -846  -723  -523  -758\n",
      "  -296  -809  -483  -254  -781  -756  -552  -652  -356     0  -358  -605\n",
      "  -550  -338  -430  -576  -426  -602     0  -887  -118   -16  -858  -437\n",
      "  -394  -401  -366     0  -897  -831  -348  -746  -409  -490  -714  -665\n",
      "  -344  -343  -384  -782  -890  -709  -589  -845  -365  -967    -4  -663\n",
      "     0  -700  -638  -402  -610  -218  -719  -712  -471  -286  -747  -297\n",
      "     0  -639  -571  -353  -596     0  -685 -1138  -680  -725  -666  -674\n",
      "  -534     0  -512  -711  -160  -731  -921  -440  -630  -548  -553  -477\n",
      "  -756  -903  -723  -421  -350  -219  -348  -457  -716  -807  -533  -580\n",
      "  -720  -520  -606  -741  -409  -526  -468  -476  -226  -377  -614  -558\n",
      "     0  -806  -631  -812  -553  -745  -242  -705  -692  -798  -372  -832\n",
      "  -398  -522  -430  -635  -428  -508  -614  -448  -693  -425     0  -596\n",
      "  -963     0     0  -621  -241  -696  -760  -779     0  -795  -402  -819\n",
      "  -660  -631   -54  -641  -277  -814  -600  -549  -696  -826  -770 -1227\n",
      "  -500     0  -376  -678  -177  -176  -867  -835  -915  -739  -365  -627\n",
      "  -649  -139  -653  -957  -820  -997  -572  -753  -713  -731  -821  -744\n",
      "  -785  -324  -518  -505  -381  -865  -630  -564  -279  -264  -216  -580\n",
      "  -707  -418  -427  -921  -501  -380  -478  -475  -999  -479  -921  -635\n",
      "  -730     0  -356  -747  -849  -850  -264  -518  -537  -818  -320  -764\n",
      "  -411 -1158  -473  -270  -762  -566  -575  -761  -219  -512  -643  -790\n",
      "  -515  -442     0  -565  -467  -633  -787  -474  -477  -505  -590  -924\n",
      "  -231  -495     0  -599  -653  -417  -525  -478  -198  -823  -540  -515\n",
      "  -921  -874  -687  -585  -219  -433  -683  -461  -805  -697  -568  -177\n",
      "  -733  -570 -1041  -700  -568  -543     0  -825  -605  -671  -862  -802\n",
      "     0  -795  -710  -563  -797  -160  -633  -201  -534  -695  -740  -500\n",
      "   -81  -486  -282  -192    90  -618  -718  -561]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1175.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1198.weight_quantized, Weights: (512, 512, 3, 3)\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]\n",
      "\n",
      "\n",
      " [[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]]]\n",
      "Calculating features for matrix with shape: (512, 512, 3, 3)\n",
      "Features for Conv_1198.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 4608\n",
      "  nnz_max: 4608\n",
      "  nnz_avg: 4608.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 4608\n",
      "  bw_max: 4608\n",
      "  bw_avg: 4608.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999997832\n",
      "  scatter_sd: 3.3306690738754696e-16\n",
      "  clustering_avg: 0.00021701388888884174\n",
      "\n",
      "\n",
      "Layer: Conv_1198.bias_quantized, Weights: (512,)\n",
      "[    6  -141    15   -37   -35    33    36     0   -70  -103  -245   -73\n",
      "    -1   -70    32   -64  -458   -97   -36    45  -112  -113   -25  -150\n",
      "     0   -25    40     0   -33    20     0   -44  -159  -109   -70  -310\n",
      "   -71    48   -94    46   -52  -143  -184   -65   -16  -278   -13    12\n",
      "   -10   -80    23  -168    17   -30   -50   -30  -138  -136    19    44\n",
      "     0   110   -70    59  -179  -269     0   -51   -73    16     0     0\n",
      "    42   -43   418    23   -32   -67    50   -58    13   -22    60   -99\n",
      "   -12  -214    -4  -119   -24    57  -125  -170   861  1058    15    11\n",
      "  -222    14     0   -64  -168     5    -1   -28  -299    36  -787   246\n",
      "  -288    42  -166   -38     0     7  -356   -71   -94    -9   -23  -147\n",
      "     0    46    22   346    60    13  -299   -32    -5    14  -218    24\n",
      "    37   -15    34    20    41   -63   -67  -144  -175   -62    41   -60\n",
      "  -335    17    28   -16  -163    21    32    69   -66  -410   -96  -101\n",
      " -1349    48  -120   -45    31    20    23   131  -145    24   -51    74\n",
      "  -551    13  -255   -26   548   -88    29    -4     0   -27  -447    11\n",
      "  -314    97  -132     7    20  -195    -1    36    27    52     5    11\n",
      "  -441   -11    -3  -195  -276  -425    21   -44  -220     0  -707   -98\n",
      "  -291  -144   -44    -7    57  -189   -61    75  -193    71   -29   289\n",
      "    90   -49    25   -66   -44     4    21  -108   -81     0  -150  -118\n",
      "    28     0    27  -151     0    10  -261    11    16    18    54  -456\n",
      "    60    87   -50    24     6    29  -106    25     0 -1569  -238   -76\n",
      "   396    27   -32    37  -150  -252  -159  -993   -98  -175     8   -66\n",
      "  -280   -19    12    25    38   -85   -64   -42   -82    44    46     0\n",
      "  -111    46    27    -2   -32    -3    38    20    17   -66     3    20\n",
      "  -104  -126   -37   -35  -112     0  -106   -20    32  -121   -93  -326\n",
      "    36   -54  -248  -299   304   -78  -264  -155    12   819  -126    31\n",
      "   -19   -62    53     0    39 -1074  -218   -60  -898   -14  -505  -244\n",
      "     0    36    32   -24  -133   -84     0   -79     0   -79   -80    36\n",
      "    15    62   -71 -1142   -65    27  -195  -114   -97   122   -24  -447\n",
      "   -22    31   -87   -25   -46  -494    22   -21   -84  -183     8   -72\n",
      "    38   -45   -10    23    26     1     0  -148  -116     0  -116   -29\n",
      "    19    26    43   -57  -300   114  -129   -87  -346   -86   -76   -52\n",
      "   -50    15    77  -258    17    42  -106     5     0   -48   -88   150\n",
      "  -231   -75    11  -148  -238  -114   -11  -475    -2   -18    39     0\n",
      "  -324   -79   -64    -3    30   -97   -31   -61  -100   -11  -405   -11\n",
      "     0  -635   -83  -349   -23  -382    86   -94    29 -1468  -130  -102\n",
      "    45   -33    -9  -192    47   -85  -130     6  -235  -172  -205  -113\n",
      "  -200     0  -194  -434  -345    20  -222   -54  2496  -145     3    37\n",
      "     0    47   -61    26   -61   -92  -159    67     0    56   -46    10\n",
      "  -331   -86  -122   -29  -288     9  -424   -60  -323  -862  -367  -330\n",
      "   -80   -18  -303   -40   -43  -177   -46   -61  -408    21    27  -965\n",
      "  -121     8   -16  -149  -206    55   -86    46     0    45   -72    -9\n",
      "  -133   -41  -539   -55     0     0    12  -189]\n",
      "Calculating features for matrix with shape: (512,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (512,)\n",
      "Skipping layer Conv_1198.bias_quantized due to None values in features.\n",
      "\n",
      "Layer: Conv_1221.weight_quantized, Weights: (2048, 512, 1, 1)\n",
      "[[[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[132]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]\n",
      "\n",
      "\n",
      " [[[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]\n",
      "\n",
      "  [[128]]]]\n",
      "Calculating features for matrix with shape: (2048, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Conv_1221.weight_quantized:\n",
      "  density: 1.0\n",
      "  nnz_min: 512\n",
      "  nnz_max: 512\n",
      "  nnz_avg: 512.0\n",
      "  nnz_sd: 0.0\n",
      "  bw_min: 512\n",
      "  bw_max: 512\n",
      "  bw_avg: 512.0\n",
      "  bw_sd: 0.0\n",
      "  scatter_avg: 0.9999999999980465\n",
      "  scatter_sd: 4.440892098500626e-16\n",
      "  clustering_avg: 0.0019531249999961845\n",
      "\n",
      "\n",
      "Layer: Conv_1221.bias_quantized, Weights: (2048,)\n",
      "[-864    0 -231 ...    0    0    0]\n",
      "Calculating features for matrix with shape: (2048,)\n",
      "Skipping detailed feature calculation for 1D tensor with shape (2048,)\n",
      "Skipping layer Conv_1221.bias_quantized due to None values in features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparsezoo import Model\n",
    "import os\n",
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# Load the model using the specified stub\n",
    "stub = \"zoo:resnet_v1-50-imagenet-pruned95_quantized\"\n",
    "model = Model(stub)\n",
    "\n",
    "# Access the download path of the model\n",
    "download_path = model.path  # This is where the model will be downloaded\n",
    "onnx_model_file = model.onnx_model.path\n",
    "\n",
    "# Download the model files if they don't already exist\n",
    "if os.path.isdir(download_path) and os.listdir(download_path):\n",
    "    print(f\"Model already downloaded at: {onnx_model_file}\")\n",
    "else:\n",
    "    # Download the model files\n",
    "    model.download()\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model downloaded at: {onnx_model_file}\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "# Function to calculate sparsity and features\n",
    "def calculate_features(weight_matrix):\n",
    "    print(f\"Calculating features for matrix with shape: {weight_matrix.shape}\")\n",
    "    \n",
    "    if weight_matrix.ndim == 0:  # Scalar\n",
    "        print(f\"Skipping feature calculation for scalar tensor with shape {weight_matrix.shape}\")\n",
    "        return {\n",
    "            'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "    elif weight_matrix.ndim == 1:  # 1D array\n",
    "        nnz = np.count_nonzero(weight_matrix)\n",
    "        density = nnz / weight_matrix.size\n",
    "        print(f\"Skipping detailed feature calculation for 1D tensor with shape {weight_matrix.shape}\")\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    N = weight_matrix.shape[0]  # Number of rows\n",
    "    nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "    # Calculate density based on the number of elements in the matrix\n",
    "    if weight_matrix.ndim == 2:\n",
    "        density = nnz / (N ** 2)  # Density as NNZ/N^2 for 2D matrices\n",
    "    else:\n",
    "        density = nnz / weight_matrix.size  # General density for other dimensions\n",
    "\n",
    "    if weight_matrix.ndim == 2:\n",
    "        nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "    elif weight_matrix.ndim == 4:\n",
    "        reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "        nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "    else:\n",
    "        print(f\"Skipping detailed feature calculation for tensor with shape {weight_matrix.shape}\")\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "    bw_min = np.min(bw) if bw else 0\n",
    "    bw_max = np.max(bw) if bw else 0\n",
    "    bw_avg = np.mean(bw) if bw else 0\n",
    "    bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "    scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "    scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "    scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "    clustering = []\n",
    "    for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "        groups = 0\n",
    "        prev_nonzero = -2\n",
    "        for idx in np.nonzero(row)[0]:\n",
    "            if idx != prev_nonzero + 1:\n",
    "                groups += 1\n",
    "            prev_nonzero = idx\n",
    "        clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "    clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "    return {\n",
    "        'density': density,\n",
    "        'nnz_min': nnz_min,\n",
    "        'nnz_max': nnz_max,\n",
    "        'nnz_avg': nnz_avg,\n",
    "        'nnz_sd': nnz_sd,\n",
    "        'bw_min': bw_min,\n",
    "        'bw_max': bw_max,\n",
    "        'bw_avg': bw_avg,\n",
    "        'bw_sd': bw_sd,\n",
    "        'scatter_avg': scatter_avg,\n",
    "        'scatter_sd': scatter_sd,\n",
    "        'clustering_avg': clustering_avg\n",
    "    }\n",
    "\n",
    "\n",
    "# Print the layers, their weights, and calculated features\n",
    "for tensor in onnx_model.graph.initializer:\n",
    "    print(f\"Layer: {tensor.name}\")\n",
    "    print(f\"Shape: {tensor.dims}\")\n",
    "    weights = numpy_helper.to_array(tensor)\n",
    "    print(f\"Weights: {weights}\\n\")\n",
    "\n",
    "    # Calculate features\n",
    "    features = calculate_features(weights)\n",
    "    \n",
    "    # Check if any of the calculated features are None and skip the layer if so\n",
    "    if any(value is None for value in features.values()):\n",
    "        print(f\"Skipping layer {tensor.name} due to None values in features.\\n\")\n",
    "        continue  # Skip this layer if any feature is None\n",
    "    \n",
    "    print(f\"Features for {tensor.name}:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# If you want to extract and handle weights and their features more specifically,\n",
    "# you can store them in a dictionary.\n",
    "weights_dict = {tensor.name: numpy_helper.to_array(tensor) for tensor in onnx_model.graph.initializer}\n",
    "\n",
    "# Example: Print specific layer weights and features\n",
    "for layer_name, weights in weights_dict.items():\n",
    "    print(f\"Layer: {layer_name}, Weights: {weights.shape}\")\n",
    "    print(weights)\n",
    "\n",
    "    # Calculate features\n",
    "    features = calculate_features(weights)\n",
    "    \n",
    "    # Check if any of the calculated features are None and skip the layer if so\n",
    "    if any(value is None for value in features.values()):\n",
    "        print(f\"Skipping layer {layer_name} due to None values in features.\\n\")\n",
    "        continue  # Skip this layer if any feature is None\n",
    "    \n",
    "    print(f\"Features for {layer_name}:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51f758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b8ca88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4490a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e55ad38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d074bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d866b06",
   "metadata": {},
   "source": [
    "# First Run (YOLOV5 Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53305bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: zoo:yolov5-n-coco-pruned40_quantized\n",
      "Processing model: zoo:yolov5-n-voc_coco-pruned30.4block_quantized\n",
      "Processing model: zoo:yolov5-n6-voc_coco-pruned55_quantized\n",
      "Processing model: zoo:yolov5-n6-coco-pruned55_quantized\n",
      "Processing model: zoo:yolov5-s-coco-pruned85_quantized\n",
      "Processing model: zoo:yolov5-s-voc_coco-pruned_quantized\n",
      "Processing model: zoo:yolov5-s6-voc_coco-pruned65_quantized\n",
      "Processing model: zoo:yolov5-s6-coco-pruned65_quantized\n",
      "Processing model: zoo:yolov5-m-coco-pruned70_quantized\n",
      "Processing model: zoo:yolov5-m-voc_coco-pruned70_quantized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from onnx import numpy_helper\n",
    "from sparsezoo import Model\n",
    "\n",
    "# Function to calculate sparsity and features\n",
    "# Function to calculate sparsity and features\n",
    "def calculate_features(weight_matrix):\n",
    "    if weight_matrix.size == 0:  # Check if the matrix size is zero\n",
    "        return {\n",
    "            'density': None,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    if weight_matrix.ndim == 0:  # Scalar\n",
    "        return {\n",
    "            'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "    elif weight_matrix.ndim == 1:  # 1D array\n",
    "        nnz = np.count_nonzero(weight_matrix)\n",
    "        density = nnz / weight_matrix.size if weight_matrix.size > 0 else 0\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    N = weight_matrix.shape[0]\n",
    "    nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "    # Calculate density\n",
    "    if weight_matrix.ndim == 2:\n",
    "        density = nnz / (N ** 2) if N > 0 else 0\n",
    "    else:\n",
    "        density = nnz / weight_matrix.size\n",
    "\n",
    "    if weight_matrix.ndim == 2:\n",
    "        nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "    elif weight_matrix.ndim == 4:\n",
    "        reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "        nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "    else:\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "    bw_min = np.min(bw) if bw else 0\n",
    "    bw_max = np.max(bw) if bw else 0\n",
    "    bw_avg = np.mean(bw) if bw else 0\n",
    "    bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "    scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "    scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "    scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "    clustering = []\n",
    "    for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "        groups = 0\n",
    "        prev_nonzero = -2\n",
    "        for idx in np.nonzero(row)[0]:\n",
    "            if idx != prev_nonzero + 1:\n",
    "                groups += 1\n",
    "            prev_nonzero = idx\n",
    "        clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "    clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "    return {\n",
    "        'density': density,\n",
    "        'nnz_min': nnz_min,\n",
    "        'nnz_max': nnz_max,\n",
    "        'nnz_avg': nnz_avg,\n",
    "        'nnz_sd': nnz_sd,\n",
    "        'bw_min': bw_min,\n",
    "        'bw_max': bw_max,\n",
    "        'bw_avg': bw_avg,\n",
    "        'bw_sd': bw_sd,\n",
    "        'scatter_avg': scatter_avg,\n",
    "        'scatter_sd': scatter_sd,\n",
    "        'clustering_avg': clustering_avg\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_metrics_from_models(model_stubs, sample_size=None):\n",
    "    metrics_list = []\n",
    "\n",
    "    for stub, accuracy in model_stubs:\n",
    "        print(f\"Processing model: {stub}\")\n",
    "        model = Model(stub)\n",
    "        onnx_model_file = model.onnx_model.path\n",
    "        onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "        for tensor in onnx_model.graph.initializer:\n",
    "            weights = numpy_helper.to_array(tensor)\n",
    "            features = calculate_features(weights)\n",
    "\n",
    "            if any(value is None for value in features.values()):\n",
    "                continue  # Skip this layer if any feature is None\n",
    "\n",
    "            features['layer'] = tensor.name\n",
    "            features['accuracy'] = accuracy\n",
    "            features['model'] = stub\n",
    "            metrics_list.append(features)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    if sample_size and len(df_metrics) > sample_size:\n",
    "        df_metrics = df_metrics.sample(n=sample_size, random_state=42)  # Sample data to reduce size\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "# Function to plot the distribution of metrics and save them as images\n",
    "def plot_metrics_distribution(df_metrics, output_dir=\"plots\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(df_metrics[metric].dropna(), kde=True, bins=50)\n",
    "            plt.title(f'Distribution of {metric}')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_distribution.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Function to plot correlation of metrics with accuracy and save them as images\n",
    "def plot_correlation_with_accuracy(df_metrics, output_dir=\"plots\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.regplot(x=df_metrics[metric], y=df_metrics['accuracy'], ci=None, scatter_kws={'s': 50})\n",
    "            plt.title(f'Correlation of {metric} with Accuracy')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_correlation.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Example model stubs with their corresponding accuracies\n",
    "model_stubs = [\n",
    "    (\"zoo:yolov5-n-coco-pruned40_quantized\", 45.1),\n",
    "    (\"zoo:yolov5-n-voc_coco-pruned30.4block_quantized\", 71.3),\n",
    "    (\"zoo:yolov5-n6-voc_coco-pruned55_quantized\", 80.6),\n",
    "    (\"zoo:yolov5-n6-coco-pruned55_quantized\", 52.8),\n",
    "    (\"zoo:yolov5-s-coco-pruned85_quantized\", 53.4),\n",
    "    (\"zoo:yolov5-s-voc_coco-pruned_quantized\", 36.7),\n",
    "    (\"zoo:yolov5-s6-voc_coco-pruned65_quantized\", 86.8),\n",
    "    (\"zoo:yolov5-s6-coco-pruned65_quantized\", 61.5),\n",
    "    (\"zoo:yolov5-m-coco-pruned70_quantized\", 63.2),\n",
    "    (\"zoo:yolov5-m-voc_coco-pruned70_quantized\", 89.5)\n",
    "    # Add more models and their accuracies here\n",
    "]\n",
    "\n",
    "# Extract metrics from the models\n",
    "df_metrics = extract_metrics_from_models(model_stubs, sample_size=1000)  # Add sample_size to limit data if necessary\n",
    "\n",
    "# Plot the distribution of metrics and save them as images\n",
    "plot_metrics_distribution(df_metrics, output_dir=\"plots\")\n",
    "\n",
    "# Plot the correlation of metrics with accuracy and save them as images\n",
    "plot_correlation_with_accuracy(df_metrics, output_dir=\"plots\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "642308f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bw_avg_correlation.png',\n",
       " 'bw_avg_distribution.png',\n",
       " 'bw_max_correlation.png',\n",
       " 'bw_max_distribution.png',\n",
       " 'bw_min_correlation.png',\n",
       " 'bw_min_distribution.png',\n",
       " 'bw_sd_correlation.png',\n",
       " 'bw_sd_distribution.png',\n",
       " 'clustering_avg_correlation.png',\n",
       " 'clustering_avg_distribution.png',\n",
       " 'density_correlation.png',\n",
       " 'density_distribution.png',\n",
       " 'nnz_avg_correlation.png',\n",
       " 'nnz_avg_distribution.png',\n",
       " 'nnz_max_correlation.png',\n",
       " 'nnz_max_distribution.png',\n",
       " 'nnz_min_correlation.png',\n",
       " 'nnz_min_distribution.png',\n",
       " 'nnz_sd_correlation.png',\n",
       " 'nnz_sd_distribution.png',\n",
       " 'scatter_avg_correlation.png',\n",
       " 'scatter_avg_distribution.png',\n",
       " 'scatter_sd_correlation.png',\n",
       " 'scatter_sd_distribution.png']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the 'plots' directory\n",
    "output_dir = \"plots\"\n",
    "files = os.listdir(output_dir)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a57186f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ayush\\\\Desktop\\\\Msc\\\\plots_archive.zip'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a zip file containing all images\n",
    "shutil.make_archive('plots_archive', 'zip', 'plots')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e3e7197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='plots_archive.zip' target='_blank'>plots_archive.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\ayush\\Desktop\\Msc\\plots_archive.zip"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a download link for the zip file\n",
    "FileLink('plots_archive.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706de5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd015df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d26362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to plot the graphs in console\n",
    "# # import os\n",
    "# # import onnx\n",
    "# # import numpy as np\n",
    "# # import pandas as pd\n",
    "# # import seaborn as sns\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # from onnx import numpy_helper\n",
    "# # from sparsezoo import Model\n",
    "\n",
    "# # # Function to calculate sparsity and features\n",
    "# # def calculate_features(weight_matrix):\n",
    "# #     if weight_matrix.size == 0:  # Check if the matrix size is zero\n",
    "# #         return {\n",
    "# #             'density': None,\n",
    "# #             'nnz_min': None,\n",
    "# #             'nnz_max': None,\n",
    "# #             'nnz_avg': None,\n",
    "# #             'nnz_sd': None,\n",
    "# #             'bw_min': None,\n",
    "# #             'bw_max': None,\n",
    "# #             'bw_avg': None,\n",
    "# #             'bw_sd': None,\n",
    "# #             'scatter_avg': None,\n",
    "# #             'scatter_sd': None,\n",
    "# #             'clustering_avg': None\n",
    "# #         }\n",
    "\n",
    "# #     if weight_matrix.ndim == 0:  # Scalar\n",
    "# #         return {\n",
    "# #             'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "# #             'nnz_min': None,\n",
    "# #             'nnz_max': None,\n",
    "# #             'nnz_avg': None,\n",
    "# #             'nnz_sd': None,\n",
    "# #             'bw_min': None,\n",
    "# #             'bw_max': None,\n",
    "# #             'bw_avg': None,\n",
    "# #             'bw_sd': None,\n",
    "# #             'scatter_avg': None,\n",
    "# #             'scatter_sd': None,\n",
    "# #             'clustering_avg': None\n",
    "# #         }\n",
    "# #     elif weight_matrix.ndim == 1:  # 1D array\n",
    "# #         nnz = np.count_nonzero(weight_matrix)\n",
    "# #         density = nnz / weight_matrix.size if weight_matrix.size > 0 else 0\n",
    "# #         return {\n",
    "# #             'density': density,\n",
    "# #             'nnz_min': None,\n",
    "# #             'nnz_max': None,\n",
    "# #             'nnz_avg': None,\n",
    "# #             'nnz_sd': None,\n",
    "# #             'bw_min': None,\n",
    "# #             'bw_max': None,\n",
    "# #             'bw_avg': None,\n",
    "# #             'bw_sd': None,\n",
    "# #             'scatter_avg': None,\n",
    "# #             'scatter_sd': None,\n",
    "# #             'clustering_avg': None\n",
    "# #         }\n",
    "\n",
    "# #     N = weight_matrix.shape[0]\n",
    "# #     nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "# #     # Calculate density\n",
    "# #     if weight_matrix.ndim == 2:\n",
    "# #         density = nnz / (N ** 2) if N > 0 else 0\n",
    "# #     else:\n",
    "# #         density = nnz / weight_matrix.size\n",
    "\n",
    "# #     if weight_matrix.ndim == 2:\n",
    "# #         nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "# #         bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "# #     elif weight_matrix.ndim == 4:\n",
    "# #         reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "# #         nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "# #         bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "# #     else:\n",
    "# #         return {\n",
    "# #             'density': density,\n",
    "# #             'nnz_min': None,\n",
    "# #             'nnz_max': None,\n",
    "# #             'nnz_avg': None,\n",
    "# #             'nnz_sd': None,\n",
    "# #             'bw_min': None,\n",
    "# #             'bw_max': None,\n",
    "# #             'bw_avg': None,\n",
    "# #             'bw_sd': None,\n",
    "# #             'scatter_avg': None,\n",
    "# #             'scatter_sd': None,\n",
    "# #             'clustering_avg': None\n",
    "# #         }\n",
    "\n",
    "# #     nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "# #     nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "# #     nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "# #     nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "# #     bw_min = np.min(bw) if bw else 0\n",
    "# #     bw_max = np.max(bw) if bw else 0\n",
    "# #     bw_avg = np.mean(bw) if bw else 0\n",
    "# #     bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "# #     scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "# #     scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "# #     scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "# #     clustering = []\n",
    "# #     for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "# #         groups = 0\n",
    "# #         prev_nonzero = -2\n",
    "# #         for idx in np.nonzero(row)[0]:\n",
    "# #             if idx != prev_nonzero + 1:\n",
    "# #                 groups += 1\n",
    "# #             prev_nonzero = idx\n",
    "# #         clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "# #     clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "# #     return {\n",
    "# #         'density': density,\n",
    "# #         'nnz_min': nnz_min,\n",
    "# #         'nnz_max': nnz_max,\n",
    "# #         'nnz_avg': nnz_avg,\n",
    "# #         'nnz_sd': nnz_sd,\n",
    "# #         'bw_min': bw_min,\n",
    "# #         'bw_max': bw_max,\n",
    "# #         'bw_avg': bw_avg,\n",
    "# #         'bw_sd': bw_sd,\n",
    "# #         'scatter_avg': scatter_avg,\n",
    "# #         'scatter_sd': scatter_sd,\n",
    "# #         'clustering_avg': clustering_avg\n",
    "# #     }\n",
    "\n",
    "# # # Function to extract metrics from models\n",
    "# # def extract_metrics_from_models(model_stubs, sample_size=None):\n",
    "# #     metrics_list = []\n",
    "\n",
    "# #     for stub, accuracy in model_stubs:\n",
    "# #         print(f\"Processing model: {stub}\")\n",
    "# #         model = Model(stub)\n",
    "# #         onnx_model_file = model.onnx_model.path\n",
    "# #         onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "# #         for tensor in onnx_model.graph.initializer:\n",
    "# #             weights = numpy_helper.to_array(tensor)\n",
    "# #             features = calculate_features(weights)\n",
    "\n",
    "# #             if any(value is None for value in features.values()):\n",
    "# #                 continue  # Skip this layer if any feature is None\n",
    "\n",
    "# #             features['layer'] = tensor.name\n",
    "# #             features['accuracy'] = accuracy\n",
    "# #             features['model'] = stub\n",
    "# #             metrics_list.append(features)\n",
    "    \n",
    "# #     df_metrics = pd.DataFrame(metrics_list)\n",
    "    \n",
    "# #     if sample_size and len(df_metrics) > sample_size:\n",
    "# #         df_metrics = df_metrics.sample(n=sample_size, random_state=42)  # Sample data to reduce size\n",
    "    \n",
    "# #     return df_metrics\n",
    "\n",
    "# # Function to plot the distribution of metrics\n",
    "# def plot_metrics_distribution(df_metrics):\n",
    "#     metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "#     for metric in metrics:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.histplot(df_metrics[metric].dropna(), kde=True, bins=50)\n",
    "#         plt.title(f'Distribution of {metric}')\n",
    "#         plt.xlabel(metric)\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "# # Function to plot correlation of metrics with accuracy\n",
    "# def plot_correlation_with_accuracy(df_metrics):\n",
    "#     metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "#     for metric in metrics:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.regplot(x=df_metrics[metric], y=df_metrics['accuracy'], ci=None, scatter_kws={'s': 50})\n",
    "#         plt.title(f'Correlation of {metric} with Accuracy')\n",
    "#         plt.xlabel(metric)\n",
    "#         plt.ylabel('Accuracy')\n",
    "#         plt.show()\n",
    "\n",
    "# # # Example model stubs with their corresponding accuracies\n",
    "# # model_stubs = [\n",
    "# #     (\"zoo:yolo_v3-spp-coco-pruned.4block_quantized\", 60.5),\n",
    "# #     (\"zoo:vgg-16-imagenet-pruned\", 70.8),\n",
    "# #     (\"zoo:inception_v3-imagenet-pruned\", 76.6),\n",
    "# #     (\"zoo:yolov8-m-coco-pruned80_quantized\", 65.2),\n",
    "# #     (\"zoo:yolov5-m6-coco-pruned75_quantized\", 67.3),\n",
    "# #     (\"zoo:vgg-19-imagenet-pruned\", 71.7),\n",
    "# #     (\"zoo:yolov5-s6-voc_coco-pruned65_quantized\", 86.8),\n",
    "# #     (\"zoo:vgg-11-imagenet-pruned\", 68.3),\n",
    "# #     (\"zoo:yolov5-x-voc_coco-pruned70.4block_quantized\", 90.5),\n",
    "# #     (\"zoo:yolov8-n-coco-pruned49_quantized\", 50.1)\n",
    "# #     # Add more models and their accuracies here\n",
    "# # ]\n",
    "\n",
    "# # # Extract metrics from the models\n",
    "# # df_metrics = extract_metrics_from_models(model_stubs, sample_size=1000)  # Add sample_size to limit data if necessary\n",
    "\n",
    "# # # Plot the distribution of metrics\n",
    "# # plot_metrics_distribution(df_metrics)\n",
    "\n",
    "# # # Plot the correlation of metrics with accuracy\n",
    "# # plot_correlation_with_accuracy(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import onnx\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from onnx import numpy_helper\n",
    "# from sparsezoo import Model\n",
    "\n",
    "# # Function to calculate sparsity and features\n",
    "# def calculate_features(weight_matrix):\n",
    "#     if weight_matrix.size == 0:  # Check if the matrix size is zero\n",
    "#         return {\n",
    "#             'density': None,\n",
    "#             'nnz_min': None,\n",
    "#             'nnz_max': None,\n",
    "#             'nnz_avg': None,\n",
    "#             'nnz_sd': None,\n",
    "#             'bw_min': None,\n",
    "#             'bw_max': None,\n",
    "#             'bw_avg': None,\n",
    "#             'bw_sd': None,\n",
    "#             'scatter_avg': None,\n",
    "#             'scatter_sd': None,\n",
    "#             'clustering_avg': None\n",
    "#         }\n",
    "\n",
    "#     if weight_matrix.ndim == 0:  # Scalar\n",
    "#         return {\n",
    "#             'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "#             'nnz_min': None,\n",
    "#             'nnz_max': None,\n",
    "#             'nnz_avg': None,\n",
    "#             'nnz_sd': None,\n",
    "#             'bw_min': None,\n",
    "#             'bw_max': None,\n",
    "#             'bw_avg': None,\n",
    "#             'bw_sd': None,\n",
    "#             'scatter_avg': None,\n",
    "#             'scatter_sd': None,\n",
    "#             'clustering_avg': None\n",
    "#         }\n",
    "#     elif weight_matrix.ndim == 1:  # 1D array\n",
    "#         nnz = np.count_nonzero(weight_matrix)\n",
    "#         density = nnz / weight_matrix.size if weight_matrix.size > 0 else 0\n",
    "#         return {\n",
    "#             'density': density,\n",
    "#             'nnz_min': None,\n",
    "#             'nnz_max': None,\n",
    "#             'nnz_avg': None,\n",
    "#             'nnz_sd': None,\n",
    "#             'bw_min': None,\n",
    "#             'bw_max': None,\n",
    "#             'bw_avg': None,\n",
    "#             'bw_sd': None,\n",
    "#             'scatter_avg': None,\n",
    "#             'scatter_sd': None,\n",
    "#             'clustering_avg': None\n",
    "#         }\n",
    "\n",
    "#     N = weight_matrix.shape[0]\n",
    "#     nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "#     # Calculate density\n",
    "#     if weight_matrix.ndim == 2:\n",
    "#         density = nnz / (N ** 2) if N > 0 else 0\n",
    "#     else:\n",
    "#         density = nnz / weight_matrix.size\n",
    "\n",
    "#     if weight_matrix.ndim == 2:\n",
    "#         nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "#         bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "#     elif weight_matrix.ndim == 4:\n",
    "#         reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "#         nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "#         bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "#     else:\n",
    "#         return {\n",
    "#             'density': density,\n",
    "#             'nnz_min': None,\n",
    "#             'nnz_max': None,\n",
    "#             'nnz_avg': None,\n",
    "#             'nnz_sd': None,\n",
    "#             'bw_min': None,\n",
    "#             'bw_max': None,\n",
    "#             'bw_avg': None,\n",
    "#             'bw_sd': None,\n",
    "#             'scatter_avg': None,\n",
    "#             'scatter_sd': None,\n",
    "#             'clustering_avg': None\n",
    "#         }\n",
    "\n",
    "#     nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "#     nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "#     nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "#     nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "#     bw_min = np.min(bw) if bw else 0\n",
    "#     bw_max = np.max(bw) if bw else 0\n",
    "#     bw_avg = np.mean(bw) if bw else 0\n",
    "#     bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "#     scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "#     scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "#     scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "#     clustering = []\n",
    "#     for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "#         groups = 0\n",
    "#         prev_nonzero = -2\n",
    "#         for idx in np.nonzero(row)[0]:\n",
    "#             if idx != prev_nonzero + 1:\n",
    "#                 groups += 1\n",
    "#             prev_nonzero = idx\n",
    "#         clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "#     clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "#     return {\n",
    "#         'density': density,\n",
    "#         'nnz_min': nnz_min,\n",
    "#         'nnz_max': nnz_max,\n",
    "#         'nnz_avg': nnz_avg,\n",
    "#         'nnz_sd': nnz_sd,\n",
    "#         'bw_min': bw_min,\n",
    "#         'bw_max': bw_max,\n",
    "#         'bw_avg': bw_avg,\n",
    "#         'bw_sd': bw_sd,\n",
    "#         'scatter_avg': scatter_avg,\n",
    "#         'scatter_sd': scatter_sd,\n",
    "#         'clustering_avg': clustering_avg\n",
    "#     }\n",
    "\n",
    "# # Function to extract metrics from models\n",
    "# def extract_metrics_from_models(model_stubs, sample_size=None):\n",
    "#     metrics_list = []\n",
    "\n",
    "#     for stub, accuracy in model_stubs:\n",
    "#         print(f\"Processing model: {stub}\")\n",
    "#         model = Model(stub)\n",
    "#         onnx_model_file = model.onnx_model.path\n",
    "#         onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "#         for tensor in onnx_model.graph.initializer:\n",
    "#             weights = numpy_helper.to_array(tensor)\n",
    "#             features = calculate_features(weights)\n",
    "\n",
    "#             if any(value is None for value in features.values()):\n",
    "#                 continue  # Skip this layer if any feature is None\n",
    "\n",
    "#             features['layer'] = tensor.name\n",
    "#             features['accuracy'] = accuracy\n",
    "#             features['model'] = stub\n",
    "#             metrics_list.append(features)\n",
    "    \n",
    "#     df_metrics = pd.DataFrame(metrics_list)\n",
    "    \n",
    "#     if sample_size and len(df_metrics) > sample_size:\n",
    "#         df_metrics = df_metrics.sample(n=sample_size, random_state=42)  # Sample data to reduce size\n",
    "    \n",
    "#     return df_metrics\n",
    "\n",
    "# # Function to plot the distribution of metrics\n",
    "# def plot_metrics_distribution(df_metrics):\n",
    "#     metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "#     for metric in metrics:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.histplot(df_metrics[metric].dropna(), kde=True, bins=50)\n",
    "#         plt.title(f'Distribution of {metric}')\n",
    "#         plt.xlabel(metric)\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "# # Function to plot correlation of metrics with accuracy\n",
    "# def plot_correlation_with_accuracy(df_metrics):\n",
    "#     metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "#     for metric in metrics:\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.regplot(x=df_metrics[metric], y=df_metrics['accuracy'], ci=None, scatter_kws={'s': 50})\n",
    "#         plt.title(f'Correlation of {metric} with Accuracy')\n",
    "#         plt.xlabel(metric)\n",
    "#         plt.ylabel('Accuracy')\n",
    "#         plt.show()\n",
    "\n",
    "# # Example model stubs with their corresponding accuracies\n",
    "# model_stubs = [\n",
    "#     (\"zoo:resnet_v1-50-imagenet-pruned95_quantized\", 75.8),\n",
    "#     (\"zoo:resnet_v1-18-imagenet-pruned85.4block_quantized\", 69),\n",
    "#     (\"zoo:resnet_v1-34-imagenet-pruned\", 73.3),\n",
    "#     (\"zoo:resnet_v1-50-imagenette-pruned\",99.9),\n",
    "#     (\"zoo:resnet_v1-101-imagenet-pruned\", 76.6),\n",
    "#     (\"zoo:resnet_v1-152-imagenet-pruned\", 77.5),\n",
    "#     (\"zoo:resnet_v1-50_2xwidth-imagenet-base\", 78.1),\n",
    "#     (\"zoo:resnet_v1-101_2xwidth-imagenet-base\", 78.8)\n",
    "#     # Add more models and their accuracies here\n",
    "# ]\n",
    "\n",
    "# # Extract metrics from the models\n",
    "# df_metrics = extract_metrics_from_models(model_stubs, sample_size=1000)  # Add sample_size to limit data if necessary\n",
    "\n",
    "# # Plot the distribution of metrics\n",
    "# plot_metrics_distribution(df_metrics)\n",
    "\n",
    "# # Plot the correlation of metrics with accuracy\n",
    "# plot_correlation_with_accuracy(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "506bc32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fcd115",
   "metadata": {},
   "source": [
    "# Second Run (ResNetV1 Models Variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46b58f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: zoo:resnet_v1-18-imagenet-pruned85.4block_quantized\n",
      "Processing model: zoo:resnet_v1-34-imagenet-pruned\n",
      "Processing model: zoo:resnet_v1-50-imagenette-pruned\n",
      "Processing model: zoo:resnet_v1-101-imagenet-pruned\n",
      "Processing model: zoo:resnet_v1-152-imagenet-pruned\n",
      "Processing model: zoo:resnet_v1-50_2xwidth-imagenet-base\n",
      "Processing model: zoo:resnet_v1-101_2xwidth-imagenet-base\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from onnx import numpy_helper\n",
    "from sparsezoo import Model\n",
    "\n",
    "# Function to calculate sparsity and features\n",
    "def calculate_features(weight_matrix):\n",
    "    if weight_matrix.size == 0:  # Check if the matrix size is zero\n",
    "        return {\n",
    "            'density': None,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    if weight_matrix.ndim == 0:  # Scalar\n",
    "        return {\n",
    "            'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "    elif weight_matrix.ndim == 1:  # 1D array\n",
    "        nnz = np.count_nonzero(weight_matrix)\n",
    "        density = nnz / weight_matrix.size if weight_matrix.size > 0 else 0\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    N = weight_matrix.shape[0]\n",
    "    nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "    # Calculate density\n",
    "    if weight_matrix.ndim == 2:\n",
    "        density = nnz / (N ** 2) if N > 0 else 0\n",
    "    else:\n",
    "        density = nnz / weight_matrix.size\n",
    "\n",
    "    if weight_matrix.ndim == 2:\n",
    "        nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "    elif weight_matrix.ndim == 4:\n",
    "        reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "        nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "    else:\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "    bw_min = np.min(bw) if bw else 0\n",
    "    bw_max = np.max(bw) if bw else 0\n",
    "    bw_avg = np.mean(bw) if bw else 0\n",
    "    bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "    scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "    scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "    scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "    clustering = []\n",
    "    for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "        groups = 0\n",
    "        prev_nonzero = -2\n",
    "        for idx in np.nonzero(row)[0]:\n",
    "            if idx != prev_nonzero + 1:\n",
    "                groups += 1\n",
    "            prev_nonzero = idx\n",
    "        clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "    clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "    return {\n",
    "        'density': density,\n",
    "        'nnz_min': nnz_min,\n",
    "        'nnz_max': nnz_max,\n",
    "        'nnz_avg': nnz_avg,\n",
    "        'nnz_sd': nnz_sd,\n",
    "        'bw_min': bw_min,\n",
    "        'bw_max': bw_max,\n",
    "        'bw_avg': bw_avg,\n",
    "        'bw_sd': bw_sd,\n",
    "        'scatter_avg': scatter_avg,\n",
    "        'scatter_sd': scatter_sd,\n",
    "        'clustering_avg': clustering_avg\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_metrics_from_models(model_stubs, sample_size=None):\n",
    "    metrics_list = []\n",
    "\n",
    "    for stub, accuracy in model_stubs:\n",
    "        print(f\"Processing model: {stub}\")\n",
    "        model = Model(stub)\n",
    "        onnx_model_file = model.onnx_model.path\n",
    "        onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "        for tensor in onnx_model.graph.initializer:\n",
    "            weights = numpy_helper.to_array(tensor)\n",
    "            features = calculate_features(weights)\n",
    "\n",
    "            if any(value is None for value in features.values()):\n",
    "                continue  # Skip this layer if any feature is None\n",
    "\n",
    "            features['layer'] = tensor.name\n",
    "            features['accuracy'] = accuracy\n",
    "            features['model'] = stub\n",
    "            metrics_list.append(features)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    if sample_size and len(df_metrics) > sample_size:\n",
    "        df_metrics = df_metrics.sample(n=sample_size, random_state=42)  # Sample data to reduce size\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "# Function to plot the distribution of metrics and save them as images\n",
    "def plot_metrics_distribution(df_metrics, output_dir=\"plots_resnet\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(df_metrics[metric].dropna(), kde=True, bins=50)\n",
    "            plt.title(f'Distribution of {metric}')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_distribution.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Function to plot correlation of metrics with accuracy and save them as images\n",
    "def plot_correlation_with_accuracy(df_metrics, output_dir=\"plots_resnet\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.regplot(x=df_metrics[metric], y=df_metrics['accuracy'], ci=None, scatter_kws={'s': 50})\n",
    "            plt.title(f'Correlation of {metric} with Accuracy')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_correlation.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Example model stubs with their corresponding accuracies\n",
    "model_stubs = [\n",
    "    (\"zoo:resnet_v1-18-imagenet-pruned85.4block_quantized\", 69),\n",
    "    (\"zoo:resnet_v1-34-imagenet-pruned\", 73.3),\n",
    "    (\"zoo:resnet_v1-50-imagenette-pruned\",99.9),\n",
    "    (\"zoo:resnet_v1-101-imagenet-pruned\", 76.6),\n",
    "    (\"zoo:resnet_v1-152-imagenet-pruned\", 77.5),\n",
    "    (\"zoo:resnet_v1-50_2xwidth-imagenet-base\", 78.1),\n",
    "    (\"zoo:resnet_v1-101_2xwidth-imagenet-base\", 78.8)\n",
    "    # Add more models and their accuracies here\n",
    "]\n",
    "\n",
    "# Extract metrics from the models\n",
    "df_metrics = extract_metrics_from_models(model_stubs, sample_size=1000)  # Add sample_size to limit data if necessary\n",
    "\n",
    "# Plot the distribution of metrics and save them as images\n",
    "plot_metrics_distribution(df_metrics, output_dir=\"plots_resnet\")\n",
    "\n",
    "# Plot the correlation of metrics with accuracy and save them as images\n",
    "plot_correlation_with_accuracy(df_metrics, output_dir=\"plots_resnet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb9e181f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bw_avg_correlation.png',\n",
       " 'bw_avg_distribution.png',\n",
       " 'bw_max_correlation.png',\n",
       " 'bw_max_distribution.png',\n",
       " 'bw_min_correlation.png',\n",
       " 'bw_min_distribution.png',\n",
       " 'bw_sd_correlation.png',\n",
       " 'bw_sd_distribution.png',\n",
       " 'clustering_avg_correlation.png',\n",
       " 'clustering_avg_distribution.png',\n",
       " 'density_correlation.png',\n",
       " 'density_distribution.png',\n",
       " 'nnz_avg_correlation.png',\n",
       " 'nnz_avg_distribution.png',\n",
       " 'nnz_max_correlation.png',\n",
       " 'nnz_max_distribution.png',\n",
       " 'nnz_min_correlation.png',\n",
       " 'nnz_min_distribution.png',\n",
       " 'nnz_sd_correlation.png',\n",
       " 'nnz_sd_distribution.png',\n",
       " 'scatter_avg_correlation.png',\n",
       " 'scatter_avg_distribution.png',\n",
       " 'scatter_sd_correlation.png',\n",
       " 'scatter_sd_distribution.png']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the 'plots' directory\n",
    "output_dir = \"plots_resnet\"\n",
    "files = os.listdir(output_dir)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "027f111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ayush\\\\Desktop\\\\Msc\\\\plots_resnet_archive.zip'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a zip file containing all images\n",
    "shutil.make_archive('plots_resnet_archive', 'zip', 'plots_resnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55bb2cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='plots_resnet_archive.zip' target='_blank'>plots_resnet_archive.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\ayush\\Desktop\\Msc\\plots_resnet_archive.zip"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a download link for the zip file\n",
    "FileLink('plots_resnet_archive.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30807b",
   "metadata": {},
   "source": [
    "# Third Run (YOLOV5, YOLOV8, ResNetV1, VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e17dd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: zoo:yolov5-s6-coco-pruned65_quantized\n",
      "Processing model: zoo:vgg-16-imagenet-pruned\n",
      "Processing model: zoo:resnet_v1-34-imagenet-pruned\n",
      "Processing model: zoo:yolov8-m-coco-pruned80_quantized\n",
      "Processing model: zoo:yolov5-m6-coco-pruned75_quantized\n",
      "Processing model: zoo:vgg-19-imagenet-pruned\n",
      "Processing model: zoo:yolov5-s6-voc_coco-pruned65_quantized\n",
      "Processing model: zoo:vgg-11-imagenet-pruned\n",
      "Processing model: zoo:resnet_v1-18-imagenet-pruned85.4block_quantized\n",
      "Processing model: zoo:yolov8-n-coco-pruned49_quantized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from onnx import numpy_helper\n",
    "from sparsezoo import Model\n",
    "\n",
    "# Function to calculate sparsity and features\n",
    "def calculate_features(weight_matrix):\n",
    "    if weight_matrix.size == 0:  # Check if the matrix size is zero\n",
    "        return {\n",
    "            'density': None,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    if weight_matrix.ndim == 0:  # Scalar\n",
    "        return {\n",
    "            'density': 1.0 if weight_matrix != 0 else 0.0,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "    elif weight_matrix.ndim == 1:  # 1D array\n",
    "        nnz = np.count_nonzero(weight_matrix)\n",
    "        density = nnz / weight_matrix.size if weight_matrix.size > 0 else 0\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    N = weight_matrix.shape[0]\n",
    "    nnz = np.count_nonzero(weight_matrix)\n",
    "    \n",
    "    # Calculate density\n",
    "    if weight_matrix.ndim == 2:\n",
    "        density = nnz / (N ** 2) if N > 0 else 0\n",
    "    else:\n",
    "        density = nnz / weight_matrix.size\n",
    "\n",
    "    if weight_matrix.ndim == 2:\n",
    "        nnz_per_row = np.count_nonzero(weight_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in weight_matrix]\n",
    "    elif weight_matrix.ndim == 4:\n",
    "        reshaped_matrix = weight_matrix.reshape(weight_matrix.shape[0], -1)\n",
    "        nnz_per_row = np.count_nonzero(reshaped_matrix, axis=1)\n",
    "        bw = [np.max(np.nonzero(row)[0]) - np.min(np.nonzero(row)[0]) + 1 if np.count_nonzero(row) > 0 else 0 for row in reshaped_matrix]\n",
    "    else:\n",
    "        return {\n",
    "            'density': density,\n",
    "            'nnz_min': None,\n",
    "            'nnz_max': None,\n",
    "            'nnz_avg': None,\n",
    "            'nnz_sd': None,\n",
    "            'bw_min': None,\n",
    "            'bw_max': None,\n",
    "            'bw_avg': None,\n",
    "            'bw_sd': None,\n",
    "            'scatter_avg': None,\n",
    "            'scatter_sd': None,\n",
    "            'clustering_avg': None\n",
    "        }\n",
    "\n",
    "    nnz_min = np.min(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_max = np.max(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_avg = np.mean(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "    nnz_sd = np.std(nnz_per_row) if nnz_per_row.size > 0 else 0\n",
    "\n",
    "    bw_min = np.min(bw) if bw else 0\n",
    "    bw_max = np.max(bw) if bw else 0\n",
    "    bw_avg = np.mean(bw) if bw else 0\n",
    "    bw_sd = np.std(bw) if bw else 0\n",
    "\n",
    "    scatter = nnz_per_row / (np.array(bw) + 1e-9)\n",
    "    scatter_avg = np.mean(scatter) if scatter.size > 0 else 0\n",
    "    scatter_sd = np.std(scatter) if scatter.size > 0 else 0\n",
    "\n",
    "    clustering = []\n",
    "    for row in reshaped_matrix if weight_matrix.ndim == 4 else weight_matrix:\n",
    "        groups = 0\n",
    "        prev_nonzero = -2\n",
    "        for idx in np.nonzero(row)[0]:\n",
    "            if idx != prev_nonzero + 1:\n",
    "                groups += 1\n",
    "            prev_nonzero = idx\n",
    "        clustering.append(groups / (np.count_nonzero(row) + 1e-9))\n",
    "    clustering_avg = np.mean(clustering) if clustering else 0\n",
    "\n",
    "    return {\n",
    "        'density': density,\n",
    "        'nnz_min': nnz_min,\n",
    "        'nnz_max': nnz_max,\n",
    "        'nnz_avg': nnz_avg,\n",
    "        'nnz_sd': nnz_sd,\n",
    "        'bw_min': bw_min,\n",
    "        'bw_max': bw_max,\n",
    "        'bw_avg': bw_avg,\n",
    "        'bw_sd': bw_sd,\n",
    "        'scatter_avg': scatter_avg,\n",
    "        'scatter_sd': scatter_sd,\n",
    "        'clustering_avg': clustering_avg\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_metrics_from_models(model_stubs, sample_size=None):\n",
    "    metrics_list = []\n",
    "\n",
    "    for stub, accuracy in model_stubs:\n",
    "        print(f\"Processing model: {stub}\")\n",
    "        model = Model(stub)\n",
    "        onnx_model_file = model.onnx_model.path\n",
    "        onnx_model = onnx.load(onnx_model_file)\n",
    "\n",
    "        for tensor in onnx_model.graph.initializer:\n",
    "            weights = numpy_helper.to_array(tensor)\n",
    "            features = calculate_features(weights)\n",
    "\n",
    "            if any(value is None for value in features.values()):\n",
    "                continue  # Skip this layer if any feature is None\n",
    "\n",
    "            features['layer'] = tensor.name\n",
    "            features['accuracy'] = accuracy\n",
    "            features['model'] = stub\n",
    "            metrics_list.append(features)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    if sample_size and len(df_metrics) > sample_size:\n",
    "        df_metrics = df_metrics.sample(n=sample_size, random_state=42)  # Sample data to reduce size\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "# Function to plot the distribution of metrics and save them as images\n",
    "def plot_metrics_distribution(df_metrics, output_dir=\"plots_new\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(df_metrics[metric].dropna(), kde=True, bins=50)\n",
    "            plt.title(f'Distribution of {metric}')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_distribution.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Function to plot correlation of metrics with accuracy and save them as images\n",
    "def plot_correlation_with_accuracy(df_metrics, output_dir=\"plots_new\"):\n",
    "    metrics = ['density', 'nnz_min', 'nnz_max', 'nnz_avg', 'nnz_sd', 'bw_min', 'bw_max', 'bw_avg', 'bw_sd', 'scatter_avg', 'scatter_sd', 'clustering_avg']\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Check if the column exists and has valid (non-None) data\n",
    "        if metric in df_metrics.columns and df_metrics[metric].notna().any():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.regplot(x=df_metrics[metric], y=df_metrics['accuracy'], ci=None, scatter_kws={'s': 50})\n",
    "            plt.title(f'Correlation of {metric} with Accuracy')\n",
    "            plt.xlabel(metric)\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_correlation.png'))\n",
    "            plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Example model stubs with their corresponding accuracies\n",
    "model_stubs = [\n",
    "    (\"zoo:yolov5-s6-coco-pruned65_quantized\", 61.5),\n",
    "    (\"zoo:vgg-16-imagenet-pruned\", 70.8),\n",
    "    (\"zoo:resnet_v1-34-imagenet-pruned\", 73.3),\n",
    "    (\"zoo:yolov8-m-coco-pruned80_quantized\", 65.2),\n",
    "    (\"zoo:yolov5-m6-coco-pruned75_quantized\", 67.3),\n",
    "    (\"zoo:vgg-19-imagenet-pruned\", 71.7),\n",
    "    (\"zoo:yolov5-s6-voc_coco-pruned65_quantized\", 86.8),\n",
    "    (\"zoo:vgg-11-imagenet-pruned\", 68.3),\n",
    "    (\"zoo:resnet_v1-18-imagenet-pruned85.4block_quantized\", 69),\n",
    "    (\"zoo:yolov8-n-coco-pruned49_quantized\", 50.1)\n",
    "    # Add more models and their accuracies here\n",
    "]\n",
    "\n",
    "# Extract metrics from the models\n",
    "df_metrics = extract_metrics_from_models(model_stubs, sample_size=1000)  # Add sample_size to limit data if necessary\n",
    "\n",
    "# Plot the distribution of metrics and save them as images\n",
    "plot_metrics_distribution(df_metrics, output_dir=\"plots_new\")\n",
    "\n",
    "# Plot the correlation of metrics with accuracy and save them as images\n",
    "plot_correlation_with_accuracy(df_metrics, output_dir=\"plots_new\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5de52886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bw_avg_correlation.png',\n",
       " 'bw_avg_distribution.png',\n",
       " 'bw_max_correlation.png',\n",
       " 'bw_max_distribution.png',\n",
       " 'bw_min_correlation.png',\n",
       " 'bw_min_distribution.png',\n",
       " 'bw_sd_correlation.png',\n",
       " 'bw_sd_distribution.png',\n",
       " 'clustering_avg_correlation.png',\n",
       " 'clustering_avg_distribution.png',\n",
       " 'density_correlation.png',\n",
       " 'density_distribution.png',\n",
       " 'nnz_avg_correlation.png',\n",
       " 'nnz_avg_distribution.png',\n",
       " 'nnz_max_correlation.png',\n",
       " 'nnz_max_distribution.png',\n",
       " 'nnz_min_correlation.png',\n",
       " 'nnz_min_distribution.png',\n",
       " 'nnz_sd_correlation.png',\n",
       " 'nnz_sd_distribution.png',\n",
       " 'scatter_avg_correlation.png',\n",
       " 'scatter_avg_distribution.png',\n",
       " 'scatter_sd_correlation.png',\n",
       " 'scatter_sd_distribution.png']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the 'plots' directory\n",
    "output_dir = \"plots_new\"\n",
    "files = os.listdir(output_dir)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5451aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ayush\\\\Desktop\\\\Msc\\\\plots_new_archive.zip'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a zip file containing all images\n",
    "shutil.make_archive('plots_new_archive', 'zip', 'plots_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "888ee999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='plots_new_archive.zip' target='_blank'>plots_new_archive.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\ayush\\Desktop\\Msc\\plots_new_archive.zip"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a download link for the zip file\n",
    "FileLink('plots_new_archive.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d2e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
